2025-12-08 22:14:52.686 [warning] [Anthropic] Tool 'copilot_testFailure' is missing input schema type; defaulting to 'object'
2025-12-08 22:14:55.880 [info] [Anthropic] Start request req_011CVvPK1uG6WV43DqehUxJG to claude-sonnet-4-5-20250929: 17 messages
2025-12-08 22:14:55.881 [trace] [Anthropic] SEND messages.stream [req_011CVvPK1uG6WV43DqehUxJG]: {
  "model": "claude-sonnet-4-5-20250929",
  "max_tokens": 4096,
  "tools": [
    {
      "name": "configure_notebook",
      "description": "Tool used to configure a Notebook. ALWAYS use this tool before running/executing any Notebook Cells for the first time or before listing/installing packages in Notebooks for the first time. I.e. there is no need to use this tool more than once for the same notebook.",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePath": {
            "description": "The absolute path of the notebook with the active kernel.",
            "type": "string"
          }
        },
        "required": [
          "filePath"
        ]
      }
    },
    {
      "name": "copilot_applyPatch",
      "description": "Edit text files. Do not use this tool to edit Jupyter notebooks. `apply_patch` allows you to execute a diff/patch against a text file, but the format of the diff specification is unique to this task, so pay careful attention to these instructions. To use the `apply_patch` command, you should pass a message of the following structure as \"input\":\n\n*** Begin Patch\n[YOUR_PATCH]\n*** End Patch\n\nWhere [YOUR_PATCH] is the actual content of your patch, specified in the following V4A diff format.\n\n*** [ACTION] File: [/absolute/path/to/file] -> ACTION can be one of Add, Update, or Delete.\nAn example of a message that you might pass as \"input\" to this function, in order to apply a patch, is shown below.\n\n*** Begin Patch\n*** Update File: /Users/someone/pygorithm/searching/binary_search.py\n@@class BaseClass\n@@    def search():\n-        pass\n+        raise NotImplementedError()\n\n@@class Subclass\n@@    def search():\n-        pass\n+        raise NotImplementedError()\n\n*** End Patch\nDo not use line numbers in this diff format.",
      "input_schema": {
        "type": "object",
        "properties": {
          "input": {
            "type": "string",
            "description": "The edit patch to apply."
          },
          "explanation": {
            "type": "string",
            "description": "A short description of what the tool call is aiming to achieve."
          }
        },
        "required": [
          "input",
          "explanation"
        ]
      }
    },
    {
      "name": "copilot_createDirectory",
      "description": "Create a new directory structure in the workspace. Will recursively create all directories in the path, like mkdir -p. You do not need to use this tool before using create_file, that tool will automatically create the needed directories.",
      "input_schema": {
        "type": "object",
        "properties": {
          "dirPath": {
            "type": "string",
            "description": "The absolute path to the directory to create."
          }
        },
        "required": [
          "dirPath"
        ]
      }
    },
    {
      "name": "copilot_createFile",
      "description": "This is a tool for creating a new file in the workspace. The file will be created with the specified content. The directory will be created if it does not already exist. Never use this tool to edit a file that already exists.",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePath": {
            "type": "string",
            "description": "The absolute path to the file to create."
          },
          "content": {
            "type": "string",
            "description": "The content to write to the file."
          }
        },
        "required": [
          "filePath",
          "content"
        ]
      }
    },
    {
      "name": "copilot_createNewJupyterNotebook",
      "description": "Generates a new Jupyter Notebook (.ipynb) in VS Code. Jupyter Notebooks are interactive documents commonly used for data exploration, analysis, visualization, and combining code with narrative text. Prefer creating plain Python files or similar unless a user explicitly requests creating a new Jupyter Notebook or already has a Jupyter Notebook opened or exists in the workspace.",
      "input_schema": {
        "type": "object",
        "properties": {
          "query": {
            "type": "string",
            "description": "The query to use to generate the jupyter notebook. This should be a clear and concise description of the notebook the user wants to create."
          }
        },
        "required": [
          "query"
        ]
      }
    },
    {
      "name": "copilot_createNewWorkspace",
      "description": "Get comprehensive setup steps to help the user create complete project structures in a VS Code workspace. This tool is designed for full project initialization and scaffolding, not for creating individual files.\n\nWhen to use this tool:\n- User wants to create a new complete project from scratch\n- Setting up entire project frameworks (TypeScript projects, React apps, Node.js servers, etc.)\n- Initializing Model Context Protocol (MCP) servers with full structure\n- Creating VS Code extensions with proper scaffolding\n- Setting up Next.js, Vite, or other framework-based projects\n- User asks for \"new project\", \"create a workspace\", \"set up a [framework] project\"\n- Need to establish complete development environment with dependencies, config files, and folder structure\n\nWhen NOT to use this tool:\n- Creating single files or small code snippets\n- Adding individual files to existing projects\n- Making modifications to existing codebases\n- User asks to \"create a file\" or \"add a component\"\n- Simple code examples or demonstrations\n- Debugging or fixing existing code\n\nThis tool provides complete project setup including:\n- Folder structure creation\n- Package.json and dependency management\n- Configuration files (tsconfig, eslint, etc.)\n- Initial boilerplate code\n- Development environment setup\n- Build and run instructions\n\nUse other file creation tools for individual files within existing projects.",
      "input_schema": {
        "type": "object",
        "properties": {
          "query": {
            "type": "string",
            "description": "The query to use to generate the new workspace. This should be a clear and concise description of the workspace the user wants to create."
          }
        },
        "required": [
          "query"
        ]
      }
    },
    {
      "name": "copilot_editFiles",
      "description": "This is a placeholder tool, do not use",
      "input_schema": {
        "type": "object",
        "properties": {},
        "required": []
      }
    },
    {
      "name": "copilot_editNotebook",
      "description": "This is a tool for editing an existing Notebook file in the workspace. Generate the \"explanation\" property first.\nThe system is very smart and can understand how to apply your edits to the notebooks.\nWhen updating the content of an existing cell, ensure newCode preserves whitespace and indentation exactly and does NOT include any code markers such as (...existing code...).",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePath": {
            "type": "string",
            "description": "An absolute path to the notebook file to edit, or the URI of a untitled, not yet named, file, such as `untitled:Untitled-1."
          },
          "cellId": {
            "type": "string",
            "description": "Id of the cell that needs to be deleted or edited. Use the value `TOP`, `BOTTOM` when inserting a cell at the top or bottom of the notebook, else provide the id of the cell after which a new cell is to be inserted. Remember, if a cellId is provided and editType=insert, then a cell will be inserted after the cell with the provided cellId."
          },
          "newCode": {
            "anyOf": [
              {
                "type": "string",
                "description": "The code for the new or existing cell to be edited. Code should not be wrapped within <VSCode.Cell> tags. Do NOT include code markers such as (...existing code...) to indicate existing code."
              },
              {
                "type": "array",
                "items": {
                  "type": "string",
                  "description": "The code for the new or existing cell to be edited. Code should not be wrapped within <VSCode.Cell> tags"
                }
              }
            ]
          },
          "language": {
            "type": "string",
            "description": "The language of the cell. `markdown`, `python`, `javascript`, `julia`, etc."
          },
          "editType": {
            "type": "string",
            "enum": [
              "insert",
              "delete",
              "edit"
            ],
            "description": "The operation peformed on the cell, whether `insert`, `delete` or `edit`.\nUse the `editType` field to specify the operation: `insert` to add a new cell, `edit` to modify an existing cell's content, and `delete` to remove a cell."
          }
        },
        "required": [
          "filePath",
          "editType",
          "cellId"
        ]
      }
    },
    {
      "name": "copilot_fetchWebPage",
      "description": "Fetches the main content from a web page. This tool is useful for summarizing or analyzing the content of a webpage. You should use this tool when you think the user is looking for information from a specific webpage.",
      "input_schema": {
        "type": "object",
        "properties": {
          "urls": {
            "type": "array",
            "items": {
              "type": "string"
            },
            "description": "An array of URLs to fetch content from."
          },
          "query": {
            "type": "string",
            "description": "The query to search for in the web page's content. This should be a clear and concise description of the content you want to find."
          }
        },
        "required": [
          "urls",
          "query"
        ]
      }
    },
    {
      "name": "copilot_findFiles",
      "description": "Search for files in the workspace by glob pattern. This only returns the paths of matching files. Use this tool when you know the exact filename pattern of the files you're searching for. Glob patterns match from the root of the workspace folder. Examples:\n- **/*.{js,ts} to match all js/ts files in the workspace.\n- src/** to match all files under the top-level src folder.\n- **/foo/**/*.js to match all js files under any foo folder in the workspace.",
      "input_schema": {
        "type": "object",
        "properties": {
          "query": {
            "type": "string",
            "description": "Search for files with names or paths matching this glob pattern."
          },
          "maxResults": {
            "type": "number",
            "description": "The maximum number of results to return. Do not use this unless necessary, it can slow things down. By default, only some matches are returned. If you use this and don't see what you're looking for, you can try again with a more specific query or a larger maxResults."
          }
        },
        "required": [
          "query"
        ]
      }
    },
    {
      "name": "copilot_findTestFiles",
      "description": "For a source code file, find the file that contains the tests. For a test file find the file that contains the code under test.",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePaths": {
            "type": "array",
            "items": {
              "type": "string"
            }
          }
        },
        "required": [
          "filePaths"
        ]
      }
    },
    {
      "name": "copilot_findTextInFiles",
      "description": "Do a fast text search in the workspace. Use this tool when you want to search with an exact string or regex. If you are not sure what words will appear in the workspace, prefer using regex patterns with alternation (|) or character classes to search for multiple potential words at once instead of making separate searches. For example, use 'function|method|procedure' to look for all of those words at once. Use includePattern to search within files matching a specific pattern, or in a specific file, using a relative path. Use this tool when you want to see an overview of a particular file, instead of using read_file many times to look for code within a file.",
      "input_schema": {
        "type": "object",
        "properties": {
          "query": {
            "type": "string",
            "description": "The pattern to search for in files in the workspace. Use regex with alternation (e.g., 'word1|word2|word3') or character classes to find multiple potential words in a single search. Be sure to set the isRegexp property properly to declare whether it's a regex or plain text pattern. Is case-insensitive."
          },
          "isRegexp": {
            "type": "boolean",
            "description": "Whether the pattern is a regex."
          },
          "includePattern": {
            "type": "string",
            "description": "Search files matching this glob pattern. Will be applied to the relative path of files within the workspace. To search recursively inside a folder, use a proper glob pattern like \"src/folder/**\". Do not use | in includePattern."
          },
          "maxResults": {
            "type": "number",
            "description": "The maximum number of results to return. Do not use this unless necessary, it can slow things down. By default, only some matches are returned. If you use this and don't see what you're looking for, you can try again with a more specific query or a larger maxResults."
          }
        },
        "required": [
          "query",
          "isRegexp"
        ]
      }
    },
    {
      "name": "copilot_getChangedFiles",
      "description": "Get git diffs of current file changes in a git repository. Don't forget that you can use run_in_terminal to run git commands in a terminal as well.",
      "input_schema": {
        "type": "object",
        "properties": {
          "repositoryPath": {
            "type": "string",
            "description": "The absolute path to the git repository to look for changes in. If not provided, the active git repository will be used."
          },
          "sourceControlState": {
            "type": "array",
            "items": {
              "type": "string",
              "enum": [
                "staged",
                "unstaged",
                "merge-conflicts"
              ]
            },
            "description": "The kinds of git state to filter by. Allowed values are: 'staged', 'unstaged', and 'merge-conflicts'. If not provided, all states will be included."
          }
        }
      }
    },
    {
      "name": "copilot_getDocInfo",
      "description": "Find information about how to document it a symbol like a class or function. This tool is useful for generating documentation comments for code symbols. You should use this tool when you think the user is looking for information about how to document a specific code symbol.",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePaths": {
            "type": "array",
            "items": {
              "type": "string"
            },
            "description": "The file paths for which documentation information is needed."
          }
        },
        "required": [
          "filePaths"
        ]
      }
    },
    {
      "name": "copilot_getErrors",
      "description": "Get any compile or lint errors in a specific file or across all files. If the user mentions errors or problems in a file, they may be referring to these. Use the tool to see the same errors that the user is seeing. If the user asks you to analyze all errors, or does not specify a file, use this tool to gather errors for all files. Also use this tool after editing a file to validate the change.",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePaths": {
            "description": "The absolute paths to the files or folders to check for errors. Omit 'filePaths' when retrieving all errors.",
            "type": "array",
            "items": {
              "type": "string"
            }
          }
        }
      }
    },
    {
      "name": "copilot_getNotebookSummary",
      "description": "This is a tool returns the list of the Notebook cells along with the id, cell types, line ranges, language, execution information and output mime types for each cell. This is useful to get Cell Ids when executing a notebook or determine what cells have been executed and what order, or what cells have outputs. If required to read contents of a cell use this to determine the line range of a cells, and then use read_file tool to read a specific line range. Requery this tool if the contents of the notebook change.",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePath": {
            "type": "string",
            "description": "An absolute path to the notebook file with the cell to run, or the URI of a untitled, not yet named, file, such as `untitled:Untitled-1.ipynb"
          }
        },
        "required": [
          "filePath"
        ]
      }
    },
    {
      "name": "copilot_getProjectSetupInfo",
      "description": "Do not call this tool without first calling the tool to create a workspace. This tool provides a project setup information for a Visual Studio Code workspace based on a project type and programming language.",
      "input_schema": {
        "type": "object",
        "properties": {
          "projectType": {
            "type": "string",
            "description": "The type of project to create. Supported values are: 'python-script', 'python-project', 'mcp-server', 'model-context-protocol-server', 'vscode-extension', 'next-js', 'vite' and 'other'"
          }
        },
        "required": [
          "projectType"
        ]
      }
    },
    {
      "name": "copilot_getSearchResults",
      "description": "The results from the search view",
      "input_schema": {
        "type": "object",
        "properties": {},
        "required": []
      }
    },
    {
      "name": "copilot_getVSCodeAPI",
      "description": "Get comprehensive VS Code API documentation and references for extension development. This tool provides authoritative documentation for VS Code's extensive API surface, including proposed APIs, contribution points, and best practices. Use this tool for understanding complex VS Code API interactions.\n\nWhen to use this tool:\n- User asks about specific VS Code APIs, interfaces, or extension capabilities\n- Need documentation for VS Code extension contribution points (commands, views, settings, etc.)\n- Questions about proposed APIs and their usage patterns\n- Understanding VS Code extension lifecycle, activation events, and packaging\n- Best practices for VS Code extension development architecture\n- API examples and code patterns for extension features\n- Troubleshooting extension-specific issues or API limitations\n\nWhen NOT to use this tool:\n- Creating simple standalone files or scripts unrelated to VS Code extensions\n- General programming questions not specific to VS Code extension development\n- Questions about using VS Code as an editor (user-facing features)\n- Non-extension related development tasks\n- File creation or editing that doesn't involve VS Code extension APIs\n\nCRITICAL usage guidelines:\n1. Always include specific API names, interfaces, or concepts in your query\n2. Mention the extension feature you're trying to implement\n3. Include context about proposed vs stable APIs when relevant\n4. Reference specific contribution points when asking about extension manifest\n5. Be specific about the VS Code version or API version when known\n\nScope: This tool is for EXTENSION DEVELOPMENT ONLY - building tools that extend VS Code itself, not for general file creation or non-extension programming tasks.",
      "input_schema": {
        "type": "object",
        "properties": {
          "query": {
            "type": "string",
            "description": "The query to search vscode documentation for. Should contain all relevant context."
          }
        },
        "required": [
          "query"
        ]
      }
    },
    {
      "name": "copilot_githubRepo",
      "description": "Searches a GitHub repository for relevant source code snippets. Only use this tool if the user is very clearly asking for code snippets from a specific GitHub repository. Do not use this tool for Github repos that the user has open in their workspace.",
      "input_schema": {
        "type": "object",
        "properties": {
          "repo": {
            "type": "string",
            "description": "The name of the Github repository to search for code in. Should must be formatted as '<owner>/<repo>'."
          },
          "query": {
            "type": "string",
            "description": "The query to search for repo. Should contain all relevant context."
          }
        },
        "required": [
          "repo",
          "query"
        ]
      }
    },
    {
      "name": "copilot_insertEdit",
      "description": "Insert new code into an existing file in the workspace. Use this tool once per file that needs to be modified, even if there are multiple changes for a file. Generate the \"explanation\" property first.\nThe system is very smart and can understand how to apply your edits to the files, you just need to provide minimal hints.\nAvoid repeating existing code, instead use comments to represent regions of unchanged code. Be as concise as possible. For example:\n// ...existing code...\n{ changed code }\n// ...existing code...\n{ changed code }\n// ...existing code...\n\nHere is an example of how you should use format an edit to an existing Person class:\nclass Person {\n\t// ...existing code...\n\tage: number;\n\t// ...existing code...\n\tgetAge() {\n\treturn this.age;\n\t}\n}",
      "input_schema": {
        "type": "object",
        "properties": {
          "explanation": {
            "type": "string",
            "description": "A short explanation of the edit being made."
          },
          "filePath": {
            "type": "string",
            "description": "An absolute path to the file to edit."
          },
          "code": {
            "type": "string",
            "description": "The code change to apply to the file.\nThe system is very smart and can understand how to apply your edits to the files, you just need to provide minimal hints.\nAvoid repeating existing code, instead use comments to represent regions of unchanged code. Be as concise as possible. For example:\n// ...existing code...\n{ changed code }\n// ...existing code...\n{ changed code }\n// ...existing code...\n\nHere is an example of how you should use format an edit to an existing Person class:\nclass Person {\n\t// ...existing code...\n\tage: number;\n\t// ...existing code...\n\tgetAge() {\n\t\treturn this.age;\n\t}\n}"
          }
        },
        "required": [
          "explanation",
          "filePath",
          "code"
        ]
      }
    },
    {
      "name": "copilot_installExtension",
      "description": "Install an extension in VS Code. Use this tool to install an extension in Visual Studio Code as part of a new workspace creation process only.",
      "input_schema": {
        "type": "object",
        "properties": {
          "id": {
            "type": "string",
            "description": "The ID of the extension to install. This should be in the format <publisher>.<extension>."
          },
          "name": {
            "type": "string",
            "description": "The name of the extension to install. This should be a clear and concise description of the extension."
          }
        },
        "required": [
          "id",
          "name"
        ]
      }
    },
    {
      "name": "copilot_listCodeUsages",
      "description": "Request to list all usages (references, definitions, implementations etc) of a function, class, method, variable etc. Use this tool when \n1. Looking for a sample implementation of an interface or class\n2. Checking how a function is used throughout the codebase.\n3. Including and updating all usages when changing a function, method, or constructor",
      "input_schema": {
        "type": "object",
        "properties": {
          "symbolName": {
            "type": "string",
            "description": "The name of the symbol, such as a function name, class name, method name, variable name, etc."
          },
          "filePaths": {
            "type": "array",
            "description": "One or more file paths which likely contain the definition of the symbol. For instance the file which declares a class or function. This is optional but will speed up the invocation of this tool and improve the quality of its output.",
            "items": {
              "type": "string"
            }
          }
        },
        "required": [
          "symbolName"
        ]
      }
    },
    {
      "name": "copilot_listDirectory",
      "description": "List the contents of a directory. Result will have the name of the child. If the name ends in /, it's a folder, otherwise a file",
      "input_schema": {
        "type": "object",
        "properties": {
          "path": {
            "type": "string",
            "description": "The absolute path to the directory to list."
          }
        },
        "required": [
          "path"
        ]
      }
    },
    {
      "name": "copilot_multiReplaceString",
      "description": "This tool allows you to apply multiple replace_string_in_file operations in a single call, which is more efficient than calling replace_string_in_file multiple times. It takes an array of replacement operations and applies them sequentially. Each replacement operation has the same parameters as replace_string_in_file: filePath, oldString, newString, and explanation. This tool is ideal when you need to make multiple edits across different files or multiple edits in the same file. The tool will provide a summary of successful and failed operations.",
      "input_schema": {
        "type": "object",
        "properties": {
          "explanation": {
            "type": "string",
            "description": "A brief explanation of what the multi-replace operation will accomplish."
          },
          "replacements": {
            "type": "array",
            "description": "An array of replacement operations to apply sequentially.",
            "items": {
              "type": "object",
              "properties": {
                "explanation": {
                  "type": "string",
                  "description": "A brief explanation of this specific replacement operation."
                },
                "filePath": {
                  "type": "string",
                  "description": "An absolute path to the file to edit."
                },
                "oldString": {
                  "type": "string",
                  "description": "The exact literal text to replace, preferably unescaped. Include at least 3 lines of context BEFORE and AFTER the target text, matching whitespace and indentation precisely. If this string is not the exact literal text or does not match exactly, this replacement will fail."
                },
                "newString": {
                  "type": "string",
                  "description": "The exact literal text to replace `oldString` with, preferably unescaped. Provide the EXACT text. Ensure the resulting code is correct and idiomatic."
                }
              },
              "required": [
                "explanation",
                "filePath",
                "oldString",
                "newString"
              ]
            },
            "minItems": 1
          }
        },
        "required": [
          "explanation",
          "replacements"
        ]
      }
    },
    {
      "name": "copilot_openSimpleBrowser",
      "description": "Preview a website or open a URL in the editor's Simple Browser. Useful for quickly viewing locally hosted websites, demos, or resources without leaving the coding environment.",
      "input_schema": {
        "type": "object",
        "properties": {
          "url": {
            "type": "string",
            "description": "The website URL to preview or open in the Simple Browser inside the editor. Must be either an http or https URL"
          }
        },
        "required": [
          "url"
        ]
      }
    },
    {
      "name": "copilot_readFile",
      "description": "Read the contents of a file.\n\nYou must specify the line range you're interested in. Line numbers are 1-indexed. If the file contents returned are insufficient for your task, you may call this tool again to retrieve more content. Prefer reading larger ranges over doing many small reads.",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePath": {
            "description": "The absolute path of the file to read.",
            "type": "string"
          },
          "startLine": {
            "type": "number",
            "description": "The line number to start reading from, 1-based."
          },
          "endLine": {
            "type": "number",
            "description": "The inclusive line number to end reading at, 1-based."
          }
        },
        "required": [
          "filePath",
          "startLine",
          "endLine"
        ]
      }
    },
    {
      "name": "copilot_readNotebookCellOutput",
      "description": "This tool will retrieve the output for a notebook cell from its most recent execution or restored from disk. The cell may have output even when it has not been run in the current kernel session. This tool has a higher token limit for output length than the runNotebookCell tool.",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePath": {
            "type": "string",
            "description": "An absolute path to the notebook file with the cell to run, or the URI of a untitled, not yet named, file, such as `untitled:Untitled-1.ipynb"
          },
          "cellId": {
            "type": "string",
            "description": "The ID of the cell for which output should be retrieved."
          }
        },
        "required": [
          "filePath",
          "cellId"
        ]
      }
    },
    {
      "name": "copilot_readProjectStructure",
      "description": "Get a file tree representation of the workspace.",
      "input_schema": {
        "type": "object",
        "properties": {},
        "required": []
      }
    },
    {
      "name": "copilot_replaceString",
      "description": "This is a tool for making edits in an existing file in the workspace. For moving or renaming files, use run in terminal tool with the 'mv' command instead. For larger edits, split them into smaller edits and call the edit tool multiple times to ensure accuracy. Before editing, always ensure you have the context to understand the file's contents and context. To edit a file, provide: 1) filePath (absolute path), 2) oldString (MUST be the exact literal text to replace including all whitespace, indentation, newlines, and surrounding code etc), and 3) newString (MUST be the exact literal text to replace \\`oldString\\` with (also including all whitespace, indentation, newlines, and surrounding code etc.). Ensure the resulting code is correct and idiomatic.). Each use of this tool replaces exactly ONE occurrence of oldString.\n\nCRITICAL for \\`oldString\\`: Must uniquely identify the single instance to change. Include at least 3 lines of context BEFORE and AFTER the target text, matching whitespace and indentation precisely. If this string matches multiple locations, or does not match exactly, the tool will fail. Never use 'Lines 123-456 omitted' from summarized documents or ...existing code... comments in the oldString or newString.",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePath": {
            "type": "string",
            "description": "An absolute path to the file to edit."
          },
          "oldString": {
            "type": "string",
            "description": "The exact literal text to replace, preferably unescaped. For single replacements (default), include at least 3 lines of context BEFORE and AFTER the target text, matching whitespace and indentation precisely. For multiple replacements, specify expected_replacements parameter. If this string is not the exact literal text (i.e. you escaped it) or does not match exactly, the tool will fail."
          },
          "newString": {
            "type": "string",
            "description": "The exact literal text to replace `old_string` with, preferably unescaped. Provide the EXACT text. Ensure the resulting code is correct and idiomatic."
          }
        },
        "required": [
          "filePath",
          "oldString",
          "newString"
        ]
      }
    },
    {
      "name": "copilot_runNotebookCell",
      "description": "This is a tool for running a code cell in a notebook file directly in the notebook editor. The output from the execution will be returned. Code cells should be run as they are added or edited when working through a problem to bring the kernel state up to date and ensure the code executes successfully. Code cells are ready to run and don't require any pre-processing. If asked to run the first cell in a notebook, you should run the first code cell since markdown cells cannot be executed. NOTE: Avoid executing Markdown cells or providing Markdown cell IDs, as Markdown cells cannot be  executed.",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePath": {
            "type": "string",
            "description": "An absolute path to the notebook file with the cell to run, or the URI of a untitled, not yet named, file, such as `untitled:Untitled-1.ipynb"
          },
          "reason": {
            "type": "string",
            "description": "An optional explanation of why the cell is being run. This will be shown to the user before the tool is run and is not necessary if it's self-explanatory."
          },
          "cellId": {
            "type": "string",
            "description": "The ID for the code cell to execute. Avoid providing markdown cell IDs as nothing will be executed."
          },
          "continueOnError": {
            "type": "boolean",
            "description": "Whether or not execution should continue for remaining cells if an error is encountered. Default to false unless instructed otherwise."
          }
        },
        "required": [
          "filePath",
          "cellId"
        ]
      }
    },
    {
      "name": "copilot_runVscodeCommand",
      "description": "Run a command in VS Code. Use this tool to run a command in Visual Studio Code as part of a new workspace creation process only.",
      "input_schema": {
        "type": "object",
        "properties": {
          "commandId": {
            "type": "string",
            "description": "The ID of the command to execute. This should be in the format <command>."
          },
          "name": {
            "type": "string",
            "description": "The name of the command to execute. This should be a clear and concise description of the command."
          },
          "args": {
            "type": "array",
            "description": "The arguments to pass to the command. This should be an array of strings.",
            "items": {
              "type": "string"
            }
          }
        },
        "required": [
          "commandId",
          "name"
        ]
      }
    },
    {
      "name": "copilot_searchCodebase",
      "description": "Run a natural language search for relevant code or documentation comments from the user's current workspace. Returns relevant code snippets from the user's current workspace if it is large, or the full contents of the workspace if it is small.",
      "input_schema": {
        "type": "object",
        "properties": {
          "query": {
            "type": "string",
            "description": "The query to search the codebase for. Should contain all relevant context. Should ideally be text that might appear in the codebase, such as function names, variable names, or comments."
          }
        },
        "required": [
          "query"
        ]
      }
    },
    {
      "name": "copilot_searchWorkspaceSymbols",
      "description": "Search the user's workspace for code symbols using language services. Use this tool when the user is looking for a specific symbol in their workspace.",
      "input_schema": {
        "type": "object",
        "properties": {
          "symbolName": {
            "type": "string",
            "description": "The symbol to search for, such as a function name, class name, or variable name."
          }
        },
        "required": [
          "symbolName"
        ]
      }
    },
    {
      "name": "copilot_testFailure",
      "description": "Includes test failure information in the prompt.",
      "input_schema": {
        "type": "object"
      }
    },
    {
      "name": "create_and_run_task",
      "description": "Creates and runs a build, run, or custom task for the workspace by generating or adding to a tasks.json file based on the project structure (such as package.json or README.md). If the user asks to build, run, launch and they have no tasks.json file, use this tool. If they ask to create or add a task, use this tool.",
      "input_schema": {
        "type": "object",
        "properties": {
          "workspaceFolder": {
            "type": "string",
            "description": "The absolute path of the workspace folder where the tasks.json file will be created."
          },
          "task": {
            "type": "object",
            "description": "The task to add to the new tasks.json file.",
            "properties": {
              "label": {
                "type": "string",
                "description": "The label of the task."
              },
              "type": {
                "type": "string",
                "description": "The type of the task. The only supported value is 'shell'.",
                "enum": [
                  "shell"
                ]
              },
              "command": {
                "type": "string",
                "description": "The shell command to run for the task. Use this to specify commands for building or running the application."
              },
              "args": {
                "type": "array",
                "description": "The arguments to pass to the command.",
                "items": {
                  "type": "string"
                }
              },
              "isBackground": {
                "type": "boolean",
                "description": "Whether the task runs in the background without blocking the UI or other tasks. Set to true for long-running processes like watch tasks or servers that should continue executing without requiring user attention. When false, the task will block the terminal until completion."
              },
              "problemMatcher": {
                "type": "array",
                "description": "The problem matcher to use to parse task output for errors and warnings. Can be a predefined matcher like '$tsc' (TypeScript), '$eslint - stylish', '$gcc', etc., or a custom pattern defined in tasks.json. This helps VS Code display errors in the Problems panel and enables quick navigation to error locations.",
                "items": {
                  "type": "string"
                }
              },
              "group": {
                "type": "string",
                "description": "The group to which the task belongs."
              }
            },
            "required": [
              "label",
              "type",
              "command"
            ]
          }
        },
        "required": [
          "task",
          "workspaceFolder"
        ]
      }
    },
    {
      "name": "documentCreate",
      "description": "Create a new document in the workspace.",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePath": {
            "type": "string",
            "description": "The path to the document to create, including the file name and extension. This path must be relative to the workspace folder."
          },
          "workspaceFolder": {
            "type": "string",
            "description": "The workspace folder to create the document in. If not specified, the document will be created in the first workspace folder."
          },
          "content": {
            "type": "string",
            "description": "The initial content of the document. If not specified, the document will be created empty."
          },
          "errorIfExists": {
            "type": "boolean",
            "description": "Whether to throw an error if the document already exists. If false, the existing document will be opened instead.",
            "default": true
          }
        }
      }
    },
    {
      "name": "documentEdit",
      "description": "Output an edited version of the document.",
      "input_schema": {
        "type": "object",
        "properties": {
          "deltas": {
            "type": "array",
            "description": "The array of changes to apply.",
            "items": {
              "type": "object",
              "properties": {
                "delete": {
                  "type": "string",
                  "description": "Text to delete from the document."
                },
                "replace": {
                  "type": "string",
                  "description": "Text to replace the deleted text with."
                }
              }
            }
          }
        }
      }
    },
    {
      "name": "editNotebookCells",
      "description": "Perform edit operations on notebook cells. Use operation='add' to create new cells (requires cellType, index, and content), operation='update' to modify existing cells (requires cellIndex and content), or operation='delete' to remove cells (requires cellIndex). Use index=-1 to append cells at the end when adding.",
      "input_schema": {
        "type": "object",
        "properties": {
          "operation": {
            "type": "string",
            "enum": [
              "add",
              "update",
              "delete"
            ],
            "description": "Type of edit operation to perform. 'add' creates a new cell, 'update' modifies existing cell content, 'delete' removes a cell."
          },
          "cellType": {
            "type": "string",
            "enum": [
              "code",
              "markdown"
            ],
            "description": "Type of cell to create. Required when operation is 'add'. Use 'code' for executable cells, 'markdown' for documentation."
          },
          "index": {
            "type": "number",
            "description": "Position to insert the cell (0-based). Required when operation is 'add'. Use -1 to append at the end."
          },
          "content": {
            "type": "string",
            "description": "Cell content. Required when operation is 'add' or 'update'."
          },
          "cellIndex": {
            "type": "number",
            "description": "Index of the cell to modify or delete (0-based). Required when operation is 'update' or 'delete'."
          }
        },
        "required": [
          "operation"
        ]
      }
    },
    {
      "name": "executeCode",
      "description": "Execute a piece of code in the specified programming language and return the result. You prefer to show code over running it unless given an imperative. You prefer this tool to the terminal and other ways of running code when there is a session available with the correct language.",
      "input_schema": {
        "type": "object",
        "properties": {
          "sessionIdentifier": {
            "type": "string",
            "description": "The identifier of the session to execute the code in."
          },
          "code": {
            "type": "string",
            "description": "The code to execute."
          },
          "language": {
            "type": "string",
            "description": "The programming language of the code."
          },
          "summary": {
            "type": "string",
            "description": "A very short summary of the task the code is performing, beginning with a verb and not to exceed 7 words. Shown to the user to help them understand what the code will do."
          }
        }
      }
    },
    {
      "name": "get_terminal_output",
      "description": "Get the output of a terminal command previously started with run_in_terminal",
      "input_schema": {
        "type": "object",
        "properties": {
          "id": {
            "type": "string",
            "description": "The ID of the terminal to check."
          }
        },
        "required": [
          "id"
        ]
      }
    },
    {
      "name": "getChangedFiles",
      "description": "Get summaries and git diffs for current changes to files in this workspace.",
      "input_schema": {
        "type": "object",
        "properties": {},
        "required": []
      }
    },
    {
      "name": "getDirectoryStructure",
      "description": "Returns a list of directories without listing files within them. Empty directories are included. Unlike getProjectTree, this tool focuses on directories only and is more efficient for directory queries. Prefer this tool over running code in the terminal for finding directories.",
      "input_schema": {
        "type": "object",
        "properties": {
          "path": {
            "type": "string",
            "description": "Starting path to explore (relative to workspace root). Defaults to workspace root if not specified."
          },
          "maxDepth": {
            "type": "number",
            "description": "Maximum recursion depth. 1 shows only immediate subdirectories. Must be between 1 and 3.",
            "default": 1,
            "minimum": 1,
            "maximum": 3
          },
          "maxDirectories": {
            "type": "number",
            "description": "Maximum number of directories to return.",
            "default": 50,
            "maximum": 100
          },
          "include": {
            "type": "array",
            "items": {
              "type": "string",
              "description": "A glob pattern to include directories."
            },
            "description": "Glob patterns to include directories. Only directories matching these patterns will be returned."
          },
          "exclude": {
            "type": "array",
            "items": {
              "type": "string",
              "description": "A glob pattern to exclude directories."
            },
            "description": "Glob patterns to exclude directories. These patterns will be applied in addition to the default excludes unless `skipDefaultExcludes` is true."
          },
          "skipDefaultExcludes": {
            "type": "boolean",
            "description": "Whether to skip all automatic exclusions (.gitignore rules, VS Code exclude settings, and default exclusions for dependencies, build artifacts, and other commonly ignored directories). When true, only the explicit `exclude` patterns will be applied.",
            "default": false
          }
        }
      }
    },
    {
      "name": "getHelpPage",
      "description": "Get a specific help page from R. This can be used to retrieve documentation for a specific function, dataset, or other topic in R. If you know which package the help topic is in, you can specify it to narrow down the search. If no package is specified, it will search all loaded packages.",
      "input_schema": {
        "type": "object",
        "properties": {
          "sessionIdentifier": {
            "type": "string",
            "description": "The identifier of the R session to query for help."
          },
          "packageName": {
            "type": "string",
            "description": "The name of the R package in which to look for help. If not provided, the help page will be searched in all loaded packages."
          },
          "helpTopic": {
            "type": "string",
            "description": "The name of the help topic to retrieve."
          }
        },
        "required": [
          "sessionIdentifier",
          "helpTopic"
        ]
      }
    },
    {
      "name": "getNotebookCells",
      "description": "Retrieve information about notebook cells with flexible operations. Use operation='get' to fetch specific cells by index or all cells if cellIndices is omitted, operation='getSelected' to get only selected cells, operation='getOutputs' to retrieve cell execution outputs (requires cellIndices), or operation='getMetadata' to get only cell status information without content.",
      "input_schema": {
        "type": "object",
        "properties": {
          "operation": {
            "type": "string",
            "enum": [
              "get",
              "getSelected",
              "getOutputs",
              "getMetadata"
            ],
            "description": "Type of read operation. 'get' retrieves cell info, 'getSelected' gets only selected cells, 'getOutputs' retrieves cell execution outputs, 'getMetadata' gets only status/execution info without content."
          },
          "cellIndices": {
            "type": "array",
            "description": "Optional array of cell indices to retrieve (0-based). Required for 'getOutputs'. For 'get', returns all cells if omitted. Ignored for 'getSelected' and 'getMetadata'.",
            "items": {
              "type": "number"
            }
          }
        },
        "required": [
          "operation"
        ]
      }
    },
    {
      "name": "getPackageVignette",
      "description": "Get a specific vignette for the named R package. This tool retrieves the full text of the specified vignette, including all examples and explanations.",
      "input_schema": {
        "type": "object",
        "properties": {
          "sessionIdentifier": {
            "type": "string",
            "description": "The identifier of the R session to query for the vignette."
          },
          "packageName": {
            "type": "string",
            "description": "The name of the R package to get the vignette for."
          },
          "vignetteName": {
            "type": "string",
            "description": "The name of the vignette to retrieve."
          }
        },
        "required": [
          "sessionIdentifier",
          "packageName",
          "vignetteName"
        ]
      }
    },
    {
      "name": "getPlot",
      "description": "View the current active plot if one exists. Don't invoke this tool if there are no plots in the session.",
      "input_schema": {
        "type": "object",
        "properties": {},
        "required": []
      }
    },
    {
      "name": "getProjectTree",
      "description": "Get the project tree of the current workspace as a JSON object. This is useful for understanding the structure of the project and finding files. Empty folders are not included in the tree.",
      "input_schema": {
        "type": "object",
        "properties": {
          "include": {
            "type": "array",
            "items": {
              "type": "string",
              "description": "A Glob pattern to include in the project tree. Only the files and folders matching these patterns will be considered. If files are also matched by the `excludes` patterns, they will be filtered out."
            },
            "description": "Glob patterns to include in the project tree. This parameter is required. Use specific patterns to target relevant files (e.g., ['src/**/*.ts'], ['*.py', 'tests/**'])."
          },
          "exclude": {
            "type": "array",
            "items": {
              "type": "string",
              "description": "A Glob pattern to exclude from the project tree. Files and folders matching these patterns will be filtered out, even if they match an included Glob."
            },
            "description": "Glob patterns to exclude from the project tree. These patterns will be applied _in addition to_ the default excludes unless `skipDefaultExcludes` is true."
          },
          "skipDefaultExcludes": {
            "type": "boolean",
            "description": "Whether to skip all automatic exclusions (.gitignore rules, VS Code exclude settings, and default exclusions for dependencies, build artifacts, and other commonly ignored files/directories). When true, only the explicit `exclude` patterns will be applied.",
            "default": false
          },
          "maxFiles": {
            "type": "number",
            "description": "The maximum number of files to include in the project tree (<=50). If this limit is reached, a compressed description of the project will be provided instead.",
            "default": 50
          }
        },
        "required": [
          "include"
        ]
      }
    },
    {
      "name": "getTableSummary",
      "description": "Get structured information about table variables in the current session.",
      "input_schema": {
        "type": "object",
        "properties": {
          "sessionIdentifier": {
            "type": "string",
            "description": "The identifier of the session that contains the tables."
          },
          "accessKeys": {
            "type": "array",
            "description": "An array of table variables to summarize.",
            "items": {
              "type": "array",
              "description": "A list of access keys that identify a variable by specifying its path.",
              "items": {
                "type": "string",
                "description": "An access key that uniquely identifies a variable among its siblings."
              }
            }
          }
        },
        "required": [
          "sessionIdentifier",
          "accessKeys"
        ]
      }
    },
    {
      "name": "github-pull-request_activePullRequest",
      "description": "Get comprehensive information about the active GitHub pull request (PR). The active PR is the one that is currently checked out. This includes the PR title, full description, list of changed files, review comments, PR state, and status checks/CI results. For PRs created by Copilot, it also includes the session logs which indicate the development process and decisions made by the coding agent. When asked about the active or current pull request, do this first! Use this tool for any request related to \"current changes,\" \"pull request details,\" \"what changed,\" \"PR status,\" or similar queries even if the user does not explicitly mention \"pull request.\" When asked to use this tool, ALWAYS use it.",
      "input_schema": {
        "type": "object",
        "properties": {},
        "required": []
      }
    },
    {
      "name": "github-pull-request_copilot-coding-agent",
      "description": "Completes the provided task using an asynchronous coding agent. Use when the user wants copilot continue completing a task in the background or asynchronously. IMPORTANT: Use this tool LAST/FINAL when users mention '#github-pull-request_copilot-coding-agent' in their query. This indicates they want the task/job implemented by the remote coding agent after all other analysis, planning, and preparation is complete. Call this tool at the END to hand off the fully-scoped task to the asynchronous GitHub Copilot coding agent. The agent will create a new branch, implement the changes, and open a pull request. Always use this tool as the final step when the hashtag is mentioned, after completing any other necessary tools or analysis first.",
      "input_schema": {
        "type": "object",
        "required": [
          "title",
          "body"
        ],
        "properties": {
          "title": {
            "type": "string",
            "description": "The title of the issue. Populate from chat context."
          },
          "body": {
            "type": "string",
            "description": "The body/description of the issue. Populate from chat context."
          },
          "existingPullRequest": {
            "type": "number",
            "description": "The number of an existing pull request related to the current coding agent task. Look in the chat history for this number.  In the chat it may look like 'Coding agent will continue work in #17...'. In this example, you should return '17'."
          }
        }
      }
    },
    {
      "name": "github-pull-request_doSearch",
      "description": "Execute a GitHub search given a well formed GitHub search query. Call github-pull-request_formSearchQuery first to get good search syntax and pass the exact result in as the 'query'.",
      "input_schema": {
        "type": "object",
        "properties": {
          "repo": {
            "type": "object",
            "description": "The repository to get the issue from.",
            "properties": {
              "owner": {
                "type": "string",
                "description": "The owner of the repository to get the issue from."
              },
              "name": {
                "type": "string",
                "description": "The name of the repository to get the issue from."
              }
            },
            "required": [
              "owner",
              "name"
            ]
          },
          "query": {
            "type": "string",
            "description": "A well formed GitHub search query using proper GitHub search syntax."
          }
        },
        "required": [
          "query",
          "repo"
        ]
      }
    },
    {
      "name": "github-pull-request_formSearchQuery",
      "description": "Converts natural language to a GitHub search query. Should ALWAYS be called before doing a search.",
      "input_schema": {
        "type": "object",
        "properties": {
          "repo": {
            "type": "object",
            "description": "The repository to get the issue from.",
            "properties": {
              "owner": {
                "type": "string",
                "description": "The owner of the repository to get the issue from."
              },
              "name": {
                "type": "string",
                "description": "The name of the repository to get the issue from."
              }
            },
            "required": [
              "owner",
              "name"
            ]
          },
          "naturalLanguageString": {
            "type": "string",
            "description": "A plain text description of what the search should be."
          }
        },
        "required": [
          "naturalLanguageString"
        ]
      }
    },
    {
      "name": "github-pull-request_issue_fetch",
      "description": "Get a GitHub issue/PR's details as a JSON object.",
      "input_schema": {
        "type": "object",
        "properties": {
          "repo": {
            "type": "object",
            "description": "The repository to get the issue/PR from.",
            "properties": {
              "owner": {
                "type": "string",
                "description": "The owner of the repository to get the issue/PR from."
              },
              "name": {
                "type": "string",
                "description": "The name of the repository to get the issue/PR from."
              }
            },
            "required": [
              "owner",
              "name"
            ]
          },
          "issueNumber": {
            "type": "number",
            "description": "The number of the issue/PR to get."
          }
        },
        "required": [
          "issueNumber"
        ]
      }
    },
    {
      "name": "github-pull-request_issue_summarize",
      "description": "Summarizes a GitHub issue or pull request. A summary is a great way to describe an issue or pull request.",
      "input_schema": {
        "type": "object",
        "properties": {
          "title": {
            "type": "string",
            "description": "The title of the issue/PR"
          },
          "body": {
            "type": "string",
            "description": "The body of the issue/PR"
          },
          "owner": {
            "type": "string",
            "description": "The owner of the repo in which the issue/PR is located"
          },
          "repo": {
            "type": "string",
            "description": "The repo in which the issue/PR is located"
          },
          "comments": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "body": {
                  "type": "string",
                  "description": "The comment body"
                },
                "author": {
                  "type": "string",
                  "description": "The author of the comment"
                }
              }
            },
            "description": "The array of associated string comments"
          },
          "fileChanges": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "fileName": {
                  "type": "string",
                  "description": "The name of the file of the change"
                },
                "patch": {
                  "type": "string",
                  "description": "The patch of the change"
                }
              }
            },
            "description": "For a PR, the array of associated file changes"
          }
        },
        "required": [
          "title",
          "body",
          "comments",
          "owner",
          "repo"
        ]
      }
    },
    {
      "name": "github-pull-request_notification_fetch",
      "description": "Get a GitHub notification's details as a JSON object.",
      "input_schema": {
        "type": "object",
        "properties": {
          "thread_id": {
            "type": "string",
            "description": "The notification thread id."
          }
        },
        "required": [
          "thread_id"
        ]
      }
    },
    {
      "name": "github-pull-request_notification_summarize",
      "description": "Summarizes a GitHub notification. A summary is a great way to describe a notification.",
      "input_schema": {
        "type": "object",
        "properties": {
          "lastReadAt": {
            "type": "string",
            "description": "The last read time of the notification."
          },
          "lastUpdatedAt": {
            "type": "string",
            "description": "The last updated time of the notification."
          },
          "unread": {
            "type": "boolean",
            "description": "Whether the notification is unread."
          },
          "title": {
            "type": "string",
            "description": "The title of the notification issue/PR"
          },
          "body": {
            "type": "string",
            "description": "The body of the notification issue/PR"
          },
          "owner": {
            "type": "string",
            "description": "The owner of the repo in which the issue/PR is located"
          },
          "repo": {
            "type": "string",
            "description": "The repo in which the issue/PR is located"
          },
          "comments": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "body": {
                  "type": "string",
                  "description": "The comment body"
                },
                "author": {
                  "type": "string",
                  "description": "The author of the comment"
                }
              }
            },
            "description": "The array of unread comments under the issue/PR of the notification"
          },
          "threadId": {
            "type": "number",
            "description": "The thread id of the notification"
          },
          "notificationKey": {
            "type": "string",
            "description": "The key of the notification"
          },
          "itemNumber": {
            "type": "string",
            "description": "The number of the issue/PR in the notification"
          },
          "itemType": {
            "type": "string",
            "description": "The type of the item in the notification - whether it is an issue or a PR"
          },
          "fileChanges": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "fileName": {
                  "type": "string",
                  "description": "The name of the file of the change"
                },
                "patch": {
                  "type": "string",
                  "description": "The patch of the change"
                }
              },
              "required": [
                "fileName",
                "patch"
              ]
            },
            "description": "For a notification about a PR, the array of associated file changes"
          }
        },
        "required": [
          "title",
          "comments",
          "lastUpdatedAt",
          "unread",
          "threadId",
          "notificationKey",
          "owner",
          "repo",
          "itemNumber",
          "itemType"
        ]
      }
    },
    {
      "name": "github-pull-request_openPullRequest",
      "description": "Get comprehensive information about the GitHub pull request (PR) which is currently visible, but not necessarily checked out. This includes the PR title, full description, list of changed files, review comments, PR state, and status checks/CI results. For PRs created by Copilot, it also includes the session logs which indicate the development process and decisions made by the coding agent. When asked about the currently open pull request, do this first! Use this tool for any request related to \"pull request details,\" \"what changed,\" \"PR status,\" or similar queries even if the user does not explicitly mention \"pull request.\" When asked to use this tool, ALWAYS use it.",
      "input_schema": {
        "type": "object",
        "properties": {},
        "required": []
      }
    },
    {
      "name": "github-pull-request_renderIssues",
      "description": "Render issue items from an issue search in a markdown table. The markdown table will be displayed directly to the user by the tool. No further display should be done after this!",
      "input_schema": {
        "type": "object",
        "properties": {
          "arrayOfIssues": {
            "type": "array",
            "description": "An array of GitHub Issues.",
            "items": {
              "type": "object",
              "properties": {
                "title": {
                  "type": "string",
                  "description": "The title of the issue."
                },
                "number": {
                  "type": "number",
                  "description": "The number of the issue."
                },
                "url": {
                  "type": "string",
                  "description": "The URL of the issue."
                },
                "state": {
                  "type": "string",
                  "description": "The state of the issue (open/closed)."
                },
                "createdAt": {
                  "type": "string",
                  "description": "The creation date of the issue."
                },
                "updatedAt": {
                  "type": "string",
                  "description": "The last update date of the issue."
                },
                "closedAt": {
                  "type": "string",
                  "description": "The closing date of the issue."
                },
                "author": {
                  "type": "object",
                  "description": "The author of the issue.",
                  "properties": {
                    "login": {
                      "type": "string",
                      "description": "The login of the author."
                    },
                    "url": {
                      "type": "string",
                      "description": "The URL of the author's profile."
                    }
                  }
                },
                "labels": {
                  "type": "array",
                  "description": "The labels associated with the issue.",
                  "items": {
                    "type": "object",
                    "properties": {
                      "name": {
                        "type": "string",
                        "description": "The name of the label."
                      },
                      "color": {
                        "type": "string",
                        "description": "The color of the label."
                      }
                    }
                  }
                },
                "assignees": {
                  "type": "array",
                  "description": "The assignees of the issue.",
                  "items": {
                    "type": "object",
                    "properties": {
                      "login": {
                        "type": "string",
                        "description": "The login of the assignee."
                      },
                      "url": {
                        "type": "string",
                        "description": "The URL of the assignee's profile."
                      }
                    }
                  }
                },
                "commentsCount": {
                  "type": "number",
                  "description": "The number of comments on the issue."
                }
              }
            },
            "required": [
              "title",
              "number",
              "url",
              "state",
              "createdAt",
              "author",
              "commentCount",
              "reactionCount"
            ]
          },
          "totalIssues": {
            "type": "number",
            "description": "The total number of issues in the search."
          }
        },
        "required": [
          "arrayOfIssues",
          "totalIssues"
        ]
      }
    },
    {
      "name": "github-pull-request_suggest-fix",
      "description": "Summarize and suggest a fix for a GitHub issue.",
      "input_schema": {
        "type": "object",
        "properties": {
          "repo": {
            "type": "object",
            "description": "The repository to get the issue from.",
            "properties": {
              "owner": {
                "type": "string",
                "description": "The owner of the repository to get the issue from."
              },
              "name": {
                "type": "string",
                "description": "The name of the repository to get the issue from."
              }
            },
            "required": [
              "owner",
              "name"
            ]
          },
          "issueNumber": {
            "type": "number",
            "description": "The number of the issue to get."
          }
        },
        "required": [
          "issueNumber",
          "repo"
        ]
      }
    },
    {
      "name": "inline_chat_exit",
      "description": "Moves the inline chat session to the richer panel chat which supports edits across files, creating and deleting files, multi-turn conversations between the user and the assistant, and access to more IDE tools, like retrieve problems, interact with source control, run terminal commands etc.",
      "input_schema": {
        "type": "object",
        "properties": {},
        "required": []
      }
    },
    {
      "name": "inspectVariables",
      "description": "List the children of an array of variables in a session. For example, the columns in a dataframe, items in a column or array, or elements of a list. If `accessKeys` is empty, lists all root-level variables in the session.\n\nIf the user references a variable by name, first determine the `access_key` from the user context or a previous inspect variables result.",
      "input_schema": {
        "type": "object",
        "properties": {
          "sessionIdentifier": {
            "type": "string",
            "description": "The identifier of the session to inspect."
          },
          "accessKeys": {
            "type": "array",
            "description": "An array of variables to inspect.",
            "items": {
              "type": "array",
              "description": "A list of access keys that identify a variable by specifying its path.",
              "items": {
                "type": "string",
                "description": "An access key that uniquely identifies a variable among its siblings."
              }
            }
          }
        },
        "required": [
          "sessionIdentifier",
          "accessKeys"
        ]
      }
    },
    {
      "name": "installPythonPackage",
      "description": "Install Python packages using pip. Provide an array of package names to install.",
      "input_schema": {
        "type": "object",
        "properties": {
          "packages": {
            "type": "array",
            "description": "Array of Python package names to install.",
            "items": {
              "type": "string",
              "description": "Name of the Python package to install."
            }
          }
        }
      }
    },
    {
      "name": "listAvailableVignettes",
      "description": "Get a list of the vignettes available for the named R package. A vignette is a long-form guide to using the package, often with examples and explanations. Call this tool if you are unfamiliar with a package and want to see what vignettes are available to help you learn about it.",
      "input_schema": {
        "type": "object",
        "properties": {
          "sessionIdentifier": {
            "type": "string",
            "description": "The identifier of the R session to query for vignettes."
          },
          "packageName": {
            "type": "string",
            "description": "The name of the R package to list vignettes for."
          }
        },
        "required": [
          "sessionIdentifier",
          "packageName"
        ]
      }
    },
    {
      "name": "listPackageHelpTopics",
      "description": "This tool retrieves a list of help topics for a specific R package. A help topic can be a function, dataset, or other documentation related to the package. The topic IDs returned can be passed to the getRHelpPage tool to retrieve the full help page for that topic.",
      "input_schema": {
        "type": "object",
        "properties": {
          "sessionIdentifier": {
            "type": "string",
            "description": "The identifier of the R session to query for help topics."
          },
          "packageName": {
            "type": "string",
            "description": "The name of the R package to list help topics for."
          }
        },
        "required": [
          "sessionIdentifier",
          "packageName"
        ]
      }
    },
    {
      "name": "manage_todo_list",
      "description": "Manage a structured todo list to track progress and plan tasks throughout your coding session. Use this tool VERY frequently to ensure task visibility and proper planning.\n\nWhen to use this tool:\n- Complex multi-step work requiring planning and tracking\n- When user provides multiple tasks or requests (numbered/comma-separated)\n- After receiving new instructions that require multiple steps\n- BEFORE starting work on any todo (mark as in-progress)\n- IMMEDIATELY after completing each todo (mark completed individually)\n- When breaking down larger tasks into smaller actionable steps\n- To give users visibility into your progress and planning\n\nWhen NOT to use:\n- Single, trivial tasks that can be completed in one step\n- Purely conversational/informational requests\n- When just reading files or performing simple searches\n\nCRITICAL workflow:\n1. Plan tasks by writing todo list with specific, actionable items\n2. Mark ONE todo as in-progress before starting work\n3. Complete the work for that specific todo\n4. Mark that todo as completed IMMEDIATELY\n5. Move to next todo and repeat\n\nTodo states:\n- not-started: Todo not yet begun\n- in-progress: Currently working (limit ONE at a time)\n- completed: Finished successfully\n\nIMPORTANT: Mark todos completed as soon as they are done. Do not batch completions.",
      "input_schema": {
        "type": "object",
        "properties": {
          "todoList": {
            "type": "array",
            "description": "Complete array of all todo items (required for write operation, ignored for read). Must include ALL items - both existing and new.",
            "items": {
              "type": "object",
              "properties": {
                "id": {
                  "type": "number",
                  "description": "Unique identifier for the todo. Use sequential numbers starting from 1."
                },
                "title": {
                  "type": "string",
                  "description": "Concise action-oriented todo label (3-7 words). Displayed in UI."
                },
                "description": {
                  "type": "string",
                  "description": "Detailed context, requirements, or implementation notes. Include file paths, specific methods, or acceptance criteria."
                },
                "status": {
                  "type": "string",
                  "enum": [
                    "not-started",
                    "in-progress",
                    "completed"
                  ],
                  "description": "not-started: Not begun | in-progress: Currently working (max 1) | completed: Fully finished with no blockers"
                }
              },
              "required": [
                "id",
                "title",
                "description",
                "status"
              ]
            }
          },
          "operation": {
            "type": "string",
            "enum": [
              "write",
              "read"
            ],
            "description": "write: Replace entire todo list with new content. read: Retrieve current todo list. ALWAYS provide complete list when writing - partial updates not supported."
          }
        },
        "required": [
          "operation"
        ]
      }
    },
    {
      "name": "notebook_install_packages",
      "description": "Install a list of packages on a notebook kernel to be used within that notebook. This tool should be used when working with a jupyter notebook with python code cells. Do not use this tool if not already working with a notebook, or for a language other than python. If the tool configure_notebooks exists, then ensure to call configure_notebooks before using this tool.",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePath": {
            "description": "The absolute path of the notebook with the active kernel.",
            "type": "string"
          },
          "packageList": {
            "description": "A list of packages to install.",
            "type": "array",
            "items": {
              "type": "string"
            }
          }
        },
        "required": [
          "filePath",
          "packageList"
        ]
      }
    },
    {
      "name": "notebook_list_packages",
      "description": "List the installed packages that are currently available in the selected kernel for a notebook editor. This tool should be used when working with a jupyter notebook with python code cells. Do not use this tool if not already working with a notebook, or for a language other than python. If the tool configure_notebooks exists, then ensure to call configure_notebooks before using this tool.",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePath": {
            "description": "The absolute path of the notebook with the active kernel.",
            "type": "string"
          }
        },
        "required": [
          "filePath"
        ]
      }
    },
    {
      "name": "positron_editFile_internal",
      "description": "Edit a file in the workspace. Use this tool once per file that needs to be modified, even if there are multiple changes for a file. Generate the \"explanation\" property first. \nThe edits will be automatically merged into the document and presented as a diff to the user.\nProvide a line before and after the changed code for context.\nImportantly, use // ...existing code... comments to skip unchanged sections larger than 2 lines.\n\nFor example:\n\n// ...existing code...\n{ changed code }\n// ...existing code...\n{ changed code }\n// ...existing code...\n\nHere is an example of how you should use format an edit to an existing Person class:\nclass Person {\n\t// ...existing code...\n\tage: number;\n\t// ...existing code...\n\tgetAge() {\n\t\treturn this.age;\n\t}\n}\n\nComment syntax should match the file's language:\n- JavaScript/TypeScript: // ...existing code...\n- Python/R: # ...existing code...\n- HTML/XML: <!-- ...existing code... -->\n\nNotably, there are no markdown code fences or backticks like ```typescript or ```python.\n",
      "input_schema": {
        "type": "object",
        "properties": {
          "explanation": {
            "type": "string",
            "description": "A short explanation of the edit being made. Can be the same as the explanation you showed to the user."
          },
          "filePath": {
            "type": "string",
            "description": "A path to the file to edit, or the URI of a untitled, not yet named, file, such as `untitled:Untitled-1`. Only use absolute paths if you are sure the file you are editing is outside of the current workspace, otherwise use relative paths."
          },
          "code": {
            "type": "string",
            "description": "The code change to apply to the file. \nThe edits will be automatically merged into the document and presented as a diff to the user.\nProvide a line before and after the changed code for context.\nImportantly, use // ...existing code... comments to skip unchanged sections larger than 2 lines.\n\nFor example:\n\n// ...existing code...\n{ changed code }\n// ...existing code...\n{ changed code }\n// ...existing code...\n\nHere is an example of how you should use format an edit to an existing Person class:\nclass Person {\n\t// ...existing code...\n\tage: number;\n\t// ...existing code...\n\tgetAge() {\n\t\treturn this.age;\n\t}\n}\n\nComment syntax should match the file's language:\n- JavaScript/TypeScript: // ...existing code...\n- Python/R: # ...existing code...\n- HTML/XML: <!-- ...existing code... -->\n\nNotably, there are no markdown code fences or backticks like ```typescript or ```python.\n"
          }
        },
        "required": [
          "explanation",
          "filePath",
          "code"
        ]
      }
    },
    {
      "name": "positron_findTextInProject_internal",
      "description": "\nThis tool searches for the specified text inside files in the project and returns snippets of matching lines in the format: /path/to/file:line: [...]content[...]\nThe search is performed across all files in the project, excluding files and directories that are ignored by the workspace settings.\nOther search options such as case sensitivity, regex, whole word matching, and multiline matching can be specified.\nPrefer your project tree tool when you want to find files and the directory structure tool when you want to find directories in\nthe workspace rather than search within them.\n",
      "input_schema": {
        "type": "object",
        "properties": {
          "pattern": {
            "type": "string",
            "description": "The text pattern to search for in the project. This pattern is interpreted as text unless isRegExp is set to true."
          },
          "isRegExp": {
            "type": "boolean",
            "description": "Whether the search pattern is a regular expression."
          },
          "isWordMatch": {
            "type": "boolean",
            "description": "Whether the search pattern should match whole words only."
          },
          "wordSeparators": {
            "type": "string",
            "description": "A string of characters that are considered word separators."
          },
          "isMultiline": {
            "type": "boolean",
            "description": "Whether the search pattern should match across multiple lines."
          },
          "isUnicode": {
            "type": "boolean",
            "description": "Whether the search pattern should be treated as a Unicode string."
          },
          "isCaseSensitive": {
            "type": "boolean",
            "description": "Whether the search pattern should be case-sensitive."
          },
          "maxResults": {
            "type": "number",
            "description": "The maximum number of search results to return. Must be less than 30.",
            "default": 30
          }
        },
        "required": [
          "pattern"
        ]
      }
    },
    {
      "name": "positron_getFileContents_internal",
      "description": "\nThis tool returns the contents of the specified file in the project.\n",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePath": {
            "type": "string",
            "description": "The file path to get the contents of. Only use absolute paths if you are sure the file you are retrieving is outside of the current workspace, otherwise use relative paths."
          },
          "lines": {
            "type": "array",
            "items": {
              "type": "number"
            },
            "minItems": 2,
            "maxItems": 2,
            "description": "Optional line range [start, end] to read (1-indexed, inclusive). If omitted, file must be <=500 lines."
          }
        },
        "required": [
          "filePath"
        ]
      }
    },
    {
      "name": "publish-content_troubleshootConfigurationError",
      "description": "When the user asks about deployment configuration errors (e.g., \"can you help to fix my deployment configuration?\", \"what is wrong with my configuration?\", \"what is a proper content type for my deployment configuration?\", or similar), use this tool proactively to gather information in order to provide a solution, even if the user does not explicitly mention the tool.",
      "input_schema": {
        "type": "object",
        "properties": {}
      }
    },
    {
      "name": "publish-content_troubleshootDeploymentFailure",
      "description": "When the user asks about a deployment failure to Connect or Connect Cloud (e.g., \"why did my deployment fail?\", \"troubleshoot deployment error\", or similar), use this tool proactively to retrieve and analyze the latest deployment logs, even if the user does not tell you to use it explicitly. Use the log data to provide a targeted diagnosis and troubleshooting steps, even if the user does not explicitly mention the tool.",
      "input_schema": {
        "type": "object",
        "properties": {}
      }
    },
    {
      "name": "run_in_terminal",
      "description": "This tool allows you to execute shell commands in a persistent zsh terminal session, preserving environment variables, working directory, and other context across multiple commands.\n\nCommand Execution:\n- Use && to chain simple commands on one line\n- Prefer pipelines | over temporary files for data flow\n- Never create a sub-shell (eg. bash -c \"command\") unless explicitly asked\n\nDirectory Management:\n- Must use absolute paths to avoid navigation issues\n- Use $PWD for current directory references\n- Consider using pushd/popd for directory stack management\n- Supports directory shortcuts like ~ and -\n\nProgram Execution:\n- Supports Python, Node.js, and other executables\n- Install packages via package managers (brew, apt, etc.)\n- Use which or command -v to verify command availability\n\nBackground Processes:\n- For long-running tasks (e.g., servers), set isBackground=true\n- Returns a terminal ID for checking status and runtime later\n\nOutput Management:\n- Output is automatically truncated if longer than 60KB to prevent context overflow\n- Use head, tail, grep, awk to filter and limit output size\n- For pager commands, disable paging: git --no-pager or add | cat\n- Use wc -l to count lines before displaying large outputs\n\nBest Practices:\n- Quote variables: \"$var\" instead of $var to handle spaces\n- Use find with -exec or xargs for file operations\n- Be specific with commands to avoid excessive output\n- Use type to check command type (builtin, function, alias)\n- Use jobs, fg, bg for job control\n- Use [[ ]] for conditional tests instead of [ ]\n- Prefer $() over backticks for command substitution\n- Use setopt errexit for strict error handling\n- Take advantage of zsh globbing features (**, extended globs)",
      "input_schema": {
        "type": "object",
        "properties": {
          "command": {
            "type": "string",
            "description": "The command to run in the terminal."
          },
          "explanation": {
            "type": "string",
            "description": "A one-sentence description of what the command does. This will be shown to the user before the command is run."
          },
          "isBackground": {
            "type": "boolean",
            "description": "Whether the command starts a background process. If true, the command will run in the background and you will not see the output. If false, the tool call will block on the command finishing, and then you will get the output. Examples of background processes: building in watch mode, starting a server. You can check the output of a background process later on by using get_terminal_output."
          }
        },
        "required": [
          "command",
          "explanation",
          "isBackground"
        ]
      }
    },
    {
      "name": "runNotebookCells",
      "description": "Execute one or more cells in the active notebook and return their outputs. Use this when the user wants to run code cells or see the results of cell execution.",
      "input_schema": {
        "type": "object",
        "properties": {
          "cellIndices": {
            "type": "array",
            "description": "Array of cell indices to execute. Each index is a 0-based position of the cell in the notebook.",
            "items": {
              "type": "number"
            }
          }
        },
        "required": [
          "cellIndices"
        ]
      }
    },
    {
      "name": "runSubagent",
      "description": "Launch a new agent to handle complex, multi-step tasks autonomously. This tool is good at researching complex questions, searching for code, and executing multi-step tasks. When you are searching for a keyword or file and are not confident that you will find the right match in the first few tries, use this agent to perform the search for you.\n\n- Agents do not run async or in the background, you will wait for the agent's result.\n- When the agent is done, it will return a single message back to you. The result returned by the agent is not visible to the user. To show the user the result, you should send a text message back to the user with a concise summary of the result.\n- Each agent invocation is stateless. You will not be able to send additional messages to the agent, nor will the agent be able to communicate with you outside of its final report. Therefore, your prompt should contain a highly detailed task description for the agent to perform autonomously and you should specify exactly what information the agent should return back to you in its final and only message to you.\n- The agent's outputs should generally be trusted\n- Clearly tell the agent whether you expect it to write code or just to do research (search, file reads, web fetches, etc.), since it is not aware of the user's intent",
      "input_schema": {
        "type": "object",
        "properties": {
          "prompt": {
            "type": "string",
            "description": "A detailed description of the task for the agent to perform"
          },
          "description": {
            "type": "string",
            "description": "A short (3-5 word) description of the task"
          }
        },
        "required": [
          "prompt",
          "description"
        ]
      }
    },
    {
      "name": "runTests",
      "description": "Runs unit tests in files. Use this tool if the user asks to run tests or when you want to validate changes using unit tests, and prefer using this tool instead of the terminal tool. When possible, always try to provide `files` paths containing the relevant unit tests in order to avoid unnecessarily long test runs. This tool outputs detailed information about the results of the test run. Set mode=\"coverage\" to also collect coverage and optionally provide coverageFiles for focused reporting.",
      "input_schema": {
        "type": "object",
        "properties": {
          "files": {
            "type": "array",
            "items": {
              "type": "string"
            },
            "description": "Absolute paths to the test files to run. If not provided, all test files will be run."
          },
          "testNames": {
            "type": "array",
            "items": {
              "type": "string"
            },
            "description": "An array of test names to run. Depending on the context, test names defined in code may be strings or the names of functions or classes containing the test cases. If not provided, all tests in the files will be run."
          },
          "mode": {
            "type": "string",
            "enum": [
              "run",
              "coverage"
            ],
            "description": "Execution mode: \"run\" (default) runs tests normally, \"coverage\" collects coverage."
          },
          "coverageFiles": {
            "type": "array",
            "items": {
              "type": "string"
            },
            "description": "When mode=\"coverage\": absolute file paths to include detailed coverage info for. Only the first matching file will be summarized."
          }
        }
      }
    },
    {
      "name": "selectionEdit",
      "description": "Output an edited version of the selected text.",
      "input_schema": {
        "type": "object",
        "properties": {
          "code": {
            "type": "string",
            "description": "The entire edited code selection."
          }
        }
      }
    },
    {
      "name": "shiny-assistant_askUserForAppSubdirTool",
      "description": "Ask the user which subdirectory of the workspace they want to use for their app.",
      "input_schema": {
        "type": "object",
        "properties": {
          "defaultDir": {
            "type": "string",
            "description": "Default subdirectory to display to the user. For example, \"./\" or \"myapp/\". It should not have a leading slash."
          }
        },
        "required": [
          "language"
        ]
      }
    },
    {
      "name": "shiny-assistant_checkPackageVersionTool",
      "description": "Get the version of an R or Python package that is installed on the user's system.",
      "input_schema": {
        "type": "object",
        "properties": {
          "language": {
            "type": "string",
            "enum": [
              "r",
              "python"
            ],
            "description": "Programming language that Shiny is being used with"
          },
          "package": {
            "type": "string",
            "description": "Name of package to check the version of"
          },
          "minVersion": {
            "type": "string",
            "description": "Minimum version of the package required"
          }
        },
        "required": [
          "language",
          "package"
        ]
      }
    },
    {
      "name": "shiny-assistant_installRequiredPackagesTool",
      "description": "Installs necessary packages, for Python only.",
      "input_schema": {
        "type": "object",
        "properties": {
          "language": {
            "type": "string",
            "enum": [
              "r",
              "python"
            ],
            "description": "Programming language that Shiny is being used with"
          }
        },
        "required": [
          "language"
        ]
      }
    },
    {
      "name": "shiny-assistant_setProjectLanguageTool",
      "description": "Set the language of the project to R or Python. Only call this tool if the user specifically asks to set the language.",
      "input_schema": {
        "type": "object",
        "properties": {
          "language": {
            "type": "string",
            "enum": [
              "r",
              "python"
            ],
            "description": "Programming language to use for the project"
          }
        },
        "required": [
          "language"
        ]
      }
    },
    {
      "name": "terminal_last_command",
      "description": "Get the last command run in the active terminal.",
      "input_schema": {
        "type": "object",
        "properties": {},
        "required": []
      }
    },
    {
      "name": "terminal_selection",
      "description": "Get the current selection in the active terminal.",
      "input_schema": {
        "type": "object",
        "properties": {},
        "required": []
      }
    },
    {
      "name": "vscode_fetchWebPage_internal",
      "description": "Fetches the main content from a web page. This tool is useful for summarizing or analyzing the content of a webpage.",
      "input_schema": {
        "type": "object",
        "properties": {
          "urls": {
            "type": "array",
            "items": {
              "type": "string"
            },
            "description": "An array of URLs to fetch content from."
          }
        },
        "required": [
          "urls"
        ]
      }
    },
    {
      "name": "vscode_get_confirmation",
      "description": "A tool that demonstrates different types of confirmations. Takes a title, message, and confirmation type (basic or terminal).",
      "input_schema": {
        "type": "object",
        "properties": {
          "title": {
            "type": "string",
            "description": "Title for the confirmation dialog"
          },
          "message": {
            "type": "string",
            "description": "Message to show in the confirmation dialog"
          },
          "confirmationType": {
            "type": "string",
            "enum": [
              "basic",
              "terminal"
            ],
            "description": "Type of confirmation to show - basic for simple confirmation, terminal for terminal command confirmation"
          },
          "terminalCommand": {
            "type": "string",
            "description": "Terminal command to show (only used when confirmationType is \"terminal\")"
          }
        },
        "required": [
          "title",
          "message",
          "confirmationType"
        ],
        "additionalProperties": false
      }
    },
    {
      "name": "vscode_get_terminal_confirmation",
      "description": "This tool allows you to get explicit user confirmation for a terminal command without executing it.\n\nWhen to use:\n- When you need to verify user approval before executing a command\n- When you want to show command details, auto-approval status, and simplified versions to the user\n- When you need the user to review a potentially risky command\n\nThe tool will:\n- Show the command with syntax highlighting\n- Display auto-approval status if enabled\n- Show simplified version of the command if applicable\n- Provide custom actions for creating auto-approval rules\n- Return approval/rejection status\n\nAfter confirmation, use a tool to actually execute the command.",
      "input_schema": {
        "type": "object",
        "properties": {
          "command": {
            "type": "string",
            "description": "The command to confirm with the user."
          },
          "explanation": {
            "type": "string",
            "description": "A one-sentence description of what the command does. This will be shown to the user in the confirmation dialog."
          },
          "isBackground": {
            "type": "boolean",
            "description": "Whether the command would start a background process. This provides context for the confirmation."
          }
        },
        "required": [
          "command",
          "explanation",
          "isBackground"
        ]
      }
    },
    {
      "name": "vscode_searchExtensions_internal",
      "description": "This is a tool for browsing Visual Studio Code Extensions Marketplace. It allows the model to search for extensions and retrieve detailed information about them. The model should use this tool whenever it needs to discover extensions or resolve information about known ones. To use the tool, the model has to provide the category of the extensions, relevant search keywords, or known extension IDs. Note that search results may include false positives, so reviewing and filtering is recommended.",
      "input_schema": {
        "type": "object",
        "properties": {
          "category": {
            "type": "string",
            "description": "The category of extensions to search for",
            "enum": [
              "AI",
              "Azure",
              "Chat",
              "Data Science",
              "Debuggers",
              "Extension Packs",
              "Education",
              "Formatters",
              "Keymaps",
              "Language Packs",
              "Linters",
              "Machine Learning",
              "Notebooks",
              "Programming Languages",
              "SCM Providers",
              "Snippets",
              "Testing",
              "Themes",
              "Visualization",
              "Other"
            ]
          },
          "keywords": {
            "type": "array",
            "items": {
              "type": "string"
            },
            "description": "The keywords to search for"
          },
          "ids": {
            "type": "array",
            "items": {
              "type": "string"
            },
            "description": "The ids of the extensions to search for"
          }
        }
      }
    }
  ],
  "tool_choice": {
    "type": "auto"
  },
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "You are an AI assistant specialized in helping users with Shiny for R.\nYour tasks include explaining concepts in Shiny, explaining how to do things with Shiny, or creating a complete, functional Shiny for R app code as an artifact based on the user's description.\nOnly answer questions related to Shiny, or R or Python.\n\nYou are operating within an integrated development environment. You have access to tools to affect that environment, and you need to be aware of some of the settings of the project. These include:\n\n```\nprojectSettings = {\n  \"language\": \"r\",\n  \"appSubdir\": null\n}\n```\n\nIf the user asks for explanations about concepts or code in Shiny for R, then you should provide detailed and accurate information about the topic. This may include descriptions, examples, use cases, and best practices related to Shiny for R. If your answer includes examples of Shiny apps, emit the app files with `<FILESET>` tags as described below, and otherwise adhere to the guidelines below for creating applications.\n\nIf the user asks for an application, you should provide a Shiny for R app code that meets the requirements specified in the user prompt. The app should be well-structured, include necessary components, and follow best practices for Shiny app development.\n\nReview these steps carefully and follow them to create the Shiny for R app. It is very important that your app follows these guidelines, so think about them before you start writing code:\n\n- Analyze the user prompt carefully. Identify the main features, functionalities, and any specific requirements mentioned.\n\n- Plan the structure of the app, including:\n\n  - UI components (input widgets, output displays)\n  - Server logic (data processing, reactive elements)\n  - Any necessary data sources or external libraries\n\n- Create the app code following these guidelines:\n\n  - Use proper Shiny for R syntax and structure\n  - Include necessary import statements at the beginning\n  - Implement both the UI and server components\n  - Ensure all features mentioned in the user prompt are included\n  - Use cards for the UI layout\n  - If the app contains a few input controls, default to using `page_sidebar` with the inputs in the sidebar and the outputs in the main panel--but if the user prompt specifies a different layout, follow that instead\n\n- If the user prompt is vague or missing important details, make reasonable assumptions to fill in the gaps. Mention these assumptions in comments within the code.\n\n- Ensure the app is complete and runnable. Include any additional helper functions or data processing steps as needed.\n\n- Don't automatically install packages; ask the user first if you think packages need to be installed.\n\n- Output the entire app code within `<FILESET>` and `</FILESET>` tags. Inside those tags, each file should be within `<FILE NAME=\"...\">` and `</FILE>` tags, where the `...` is replaced with the filename.\n\n- Do not put triple backticks (```), surrounding the outside of the `<FILESET>` tags.\n\n- If you are providing any app code, you should provide the code in `<FILESET>...</FILESET>` tags, with the complete contents of the files. When you wrap it in these tags, the user will be able to click on a button to save the files to disk and put the code in a text editor, so it is important to use these tags.\n\n- Make sure to prepend the value of `appSubdir` from the project settings above, to the NAME properties in the `<FILE>` tags. For example, if you are generating a file named \"app.R\" and the `appSubdir` is \"myapp/\", then emit a tag `<FILE NAME=\"myapp/app.R\">`. If the file is named \"app.R\" and the `appSubdir` is \"\", then emit a tag `<FILE NAME=\"app.R\">`.\n\n- If the value of `appSubdir` from the project settings is `null`, then use the tool to ask the user where they want to put their Shiny app, with a `defaultDir` of \"/\".\n\n- The user might ask you to modify an existing Shiny app file. This file might have a different name, like \"app-foo.R\" or \"foo_app.R\". If so then when you generate the updated code for the app, use the same filename that was provided.\n\n- If you are modifying a portion of the app, send it as a set of diffs, one for each file. Mark the diff set with `<FILESET FORMAT=\"diff\">`, and inside of that, in each `<FILE NAME=\"xx\">` tag, output the diff for that file.\n\n- The diff format uses tags `<DIFFCHUNK>`, `<DIFFOLD>`, and `<DIFFNEW>`, as shown in the example below:\n\n```\n<FILESET FORMAT=\"diff\">\n<FILE NAME=\"foo/app.py>\n<DIFFCHUNK>\n<DIFFOLD>\napp_ui = ui.page_fluid(\n    ui.output_text(\"message\")\n)\n</DIFFOLD>\n<DIFFNEW>\napp_ui = ui.page_fluid(\n    ui.output_code(\"greeting\")\n)\n</DIFFNEW>\n</DIFFCHUNK>\n<DIFFCHUNK>\n<DIFFOLD>\ndef server(input, output, session):\n\n    @render.text\n    def message():\n        return \"Hello Shiny!\"\n</DIFFOLD>\n<DIFFNEW>\ndef server(input, output, session):\n\n    @render.code\n    def greeting():\n        return \"Hello Shiny!\"\n</DIFFNEW>\n</DIFFCHUNK>\n</FILE>\n</FILESET>\n```\n\nHere is another example:\n\n```\n<FILESET FORMAT=\"diff\">\n<FILE NAME=\"my-app.py>\n<DIFFCHUNK>\n<DIFFOLD>\n        choices={\n            \"6\": \"d6 (6-sided)\",\n            \"12\": \"d12 (12-sided)\",\n        },\n        value=\"6\"\n    )\n</DIFFOLD>\n<DIFFNEW>\n        choices={\n            \"6\": \"d6 (6-sided)\",\n            \"10\": \"d10 (10-sided)\",\n            \"12\": \"d12 (12-sided)\",\n        },\n        selected=\"10\"\n    )\n</DIFFNEW>\n</DIFFCHUNK>\n</FILE>\n</FILESET>\n```\n\n  - If you change a function, loop, or other block, also rewrite neighboring lines both above and below the change. Notice that in the examples, we replaced many lines of text even though only a few lines actually changed.\n  - Whitespace is important. Make sure to preserve leading whitespace for eaach line. Use correct, exact indentation. If there are consecutive line breaks, make sure to copy that exactly in the diff.\n  - Again, whitespace is important. Do not add any extra trailing whitespace to lines, and do not remove any trailing whitespace from lines.\n  - If one file is provided as a diff, you must provide all files as diffs.\n\n- In most cases, send a diff. Only send a complete fileset if a new file is being created or if a file is being completely rewritten.\n\n- If the user asks to put the app in a different directory, then use the tool to ask the user where they want to put it, and use a default directory that you decide on.\n\n  - Use the bslib package for styling and layout.\n\n- Use `DT::renderDT()` and `DT::dataTableOutput()`. Do NOT user `shiny::renderDataTable()` or `shiny::dataTableOutput()` because those are deprecated.\n\nChat applications\n=================\n\nShiny can be used to create AI chat applications, using the shinychat package as well as the ellmer package for communicating with LLMs.\n\nOnly create a chat application if the user specifically asks for one; otherwise create a non-chat application.\n\nIf the user asks for a chat application, remind them that they need to install the latest dev versions shinychat and ellmer, as well as the dotenv package. To do this, first install pak if necessary, then use pak to install those packages:\n\n```\nif (system.file(package=\"pak\")==\"\") install.packages(\"pak\")\npak::pak(c(\"posit-dev/shinychat\", \"tidyverse/ellmer\", \"dotenv\"))\n```\n\nTell them to create a `.env` file with their API keys, with the format:\n\n```\nOPENAI_API_KEY=XXXXXXXXXXX\nANTHROPIC_API_KEY=XXXXXXXXXXX\n```\n\nIf someone asks for a Chat application, use an OpenAI's gpt-4o (not gpt-4, but gpt-4o) model by default.\n\n\nThe following is the documentation for the shinychat package:\n\n<DOCUMENTATION PACKAGE=\"shinychat\" PAGE=\"README\">\nshinychat\n=========\n\n## Installation\n\nYou can install shinychat from CRAN with:\n\n``` r\ninstall.packages(\"shinychat\")\n```\n\nOr, install the development version of shinychat from [GitHub](https://github.com/) with:\n\n``` r\n# install.packages(\"pak\")\npak::pak(\"posit-dev/shinychat\")\n```\n\n## Example\n\nTo run this example, you'll first need to create an OpenAI API key, and set it in your environment as `OPENAI_API_KEY`.\n\nYou'll also need to call `pak::pak(\"tidyverse/ellmer\")` to install the {[ellmer](https://ellmer.tidyverse.org/)} package.\n\n```r\nlibrary(shiny)\nlibrary(shinychat)\n\nui <- bslib::page_fluid(\n  chat_ui(\"chat\")\n)\n\nserver <- function(input, output, session) {\n  chat <- ellmer::chat_openai(system_prompt = \"You're a trickster who answers in riddles\")\n  \n  observeEvent(input$chat_user_input, {\n    stream <- chat$stream_async(input$chat_user_input)\n    chat_append(\"chat\", stream)\n  })\n}\n\nshinyApp(ui, server)\n```\n\n</DOCUMENTATION>\n\n\nThe following is the documentation for the ellmer package:\n\n<DOCUMENTATION PACKAGE=\"ellmer\">\nThis file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.\n\n<file_summary>\nThis section contains a summary of this file.\n\n<purpose>\nThis file contains a packed representation of the entire repository's contents.\nIt is designed to be easily consumable by AI systems for analysis, code review,\nor other automated processes.\n</purpose>\n\n<file_format>\nThe content is organized as follows:\n1. This summary section\n2. Repository information\n3. Directory structure\n4. Repository files, each consisting of:\n  - File path as an attribute\n  - Full contents of the file\n</file_format>\n\n<usage_guidelines>\n- This file should be treated as read-only. Any changes should be made to the\n  original repository files, not this packed version.\n- When processing this file, use the file path to distinguish\n  between different files in the repository.\n- Be aware that this file may contain sensitive information. Handle it with\n  the same level of security as you would the original repository.\n</usage_guidelines>\n\n<notes>\n- Some files may have been excluded based on .gitignore rules and Repomix's configuration\n- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files\n- Only files matching these patterns are included: README.md, vignettes/*.Rmd\n- Files matching patterns in .gitignore are excluded\n- Files matching default ignore patterns are excluded\n- Files are sorted by Git change count (files with more changes are at the bottom)\n</notes>\n\n<additional_info>\n\n</additional_info>\n\n</file_summary>\n\n<directory_structure>\nvignettes/\n  ellmer.Rmd\n  prompt-design.Rmd\n  streaming-async.Rmd\n  structured-data.Rmd\n  tool-calling.Rmd\nREADME.md\n</directory_structure>\n\n<files>\nThis section contains the contents of the repository's files.\n\n<file path=\"vignettes/streaming-async.Rmd\">\n---\ntitle: \"Streaming and async APIs\"\noutput: rmarkdown::html_vignette\nvignette: >\n  %\\VignetteIndexEntry{Streaming and async APIs}\n  %\\VignetteEngine{knitr::rmarkdown}\n  %\\VignetteEncoding{UTF-8}\n---\n\n```{r, include = FALSE}\nknitr::opts_chunk$set(\n  collapse = TRUE,\n  comment = \"#>\"\n)\n```\n\n\n### Streaming results\n\nThe `chat()` method does not return any results until the entire response is received. (It can _print_ the streaming results to the console but it _returns_ the result only when the response is complete.)\n\nIf you want to process the response as it arrives, you can use the `stream()` method. This is useful when you want to send the response, in realtime, somewhere other than the R console (e.g., to a file, an HTTP response, or a Shiny chat window), or when you want to manipulate the response before displaying it without giving up the immediacy of streaming.\n\nWith the `stream()` method, which returns a [coro](https://coro.r-lib.org/) [generator](https://coro.r-lib.org/articles/generator.html), you can process the response by looping over it as it arrives.\n\n```{r eval=FALSE}\nstream <- chat$stream(\"What are some common uses of R?\")\ncoro::loop(for (chunk in stream) {\n  cat(toupper(chunk))\n})\n#>  R IS COMMONLY USED FOR:\n#>\n#>  1. **STATISTICAL ANALYSIS**: PERFORMING COMPLEX STATISTICAL TESTS AND ANALYSES.\n#>  2. **DATA VISUALIZATION**: CREATING GRAPHS, CHARTS, AND PLOTS USING PACKAGES LIKE  GGPLOT2.\n#>  3. **DATA MANIPULATION**: CLEANING AND TRANSFORMING DATA WITH PACKAGES LIKE DPLYR AND TIDYR.\n#>  4. **MACHINE LEARNING**: BUILDING PREDICTIVE MODELS WITH LIBRARIES LIKE CARET AND #>  RANDOMFOREST.\n#>  5. **BIOINFORMATICS**: ANALYZING BIOLOGICAL DATA AND GENOMIC STUDIES.\n#>  6. **ECONOMETRICS**: PERFORMING ECONOMIC DATA ANALYSIS AND MODELING.\n#>  7. **REPORTING**: GENERATING DYNAMIC REPORTS AND DASHBOARDS WITH R MARKDOWN.\n#>  8. **TIME SERIES ANALYSIS**: ANALYZING TEMPORAL DATA AND FORECASTING.\n#>\n#>  THESE USES MAKE R A POWERFUL TOOL FOR DATA SCIENTISTS, STATISTICIANS, AND RESEARCHERS.\n```\n\n## Async usage\n\nellmer also supports async usage. This is useful when you want to run multiple, concurrent chat sessions. This is particularly important for Shiny applications where using the methods described above would block the Shiny app for other users for the duration of each response.\n\nTo use async chat, call `chat_async()`/`stream_async()` instead of `chat()`/`stream()`. The `_async` variants take the same arguments for construction but return a promise instead of the actual response.\n\nRemember that chat objects are stateful; they preserve the conversation history as you interact with it. This means that it doesn't make sense to issue multiple, concurrent chat/stream operations on the same chat object because the conversation history can become corrupted with interleaved conversation fragments. If you need to run concurrent chat sessions, create multiple chat objects.\n\n### Asynchronous chat\n\nFor asynchronous, non-streaming chat, you'd use the `chat()` method as before, but handle the result as a promise instead of a string.\n\n```{r eval=FALSE}\nlibrary(promises)\n\nchat$chat_async(\"How's your day going?\") %...>% print()\n#> I'm just a computer program, so I don't have feelings, but I'm here to help you with any questions you have.\n```\n\nTODO: Shiny example\n\n### Asynchronous streaming\n\nFor asynchronous streaming, you'd use the `stream()` method as before, but the result is an [async generator](https://coro.r-lib.org/reference/async_generator.html) from the [coro package](https://coro.r-lib.org/). This is the same as a regular [generator](https://coro.r-lib.org/articles/generator.html), except that instead of giving you strings, it gives you promises that resolve to strings.\n\n```{r eval=FALSE}\nstream <- chat$stream_async(\"What are some common uses of R?\")\ncoro::async(function() {\n  for (chunk in await_each(stream)) {\n    cat(toupper(chunk))\n  }\n})()\n#>  R IS COMMONLY USED FOR:\n#>\n#>  1. **STATISTICAL ANALYSIS**: PERFORMING VARIOUS STATISTICAL TESTS AND MODELS.\n#>  2. **DATA VISUALIZATION**: CREATING PLOTS AND GRAPHS TO VISUALIZE DATA.\n#>  3. **DATA MANIPULATION**: CLEANING AND TRANSFORMING DATA WITH PACKAGES LIKE DPLYR.\n#>  4. **MACHINE LEARNING**: BUILDING PREDICTIVE MODELS AND ALGORITHMS.\n#>  5. **BIOINFORMATICS**: ANALYZING BIOLOGICAL DATA, ESPECIALLY IN GENOMICS.\n#>  6. **TIME SERIES ANALYSIS**: ANALYZING TEMPORAL DATA FOR TRENDS AND FORECASTS.\n#>  7. **REPORT GENERATION**: CREATING DYNAMIC REPORTS WITH R MARKDOWN.\n#>  8. **GEOSPATIAL ANALYSIS**: MAPPING AND ANALYZING GEOGRAPHIC DATA.\n```\n\nAsync generators are very advanced and require a good understanding of asynchronous programming in R. They are also the only way to present streaming results in Shiny without blocking other users. Fortunately, Shiny will soon have chat components that will make this easier, where you'll simply hand the result of `stream_async()` to a chat output.\n</file>\n\n<file path=\"vignettes/tool-calling.Rmd\">\n---\ntitle: \"Tool/function calling\"\noutput: rmarkdown::html_vignette\nvignette: >\n  %\\VignetteIndexEntry{Tool/function calling}\n  %\\VignetteEngine{knitr::rmarkdown}\n  %\\VignetteEncoding{UTF-8}\n---\n\n```{r, include = FALSE}\nknitr::opts_chunk$set(\n  collapse = TRUE,\n  comment = \"#>\",\n  eval = ellmer:::openai_key_exists()\n)\n```\n\n## Introduction\n\nOne of the most interesting aspects of modern chat models is their ability to make use of external tools that are defined by the caller.\n\nWhen making a chat request to the chat model, the caller advertises one or more tools (defined by their function name, description, and a list of expected arguments), and the chat model can choose to respond with one or more \"tool calls\". These tool calls are requests *from the chat model to the caller* to execute the function with the given arguments; the caller is expected to execute the functions and \"return\" the results by submitting another chat request with the conversation so far, plus the results. The chat model can then use those results in formulating its response, or, it may decide to make additional tool calls.\n\n*Note that the chat model does not directly execute any external tools!* It only makes requests for the caller to execute them. It's easy to think that tool calling might work like this:\n\n![Diagram showing showing the wrong mental model of tool calls: a user initiates a request that flows to the assistant, which then runs the code, and returns the result back to the user.\"](tool-calling-wrong.svg)\n\nBut in fact it works like this:\n\n![Diagram showing the correct mental model for tool calls: a user sends a request that needs a tool call, the assistant request that the user's runs that tool, returns the result to the assistant, which uses it to generate the final answer.](tool-calling-right.svg)\n\nThe value that the chat model brings is not in helping with execution, but with knowing when it makes sense to call a tool, what values to pass as arguments, and how to use the results in formulating its response.\n\n```{r setup}\nlibrary(ellmer)\n```\n\n### Motivating example\n\nLet's take a look at an example where we really need an external tool. Chat models generally do not know the current time, which makes questions like these impossible.\n\n```{r eval=FALSE}\nchat <- chat_openai(model = \"gpt-4o\")\nchat$chat(\"How long ago exactly was the moment Neil Armstrong touched down on the moon?\")\n#> Neil Armstrong touched down on the moon on July 20, 1969, at 20:17 UTC. To determine how long ago that\n#> was from the current year of 2023, we can calculate the difference in years, months, and days.\n#>\n#> From July 20, 1969, to July 20, 2023, is exactly 54 years. If today's date is after July 20, 2023, you\n#> would add the additional time since then. If it is before, you would consider slightly less than 54\n#> years.\n#>\n#> As of right now, can you confirm the current date so we can calculate the precise duration?\n```\n\nUnfortunately, this example was run on September 18, 2024. Let's give the chat model the ability to determine the current time and try again.\n\n### Defining a tool function\n\nThe first thing we'll do is define an R function that returns the current time. This will be our tool.\n\n```{r}\n#' Gets the current time in the given time zone.\n#'\n#' @param tz The time zone to get the current time in.\n#' @return The current time in the given time zone.\nget_current_time <- function(tz = \"UTC\") {\n  format(Sys.time(), tz = tz, usetz = TRUE)\n}\n```\n\nNote that we've gone through the trouble of creating [roxygen2 comments](https://roxygen2.r-lib.org/). This is a very important step that will help the model use your tool correctly!\n\nLet's test it:\n\n```{r eval=FALSE}\nget_current_time()\n#> [1] \"2024-09-18 17:47:14 UTC\"\n```\n\n### Registering tools\n\nNow we need to tell our chat object about our `get_current_time` function. This by creating and registering a tool:\n\n```{r}\nchat <- chat_openai(model = \"gpt-4o\")\n\nchat$register_tool(tool(\n  get_current_time,\n  \"Gets the current time in the given time zone.\",\n  tz = type_string(\n    \"The time zone to get the current time in. Defaults to `\\\"UTC\\\"`.\",\n    required = FALSE\n  )\n))\n```\n\nThis is a fair amount of code to write, even for such a simple function as `get_current_time`. Fortunately, you don't have to write this by hand! I generated the above `register_tool` call by calling `create_tool_def(get_current_time)`, which printed that code at the console. `create_tool_def()` works by passing the function's signature and documentation to GPT-4o, and asking it to generate the `register_tool` call for you.\n\nNote that `create_tool_def()` may not create perfect results, so you must review the generated code before using it. But it is a huge time-saver nonetheless, and removes the tedious boilerplate generation you'd have to do otherwise.\n\n### Using the tool\n\nThat's all we need to do! Let's retry our query:\n\n```{r eval=FALSE}\nchat$chat(\"How long ago exactly was the moment Neil Armstrong touched down on the moon?\")\n#> Neil Armstrong touched down on the moon on July 20, 1969, at 20:17 UTC.\n#>\n#> To calculate the time elapsed from that moment until the current time (September 18, 2024, 17:47:19\n#> UTC), we need to break it down.\n#>\n#> 1. From July 20, 1969, 20:17 UTC to July 20, 2024, 20:17 UTC is exactly 55 years.\n#> 2. From July 20, 2024, 20:17 UTC to September 18, 2024, 17:47:19 UTC, we need to further break down:\n#>\n#>    - From July 20, 2024, 20:17 UTC to September 18, 2024, 17:47:19 UTC, which is:\n#>      - 1 full month (August)\n#>      - 30  20 = 10 days of July\n#>      - 18 days of September until 17:47:19 UTC\n#>\n#> So, in detail:\n#>    - 55 years\n#>    - 1 month\n#>    - 28 days\n#>    - From July 20, 2024, 20:17 UTC to July 20, 2024, 17:47:19 UTC: 23 hours, 30 minutes, and 19 seconds\n#>\n#> Time Total:\n#> - 55 years\n#> - 1 month\n#> - 28 days\n#> - 23 hours\n#> - 30 minutes\n#> - 19 seconds\n#>\n#> This is the exact time that has elapsed since Neil Armstrong's historic touchdown on the moon.\n```\n\nThat's correct! Without any further guidance, the chat model decided to call our tool function and successfully used its result in formulating its response.\n\n(Full disclosure: I originally tried this example with the default model of `gpt-4o-mini` and it got the tool calling right but the date math wrong, hence the explicit `model=\"gpt-4o\"`.)\n\nThis tool example was extremely simple, but you can imagine doing much more interesting things from tool functions: calling APIs, reading from or writing to a database, kicking off a complex simulation, or even calling a complementary GenAI model (like an image generator). Or if you are using ellmer in a Shiny app, you could use tools to set reactive values, setting off a chain of reactive updates.\n\n### Tool limitations\n\nRemember that tool arguments come from the chat model, and tool results are returned to the chat model. That means that only simple, {jsonlite} compatible data types can be used as inputs and outputs. It's highly recommended that you stick to strings/character, numbers, booleans/logical, null, and named or unnamed lists of those types. And you can forget about using functions, environments, external pointers, R6 classes, and other complex R objects as arguments or return values. Returning data frames seems to work OK, although be careful not to return too much data, as it all counts as tokens (i.e., they count against your context window limit and also cost you money).\n</file>\n\n<file path=\"vignettes/ellmer.Rmd\">\n---\ntitle: \"Getting started with ellmer\"\noutput: rmarkdown::html_vignette\nvignette: >\n  %\\VignetteIndexEntry{Getting started with ellmer}\n  %\\VignetteEngine{knitr::rmarkdown}\n  %\\VignetteEncoding{UTF-8}\n---\n\n```{r, include = FALSE}\nknitr::opts_chunk$set(\n  collapse = TRUE,\n  eval = ellmer:::openai_key_exists(),\n  comment = \"#>\"\n)\n```\n\n```{r setup}\nlibrary(ellmer)\n```\n\nellmer makes it easy to access the wealth of large language models (LLMs) from R. But what can you do with those models once you have access to them? This vignette will give you the basic vocabulary you need to use an LLM effectively and will show you some examples to ignite your creativity.\n\nIn this vignette we'll mostly ignore how LLMs work, using them as convenient black boxes. If you want to get a sense of how they actually work, we recommend watching Jeremy Howard's posit::conf(2023) keynote: [A hacker's guide to open source LLMs](https://www.youtube.com/watch?v=sYliwvml9Es).\n\n## Vocabulary\n\nWe'll start by laying out the key vocab that you'll need to understand LLMs. Unfortunately the vocab is all a little entangled: to understand one term you'll often have to know a little about some of the others. So we'll start with some simple definitions of the most important terms then iteratively go a little deeper.\n\nIt all starts with a **prompt**, which is the text (typically a question or a request) that you send to the LLM. This starts a **conversation**, a sequence of turns that alternate between user prompts and model responses. Inside the model, both the prompt and response are represented by a sequence of **tokens**, which represent either individual words or subcomponents of a word. The tokens are used to compute the cost of using a model and to measure the size of the **context**, the combination of the current prompt and any previous prompts and responses used to generate the next response.\n\nIt's useful to make the distinction between providers and models. A **provider** is a web API that gives access to one or more **models**. The distinction is a bit subtle because providers are often synonymous with a model, like OpenAI and GPT, Anthropic and Claude, and Google and Gemini. But other providers, like Ollama, can host many different models, typically open source models like LLaMa and Mistral. Still other providers support both open and closed models, typically by partnering with a company that provides a popular closed model. For example, Azure OpenAI offers both open source models and OpenAI's GPT, while AWS Bedrock offers both open source models and Anthropic's Claude.\n\n### What is a token?\n\nAn LLM is a _model_, and like all models needs some way to represent its inputs numerically. For LLMs, that means we need some way to convert words to numbers. This is the goal of the **tokenizer**. For example, using the GPT 4o tokenizer, the string \"When was R created?\" is converted to 5 tokens: 5958 (\"When\"), 673 (\" was\"), 460 (\" R\"), 5371 (\" created\"), 30 (\"?\"). As you can see, many simple strings can be represented by a single token. But more complex strings require multiple tokens. For example, the string \"counterrevolutionary\" requires 4 tokens: 32128 (\"counter\"), 264 (\"re\"), 9477 (\"volution\"), 815 (\"ary\"). (You can see how various strings are tokenized at <http://tiktokenizer.vercel.app/>).\n\nIt's important to have a rough sense of how text is converted to tokens because tokens are used to determine the cost of a model and how much context can be used to predict the next response. On average an English word needs ~1.5 tokens so a page might require 375-400 tokens and a complete book might require 75,000 to 150,000 tokens. Other languages will typically require more tokens, because (in brief) LLMs are trained on data from the internet, which is primarily in English.\n\nLLMs are priced per million tokens. State of the art models (like GPT-4o or Claude 3.5 sonnet) cost $2-3 per million input tokens, and $10-15 per million output tokens. Cheaper models can cost much less, e.g. GPT-4o mini costs $0.15 per million input tokens and $0.60 per million output tokens. Even $10 of API credit will give you a lot of room for experimentation, particularly with cheaper models, and prices are likely to decline as model performance improves.\n\nTokens also used to measure the context window, which is how much text the LLM can use to generate the next response. As we'll discuss shortly, the context length includes the full state of your conversation so far (both your prompts and the model's responses), which means that cost grow rapidly with the number of conversational turns.\n\nIn ellmer, you can see how many tokens a conversations has used by printing it, and you can see total usage for a session with `token_usage()`.\n\n```{r}\nchat <- chat_openai(model = \"gpt-4o\")\n. <- chat$chat(\"Who created R?\", echo = FALSE)\nchat\n\ntoken_usage()\n```\n\nIf you want to learn more about tokens and tokenizers, I'd recommend watching the first 20-30 minutes of [Let's build the GPT Tokenizer](https://www.youtube.com/watch?v=zduSFxRajkE) by Andrej Karpathy. You certainly don't need to learn how to build your own tokenizer, but the intro will give you a bunch of useful background knowledge that will help improve your undersstanding of how LLM's work.\n\n### What is a conversation?\n\nA conversation with an LLM takes place through a series of HTTP requests and responses: you send your question to the LLM as an HTTP request, and it sends back its reply as an HTTP response. In other words, a conversation consists of a sequence of a paired turns: a sent prompt and a returned response.\n\nIt's important to note that a request includes not only the current user prompt, but every previous user prompt and model response. This means that:\n\n* The cost of a conversation grows quadratically with the number of turns: if you want to save money, keep your conversations short.\n\n* Each response is affected by all previous prompts and responses. This can make a converstion get stuck in a local optimum, so it's generally better to iterate by starting a new conversation with a better prompt rather than having a long back-and-forth.\n\n* ellmer has full control over the conversational history. Because it's ellmer's responsibility to send the previous turns of the conversation, it's possible to start a conversation with one model and finish it with another.\n\n### What is a prompt?\n\nThe user prompt is the question that you send to the model. There are two other important prompts that underlie the user prompt:\n\n* The **platform prompt**, which is unchangeable, set by the model provider, and affects every conversation. You can see what these look like from Anthropic, who [publishes their core system prompts](https://docs.anthropic.com/en/release-notes/system-prompts).\n\n* The **system prompt** (aka developer prompt), which is set when you create a new conversation, and affects every response. It's used to provide additional instructions to the model, shaping its responses to your needs. For example, you might use the system prompt to ask the model to always respond in Spanish or to write dependency-free base R code. You can also use the system prompt to provide the model with information it wouldn't otherwise know, like the details of your database schema, or your preferred ggplot2 theme and color palette.\n\nOpenAI calls this the [chain of command](https://cdn.openai.com/spec/model-spec-2024-05-08.html#follow-the-chain-of-command): if there are conflicts or inconsistencies the prompts, the platform prompt overrides the system prompt, which in turn overrides the user prompt.\n\nWhen you use a chat app like ChatGPT or claude.ai you can only iterate on the user prompt. But when you're programming with LLMs, you'll primarily iterate on the system prompt. For example, if you're developing an app that helps a user write tidyverse code, you'd work with the system prompt to ensure that user gets the style of code they want.\n\nWriting a good prompt, which is called __prompt design__, is key to effective use of LLMs. It is discussed in more detail in `vignette(\"prompt-design\")`.\n\n## Example uses\n\nNow that you've got the basic vocab under your belt, I'm going to fire a bunch of interesting potential use cases at you. While there are special purpose tools that might solve these cases faster and/or cheaper, an LLM allows you to rapidly prototype a solution. This can be extremely valuable even if you end up using those more specialised tools in your final product.\n\nIn general, we recommend avoiding LLMs where accuracy is critical. That said, there are still many cases for their use. For example, even though they always require some manual fiddling, you might save a bunch of time ever with an 80% correct solution. In fact, even a not-so-good solution can still be useful because it makes it easier to get started: it's easier to react to something rather than to have to start from scratch with a blank page.\n\n### Chatbots\n\nA great place to start with ellmer and LLMs is to build a chatbot with a custom prompt. Chatbots are a familiar interface to LLMs and are easy to create in R with [shinychat](https://github.com/jcheng5/shinychat). And there's a surprising amount of value to creating a custom chatbot that has a prompt stuffed with useful knowledge. For example:\n\n* Help people use your new package. To do so, you need a custom prompt because LLMs were trained on data prior to your package's existence. You can create a surprisingly useful tool just by preloading the prompt with your README and vignettes. This is how the [ellmer assistant](https://github.com/jcheng5/elmer-assistant) works.\n\n* Build language specific prompts for R and/or python. [Shiny assistant](https://shiny.posit.co/blog/posts/shiny-assistant/) helps you build shiny apps (either in R or python) by combining a [prompt](https://github.com/posit-dev/shiny-assistant/blob/main/shinyapp/app_prompt.md) that gives general advice on building apps with a prompt for [R](https://github.com/posit-dev/shiny-assistant/blob/main/shinyapp/app_prompt_r.md) or [python](https://github.com/posit-dev/shiny-assistant/blob/main/shinyapp/app_prompt_python.md). The python prompt is very detailed because there's much less information about Shiny for Python in the existing LLM knowledgebases.\n\n* Help people find the answers to their questions. Even if you've written a bunch of documentation for something, you might find that you still get questions because folks can't easily find exactly what they're looking for. You can reduce the need to answer these questions by creating a chatbot with a prompt that contains your documentation. For example, if you're a teacher, you could create a chatbot that includes your syllabus in the prompt. This eliminates a common class of question where the data necessary to answer the question is available, but hard to find.\n\nAnother direction is to give the chatbot additional context about your current environment. For example, [aidea](https://github.com/cpsievert/aidea) allows the user to interactively explore a dataset with the help of the LLM. It adds summary statistics about the dataset to the [prompt](https://github.com/cpsievert/aidea/blob/main/inst/app/prompt.md) so that the LLM knows something about your data. Along these lines, imagine writing a chatbot to help with data import that has a prompt which include all the files in the current directory along with their first few lines.\n\n### Structured data extraction\n\nLLMs are often very good at extracting structured data from unstructured text. This can give you traction to analyse data that was previously unaccessible. For example:\n\n* Customer tickets and GitHub issues: you can use LLMs for quick and dirty sentiment analysis by extracting any specifically mentioned products and summarising the discussion as a few bullet points.\n\n* Geocoding: LLMs do a surprisingly good job at geocoding, especially extracting addresses or finding the latitute/longitude of cities. There are specialised tools that do this better, but using an LLM makes it easy to get started.\n\n* Recipes: I've extracted structured data from baking and cocktail recipes. Once you have the data in a structured form you can use your R skills to better understand how recipes vary within a cookbook or to look for recipes that use the ingredients currently in your kitchen. You could even use shiny assistant to help make those techniques available to anyone, not just R users.\n\nStructured data extraction also works well with images. It's not the fastest or cheapest way to extract data but it makes it really easy to prototype ideas. For example, maybe you have a bunch of scanned documents that you want to index. You can convert PDFs to images (e.g. using {imagemagick}) then use structured data extraction to pull out key details.\n\nLearn more about structured data extraction in `vignette(\"structure-data\")`.\n\n### Programming\n\nLLMs can also be useful to solve general programming problems. For example:\n\n* Write a detailed prompt that explains how to update code to use a new version of a package. You could combine this with the rstudioapi package to allow the user to select code, transform it, and replace it in the existing text. A comprehensive example of this sort of app is [chores](https://simonpcouch.github.io/chores/), which includes prompts for automatically generating roxygen documentation blocks, updating testthat code to the 3rd edition, and converting `stop()` and `abort()` to use `cli::cli_abort()`.\n\n* You could automatically look up the documentation for an R function, and include it in the prompt to make it easier to figure out how to use a specific function.\n\n* You can use LLMs to explain code, or even ask them to [generate a diagram](https://bsky.app/profile/daviddiviny.com/post/3lb6kjaen4c2u).\n\n* You can ask an LLM to analyse your code for potential code smells or security issues. You can do this a function at a time, or explore the entire source code of your package or script in the prompt.\n\n* You could use [gh](https://gh.r-lib.org) to find unlabelled issues, extract the text, and ask the LLM to figure out what labels might be most appropriate. Or maybe an LLM might be able to help people create better reprexes, or simplify reprexes that are too complicated?\n\n* I find it useful to have an LLM document a function for me, even knowing that it's likely to be mostly incorrect. Having something to react to make it much easier for me to get started.\n\n* If you're working with code or data from another programming language, you can ask an LLM to convert it to R code for you. Even if it's not perfect, it's still typically much faster than doing everything yourself.\n\n## Miscellaneous\n\nTo finish up here are a few other ideas that seem cool but didn't seem to fit the above categories:\n\n* Automatically generate alt text for plots, using `content_image_plot()`.\n\n* Analyse the text of your statistical report to look for flaws in your statistical reasoning (e.g. misinterpreting p-values or assuming causation where only correlation exists).\n\n* Use your existing company style guide to generate a [brand.yaml](https://posit-dev.github.io/brand-yml/articles/llm-brand-yml-prompt/) specification to automatically style your reports, apps, dashboards and plots to match your corporate style guide.\n</file>\n\n<file path=\"vignettes/prompt-design.Rmd\">\n---\ntitle: \"Prompt design\"\noutput: rmarkdown::html_vignette\nvignette: >\n  %\\VignetteIndexEntry{Prompt design}\n  %\\VignetteEngine{knitr::rmarkdown}\n  %\\VignetteEncoding{UTF-8}\n---\n\n```{r, include = FALSE}\nknitr::opts_chunk$set(\n  collapse = TRUE,\n  comment = \"#>\",\n  eval = ellmer:::openai_key_exists() && ellmer:::anthropic_key_exists(),\n  cache = TRUE\n)\noptions(ellmer_seed = 1337)\n```\n\nThis vignette gives you some advice about how to use ellmer to write prompts. We'll work through two hopefully relevant examples: a prompt that generates code and another that extracts structured data. If you've never written a prompt, I'd highly recommend reading Ethan Mollick's [Getting started with AI: Good enough prompting](https://www.oneusefulthing.org/p/getting-started-with-ai-good-enough). I think understanding his analogy about how AI works will really help you get started:\n\n> Treat AI like an infinitely patient new coworker who forgets everything you tell them each new conversation, one that comes highly recommended but whose actual abilities are not that clear. ... Two parts of this are analogous to working with humans (being new on the job and being a coworker) and two of them are very alien (forgetting everything and being infinitely patient). We should start with where AIs are closest to humans, because that is the key to good-enough prompting\n\nAs well as learning general prompt design skills, it's also a good idea to read any specific advice for the model that you're using. Here are some pointers to the prompt design guides of some of the most popular models:\n\n* [Claude](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview)\n* [OpenAI](https://platform.openai.com/docs/guides/prompt-engineering)\n* [Gemini](https://ai.google.dev/gemini-api/docs/prompting-intro)\n\nIf you have a claude account, you can use its [prompt-generator](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-generator). It's specifically tailored for Claude, but I suspect it will help you with many other LLMs, or at least give you some ideas as to what else to include in your prompt.\n\n```{r setup}\n#| cache: false\nlibrary(ellmer)\n```\n\n```{r}\n#| include: false\n# Manually ratchet claude variability way down to hopefully make generated\n# code better match my prose.\nchat_anthropic <- function(...) {\n  ellmer::chat_anthropic(..., params = params(temperature = 0))\n}\n```\n\n## Best practices\n\nIt's highly likely that you'll end up writing long, possibly multi-page prompts. To ensure your success with this task, we have two recommendations. First, put each prompt its own, separate file. Second, write the prompts using markdown. The reason to use markdown is that it's quite readable to LLMs (and humans), and it allows you to do things like use headers to divide up a prompt into sections and itemised lists to enumerate multiple options. You can see some examples of this style of prompt here:\n\n* <https://github.com/posit-dev/shiny-assistant/blob/main/shinyapp/app_prompt_python.md>\n* <https://github.com/jcheng5/py-sidebot/blob/main/prompt.md>\n* <https://github.com/simonpcouch/pal/tree/main/inst/prompts>\n* <https://github.com/cpsievert/aidea/blob/main/inst/app/prompt.md>\n\nIn terms of file names, if you only have one prompt in your project, call it `prompt.md`. If you have multiple prompts, give them informative names like `prompt-extract-metadata.md` or `prompt-summarize-text.md`. If you're writing a package, put your prompt(s) in `inst/prompts`, otherwise it's fine to put them in the project's root directory.\n\nYour prompts are going to change over time, so we'd highly recommend commiting them to a git repo. That will ensure that you can easily see what has changed, and that if you accidentally make a mistake you can easily roll back to a known good verison.\n\nIf your prompt includes dynamic data, use `ellmer::interpolate_file()` to intergrate it into your prompt. `interpolate_file()` works like [glue](https://glue.tidyverse.org) but uses `{{ }}` instead of `{ }` to make it easier to work with JSON.\n\nAs you iterate the prompt, it's a good idea to build up a small set of challenging examples that you can regularly re-check with your latest version of the prompt. Currently you'll need to do this by hand, but we hope to eventually provide tools that'll help you do this a little more formally.\n\nUnfortunately, you won't see these best practices in action in this vignette since we're keeping the prompts short and inline to make it easier for you to grok what's going on.\n\n## Code generation\n\nLet's explore prompt design for a simple code generation task:\n\n```{r}\n#| cache: false\nquestion <- \"\n  How can I compute the mean and median of variables a, b, c, and so on,\n  all the way up to z, grouped by age and sex.\n\"\n```\n\nI'll use `chat_anthropic()` for this problem because in our experience it does the best job of generating code.\n\n### Basic flavour\n\nWhen I don't provide a system prompt, I sometimes get answers in different languages or different styles of R code:\n\n```{r}\n#| label: code-basic\nchat <- chat_anthropic()\nchat$chat(question)\n```\n\nI can ensure that I always get R code in a specific style by providing a system prompt:\n\n```{r}\n#| label: code-r\nchat <- chat_anthropic(\n  system_prompt = \"\n  You are an expert R programmer who prefers the tidyverse.\n\"\n)\nchat$chat(question)\n```\n\nNote that I'm using both a system prompt (which defines the general behaviour) and a user prompt (which asks the specific question). You could put all this content in the user prompt and get similar results, but I think it's helpful to use both to cleanly divide the general framing of the response from the specific questions you ask.\n\nSince I'm mostly interested in the code, I ask it to drop the explanation and sample data:\n\n```{r}\n#| label: code-r-minimal\nchat <- chat_anthropic(\n  system_prompt = \"\n  You are an expert R programmer who prefers the tidyverse.\n  Just give me the code. I don't want any explanation or sample data.\n\"\n)\nchat$chat(question)\n```\n\nAnd of course, if you want a different style of R code, just ask for it:\n\n```{r}\n#| label: code-styles\nchat <- chat_anthropic(\n  system_prompt = \"\n  You are an expert R programmer who prefers data.table.\n  Just give me the code. I don't want any explanation or sample data.\n\"\n)\nchat$chat(question)\n\nchat <- chat_anthropic(\n  system_prompt = \"\n  You are an expert R programmer who prefers base R.\n  Just give me the code. I don't want any explanation or sample data.\n\"\n)\nchat$chat(question)\n```\n\n### Be explicit\n\nIf there's something about the output that you don't like, try being more explicit. For example, the code isn't styled quite how I'd like it, so I provide more details about what I do want:\n\n```{r}\n#| label: code-explicit\nchat <- chat_anthropic(\n  system_prompt = \"\n  You are an expert R programmer who prefers the tidyverse.\n  Just give me the code. I don't want any explanation or sample data.\n\n  Follow the tidyverse style guide:\n  * Spread long function calls across multiple lines.\n  * Where needed, always indent function calls with two spaces.\n  * Only name arguments that are less commonly used.\n  * Always use double quotes for strings.\n  * Use the base pipe, `|>`, not the magrittr pipe `%>%`.\n\"\n)\nchat$chat(question)\n```\n\nThis still doesn't yield exactly the code that I'd write, but it's pretty close.\n\nYou could provide a different prompt if you were looking for more explanation of the code:\n\n```{r}\n#| label: code-teacher\nchat <- chat_anthropic(\n  system_prompt = \"\n  You are an expert R teacher.\n  I am a new R user who wants to improve my programming skills.\n  Help me understand the code you produce by explaining each function call with\n  a brief comment. For more complicated calls, add documentation to each\n  argument. Just give me the code. I don't want any explanation or sample data.\n\"\n)\nchat$chat(question)\n```\n\n### Teach it about new features\n\nYou can imagine LLMs as being a sort of an average of the internet at a given point in time. That means they will provide popular answers, which will tend to reflect older coding styles (either because the new features aren't in their index, or the older features are so much more popular). So if you want your code to use specific newer language features, you might need to provide the examples yourself:\n\n```{r}\n#| label: code-new-feature\nchat <- chat_anthropic(\n  system_prompt = \"\n  You are an expert R programmer.\n  Just give me the code; no explanation in text.\n  Use the `.by` argument rather than `group_by()`.\n  dplyr 1.1.0 introduced per-operation grouping with the `.by` argument.\n  e.g., instead of:\n\n  transactions |>\n    group_by(company, year) |>\n    mutate(total = sum(revenue))\n\n  write this:\n  transactions |>\n    mutate(\n      total = sum(revenue),\n      .by = c(company, year)\n    )\n\"\n)\nchat$chat(question)\n```\n\n## Structured data\n\nProviding a rich set of examples is a great way to encourage the output to produce exactly what you want. This is known as **multi-shot prompting**. Below we'll work through a prompt that I designed to extract structured data from recipes, but the same ideas apply in many other situations.\n\n### Getting started\n\nMy overall goal is to turn a list of ingredients, like the following, into a nicely structured JSON that I can then analyse in R (e.g. compute the total weight, scale the recipe up or down, or convert the units from volumes to weights).\n\n```{r}\n#| cache: false\ningredients <- \"\n   cup (150g) dark brown sugar\n  2 large eggs\n   cup (165g) sour cream\n   cup (113g) unsalted butter, melted\n  1 teaspoon vanilla extract\n   teaspoon kosher salt\n   cup (80ml) neutral oil\n  1 cups (190g) all-purpose flour\n  150g plus 1 teaspoons sugar\n\"\n```\n\n(This isn't the ingredient list for a real recipe but it includes a sampling of styles that I encountered in my project.)\n\nIf you don't have strong feelings about what the data structure should look like, you can start with a very loose prompt and see what you get back. I find this a useful pattern for underspecified problems where the heavy lifting lies with precisely defining the problem you want to solve. Seeing the LLM's attempt to create a data structure gives me something to react to, rather than having to start from a blank page.\n\n```{r}\n#| label: data-loose\ninstruct_json <- \"\n  You're an expert baker who also loves JSON. I am going to give you a list of\n  ingredients and your job is to return nicely structured JSON. Just return the\n  JSON and no other commentary.\n\"\n\nchat <- chat_openai(instruct_json)\nchat$chat(ingredients)\n```\n\n(I don't know if the additional colour, \"You're an expert baker who also loves JSON\", does anything, but I like to think this helps the LLM get into the right mindset of a very nerdy baker.)\n\n### Provide examples\n\nThis isn't a bad start, but I prefer to cook with weight and I only want to see volumes if weight isn't available so I provide a couple of examples of what I'm looking for. I was pleasantly suprised that I can provide the input and output examples in such a loose format.\n\n```{r}\n#| label: data-examples\ninstruct_weight <- r\"(\n  Here are some examples of the sort of output I'm looking for:\n\n   cup (150g) dark brown sugar\n  {\"name\": \"dark brown sugar\", \"quantity\": 150, \"unit\": \"g\"}\n\n   cup (80ml) neutral oil\n  {\"name\": \"neutral oil\", \"quantity\": 80, \"unit\": \"ml\"}\n\n  2 t ground cinnamon\n  {\"name\": \"ground cinnamon\", \"quantity\": 2, \"unit\": \"teaspoon\"}\n)\"\n\nchat <- chat_openai(paste(instruct_json, instruct_weight))\nchat$chat(ingredients)\n```\n\nJust providing the examples seems to work remarkably well. But I found it useful to also include a description of what the examples are trying to accomplish. I'm not sure if this helps the LLM or not, but it certainly makes it easier for me to understand the organisation of the whole prompt and check that I've covered the key pieces I'm interested in.\n\n```{r}\n#| cache: false\ninstruct_weight <- r\"(\n  * If an ingredient has both weight and volume, extract only the weight:\n\n   cup (150g) dark brown sugar\n  [\n    {\"name\": \"dark brown sugar\", \"quantity\": 150, \"unit\": \"g\"}\n  ]\n\n* If an ingredient only lists a volume, extract that.\n\n  2 t ground cinnamon\n   cup (80ml) neutral oil\n  [\n    {\"name\": \"ground cinnamon\", \"quantity\": 2, \"unit\": \"teaspoon\"},\n    {\"name\": \"neutral oil\", \"quantity\": 80, \"unit\": \"ml\"}\n  ]\n)\"\n```\n\nThis structure also allows me to give the LLMs a hint about how I want multiple ingredients to be stored, i.e. as an JSON array.\n\nI then iterated on the prompt, looking at the results from different recipes to get a sense of what the LLM was getting wrong. Much of this felt like I waws iterating on my own understanding of the problem as I didn't start by knowing exactly how I wanted the data. For example, when I started out I didn't really think about all the various ways that ingredients are specified. For later analysis, I always want quantities to be number, even if they were originally fractions, or the if the units aren't precise (like a pinch). It made me realise that some ingredients are unitless.\n\n```{r}\n#| cache: false\ninstruct_unit <- r\"(\n* If the unit uses a fraction, convert it to a decimal.\n\n   cup sugar\n   teaspoon salt\n  [\n    {\"name\": \"dark brown sugar\", \"quantity\": 0.33, \"unit\": \"cup\"},\n    {\"name\": \"salt\", \"quantity\": 0.5, \"unit\": \"teaspoon\"}\n  ]\n\n* Quantities are always numbers\n\n  pinch of kosher salt\n  [\n    {\"name\": \"kosher salt\", \"quantity\": 1, \"unit\": \"pinch\"}\n  ]\n\n* Some ingredients don't have a unit.\n  2 eggs\n  1 lime\n  1 apple\n  [\n    {\"name\": \"egg\", \"quantity\": 2},\n    {\"name\": \"lime\", \"quantity\": 1},\n    {\"name\", \"apple\", \"quantity\": 1}\n  ]\n)\"\n```\n\nYou might want to take a look at the [full prompt](https://gist.github.com/hadley/7688b4dd1e5e97b800c6d7d79e437b48) to see what I ended up with.\n\n### Structured data\n\nNow that I've iterated to get a data structure I like, it seems useful to formalise it and tell the LLM exactly what I'm looking for when dealing with structured data. This guarantees that the LLM will only return JSON, that the JSON will have the fields that you expect, and that ellmer will convert it into an R data structure.\n\n```{r}\n#| label: data-structured\ntype_ingredient <- type_object(\n  name = type_string(\"Ingredient name\"),\n  quantity = type_number(),\n  unit = type_string(\"Unit of measurement\")\n)\n\ntype_ingredients <- type_array(items = type_ingredient)\n\nchat <- chat_openai(c(instruct_json, instruct_weight))\nchat$extract_data(ingredients, type = type_ingredients)\n```\n\n### Capturing raw input\n\nOne thing that I'd do next time would also be to include the raw ingredient names in the output. This doesn't make much difference in this simple example but it makes it much easier to align the input with the output and to start developing automated measures of how well my prompt is doing.\n\n```{r}\n#| cache: false\ninstruct_weight_input <- r\"(\n  * If an ingredient has both weight and volume, extract only the weight:\n\n     cup (150g) dark brown sugar\n    [\n      {\"name\": \"dark brown sugar\", \"quantity\": 150, \"unit\": \"g\", \"input\": \" cup (150g) dark brown sugar\"}\n    ]\n\n  * If an ingredient only lists a volume, extract that.\n\n    2 t ground cinnamon\n     cup (80ml) neutral oil\n    [\n      {\"name\": \"ground cinnamon\", \"quantity\": 2, \"unit\": \"teaspoon\", \"input\": \"2 t ground cinnamon\"},\n      {\"name\": \"neutral oil\", \"quantity\": 80, \"unit\": \"ml\", \"input\": \" cup (80ml) neutral oil\"}\n    ]\n)\"\n```\n\nI think this is particularly important if you're working with even less structured text. For example, imagine you had this text:\n\n```{r}\n#| cache: false\nrecipe <- r\"(\n  In a large bowl, cream together one cup of softened unsalted butter and a\n  quarter cup of white sugar until smooth. Beat in an egg and 1 teaspoon of\n  vanilla extract. Gradually stir in 2 cups of all-purpose flour until the\n  dough forms. Finally, fold in 1 cup of semisweet chocolate chips. Drop\n  spoonfuls of dough onto an ungreased baking sheet and bake at 350F (175C)\n  for 10-12 minutes, or until the edges are lightly browned. Let the cookies\n  cool on the baking sheet for a few minutes before transferring to a wire\n  rack to cool completely. Enjoy!\n)\"\n```\n\nIncluding the input text in the output makes it easier to see if it's doing a good job:\n\n```{r}\n#| label: data-unstructured-input\nchat <- chat_openai(c(instruct_json, instruct_weight_input))\nchat$chat(recipe)\n```\n\nWhen I ran it while writing this vignette, it seemed to be working out the weight of the ingredients specified in volume, even though the prompt specifically asks it not to. This may suggest I need to broaden my examples.\n\n## Token usage\n\n```{r}\n#| label: usage\n#| type: asis\n#| echo: false\nknitr::kable(token_usage())\n```\n</file>\n\n<file path=\"vignettes/structured-data.Rmd\">\n---\ntitle: \"Structured data\"\noutput: rmarkdown::html_vignette\nvignette: >\n  %\\VignetteIndexEntry{Structured data}\n  %\\VignetteEngine{knitr::rmarkdown}\n  %\\VignetteEncoding{UTF-8}\n---\n\n```{r, include = FALSE}\nknitr::opts_chunk$set(\n  collapse = TRUE,\n  comment = \"#>\",\n  eval = ellmer:::openai_key_exists(),\n  cache = TRUE\n)\n```\n\nWhen using an LLM to extract data from text or images, you can ask the chatbot to format it in JSON or any other format that you like. This works well most of the time, but there's no guarantee that you'll get the exact format you want. In particular, if you're trying to get JSON, you'll find that it's typically surrounded in ```` ```json ````, and you'll occasionally get text that isn't valid JSON. To avoid these problems, you can use a recent LLM feature: **structured data** (aka structured output). With structured data, you supply the type specification that defines the object structure you want and the LLM ensures that's what you'll get back.\n\n```{r setup}\n#| cache: false\nlibrary(ellmer)\n```\n\n## Structured data basics\n\nTo extract structured data you call the `$extract_data()` method instead of the `$chat()` method. You'll also need to define a type specification that describes the structure of the data that you want (more on that shortly). Here's a simple example that extracts two specific values from a string:\n\n```{r}\n#| label: basics-text\nchat <- chat_openai()\nchat$extract_data(\n  \"My name is Susan and I'm 13 years old\",\n  type = type_object(\n    age = type_number(),\n    name = type_string()\n  )\n)\n```\n\nThe same basic idea works with images too:\n\n```{r}\n#| label: basics-image\nchat$extract_data(\n  content_image_url(\"https://www.r-project.org/Rlogo.png\"),\n  type = type_object(\n    primary_shape = type_string(),\n    primary_colour = type_string()\n  )\n)\n```\n\n## Data types basics\n\nTo define your desired type specification (also known as a **schema**), you use the `type_()` functions. (You might already be familiar with these if you've done any function calling, as discussed in `vignette(\"function-calling\")`). The type functions can be divided into three main groups:\n\n* **Scalars** represent five types of single values, `type_boolean()`, `type_integer()`, `type_number()`, `type_string()`, and `type_enum()`, which represent a single logical, integer, double, string, and factor value respectively.\n\n* **Arrays** represent any number of values of the same type. They are created with `type_array()`. You must always supply the `item` argument which specifies the type for each individual element. Arrays of scalars are very similar to R's atomic vectors:\n\n  ```{r}\n  #| cache: false\n  type_logical_vector <- type_array(items = type_boolean())\n  type_integer_vector <- type_array(items = type_integer())\n  type_double_vector <- type_array(items = type_number())\n  type_character_vector <- type_array(items = type_string())\n  ```\n\n  You can also have arrays of arrays and arrays of objects, which more closely resemble lists with well defined structures:\n\n  ```{r}\n  #| cache: false\n  list_of_integers <- type_array(items = type_integer_vector)\n  ```\n\n* **Objects** represent a collection of named values. They are created with `type_object()`. Objects can contain any number of scalars, arrays, and other objects. They are similar to named lists in R.\n\n  ```{r}\n  #| cache: false\n  type_person <- type_object(\n    name = type_string(),\n    age = type_integer(),\n    hobbies = type_array(items = type_string())\n  )\n  ```\n\nUsing these type specifications ensures that the LLM will return JSON. But ellmer goes one step further to convert the results to the closest R analog. Currently, this converts arrays of boolean, integers, numbers, and strings into logical, integer, numeric, and character vectors. Arrays of objects are converted into data frames. You can opt-out of this and get plain lists by setting `convert = FALSE` in `$extract_data()`.\n\nIn addition to defining types, you need to provide the LLM with some information about what you actually want. This is the purpose of the first argument, `description`, which is a string that describes the data that you want. This is a good place to ask nicely for other attributes you'll like the value to have (e.g. minimum or maximum values, date formats, ...). There's no guarantee that these requests will be honoured, but the LLM will usually make a best effort to do so.\n\n```{r}\n#| cache: false\ntype_type_person <- type_object(\n  \"A person\",\n  name = type_string(\"Name\"),\n  age = type_integer(\"Age, in years.\"),\n  hobbies = type_array(\n    \"List of hobbies. Should be exclusive and brief.\",\n    items = type_string()\n  )\n)\n```\n\nNow we'll dive into some examples before coming back to talk more about the details of data types.\n\n## Examples\n\nThe following examples, which are [closely inspired by the Claude documentation](https://github.com/anthropics/anthropic-cookbook/blob/main/tool_use/extracting_structured_json.ipynb), hint at some of the ways you can use structured data extraction.\n\n### Example 1: Article summarisation\n\n```{r}\n#| label: examples-summarisation\ntext <- readLines(system.file(\"examples/third-party-testing.txt\", package = \"ellmer\"))\n# url <- \"https://www.anthropic.com/news/third-party-testing\"\n# html <- rvest::read_html(url)\n# text <- rvest::html_text2(rvest::html_element(html, \"article\"))\n\ntype_summary <- type_object(\n  \"Summary of the article.\",\n  author = type_string(\"Name of the article author\"),\n  topics = type_array(\n    'Array of topics, e.g. [\"tech\", \"politics\"]. Should be as specific as possible, and can overlap.',\n    type_string(),\n  ),\n  summary = type_string(\"Summary of the article. One or two paragraphs max\"),\n  coherence = type_integer(\"Coherence of the article's key points, 0-100 (inclusive)\"),\n  persuasion = type_number(\"Article's persuasion score, 0.0-1.0 (inclusive)\")\n)\n\nchat <- chat_openai()\ndata <- chat$extract_data(text, type = type_summary)\ncat(data$summary)\n\nstr(data)\n```\n\n### Example 2: Named entity recognition\n\n```{r}\n#| label: examples-named-entity\ntext <- \"\n  John works at Google in New York. He met with Sarah, the CEO of\n  Acme Inc., last week in San Francisco.\n\"\n\ntype_named_entity <- type_object(\n  name = type_string(\"The extracted entity name.\"),\n  type = type_enum(\"The entity type\", c(\"person\", \"location\", \"organization\")),\n  context = type_string(\"The context in which the entity appears in the text.\")\n)\ntype_named_entities <- type_array(items = type_named_entity)\n\nchat <- chat_openai()\nchat$extract_data(text, type = type_named_entities)\n```\n\n### Example 3: Sentiment analysis\n\n```{r}\n#| label: examples-sentiment\ntext <- \"\n  The product was okay, but the customer service was terrible. I probably\n  won't buy from them again.\n\"\n\ntype_sentiment <- type_object(\n  \"Extract the sentiment scores of a given text. Sentiment scores should sum to 1.\",\n  positive_score = type_number(\"Positive sentiment score, ranging from 0.0 to 1.0.\"),\n  negative_score = type_number(\"Negative sentiment score, ranging from 0.0 to 1.0.\"),\n  neutral_score = type_number(\"Neutral sentiment score, ranging from 0.0 to 1.0.\")\n)\n\nchat <- chat_openai()\nstr(chat$extract_data(text, type = type_sentiment))\n```\n\nNote that while we've asked nicely for the scores to sum 1, which they do in this example (at least when I ran the code), this is not guaranteed.\n\n### Example 4: Text classification\n\n```{r}\n#| label: examples-classification\ntext <- \"The new quantum computing breakthrough could revolutionize the tech industry.\"\n\ntype_classification <- type_array(\n  \"Array of classification results. The scores should sum to 1.\",\n  type_object(\n    name = type_enum(\n      \"The category name\",\n      values = c(\n        \"Politics\",\n        \"Sports\",\n        \"Technology\",\n        \"Entertainment\",\n        \"Business\",\n        \"Other\"\n      )\n    ),\n    score = type_number(\n      \"The classification score for the category, ranging from 0.0 to 1.0.\"\n    )\n  )\n)\n\nchat <- chat_openai()\ndata <- chat$extract_data(text, type = type_classification)\ndata\n```\n\n### Example 5: Working with unknown keys\n\n```{r, eval = ellmer:::anthropic_key_exists()}\n#| label: examples-unknown-keys\ntype_characteristics <- type_object(\n  \"All characteristics\",\n  .additional_properties = TRUE\n)\n\nprompt <- \"\n  Given a description of a character, your task is to extract all the characteristics of that character.\n\n  <description>\n  The man is tall, with a beard and a scar on his left cheek. He has a deep voice and wears a black leather jacket.\n  </description>\n\"\n\nchat <- chat_anthropic()\nstr(chat$extract_data(prompt, type = type_characteristics))\n```\n\nThis example only works with Claude, not GPT or Gemini, because only Claude supports adding additional, arbitrary properties.\n\n### Example 6: Extracting data from an image\n\nThe final example comes from [Dan Nguyen](https://gist.github.com/dannguyen/faaa56cebf30ad51108a9fe4f8db36d8) (you can see other interesting applications at that link). The goal is to extract structured data from this screenshot:\n\n![Screenshot of schedule A: a table showing assets and \"unearned\" income](congressional-assets.png)\n\nEven without any descriptions, ChatGPT does pretty well:\n\n```{r}\n#| label: examples-image\ntype_asset <- type_object(\n  assert_name = type_string(),\n  owner = type_string(),\n  location = type_string(),\n  asset_value_low = type_integer(),\n  asset_value_high = type_integer(),\n  income_type = type_string(),\n  income_low = type_integer(),\n  income_high = type_integer(),\n  tx_gt_1000 = type_boolean()\n)\ntype_assets <- type_array(items = type_asset)\n\nchat <- chat_openai()\nimage <- content_image_file(\"congressional-assets.png\")\ndata <- chat$extract_data(image, type = type_assets)\ndata\n```\n\n## Advanced data types\n\nNow that you've seen a few examples, it's time to get into more specifics about data type declarations.\n\n### Required vs optional\n\nBy default, all components of an object are required. If you want to make some optional, set `required = FALSE`. This is a good idea if you don't think your text will always contain the required fields as LLMs may hallucinate data in order to fulfill your spec.\n\nFor example, here the LLM hallucinates a date even though there isn't one in the text:\n\n```{r}\n#| label: type-required\ntype_article <- type_object(\n  \"Information about an article written in markdown\",\n  title = type_string(\"Article title\"),\n  author = type_string(\"Name of the author\"),\n  date = type_string(\"Date written in YYYY-MM-DD format.\")\n)\n\nprompt <- \"\n  Extract data from the following text:\n\n  <text>\n  # Structured Data\n  By Hadley Wickham\n\n  When using an LLM to extract data from text or images, you can ask the chatbot to nicely format it, in JSON or any other format that you like.\n  </text>\n\"\n\nchat <- chat_openai()\nchat$extract_data(prompt, type = type_article)\nstr(data)\n```\n\nNote that I've used more of an explict prompt here. For this example, I found that this generated better results and that it's a useful place to put additional instructions.\n\nIf I let the LLM know that the fields are all optional, it'll return `NULL` for the missing fields:\n\n```{r}\n#| label: type-optional\ntype_article <- type_object(\n  \"Information about an article written in markdown\",\n  title = type_string(\"Article title\", required = FALSE),\n  author = type_string(\"Name of the author\", required = FALSE),\n  date = type_string(\"Date written in YYYY-MM-DD format.\", required = FALSE)\n)\nchat$extract_data(prompt, type = type_article)\n```\n\n### Data frames\n\nIf you want to define a data frame like object, you might be tempted to create a definition similar to what R uses: an object (i.e., a named list) containing multiple vectors (i.e., an array):\n\n```{r}\n#| cache: false\ntype_my_df <- type_object(\n  name = type_array(items = type_string()),\n  age = type_array(items = type_integer()),\n  height = type_array(items = type_number()),\n  weight = type_array(items = type_number())\n)\n```\n\nThis, however, is not quite right becuase there's no way to specify that each array should have the same length. Instead, you'll need to turn the data structure \"inside out\" and create an array of objects:\n\n```{r}\n#| cache: false\ntype_my_df <- type_array(\n  items = type_object(\n    name = type_string(),\n    age = type_integer(),\n    height = type_number(),\n    weight = type_number()\n  )\n)\n```\n\nIf you're familiar with the terms row-oriented and column-oriented data frames, this is the same idea. Since most languages don't possess vectorisation like R, row-oriented structures tend to be much more common in the wild.\n\n## Token usage\n\n```{r}\n#| label: usage\n#| type: asis\n#| echo: false\nknitr::kable(token_usage())\n```\n</file>\n\n<file path=\"README.md\">\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# ellmer <a href=\"https://ellmer.tidyverse.org\"><img src=\"man/figures/logo.png\" align=\"right\" height=\"138\" alt=\"ellmer website\" /></a>\n\n<!-- badges: start -->\n\n[![Lifecycle:\nexperimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://lifecycle.r-lib.org/articles/stages.html#experimental)\n[![R-CMD-check](https://github.com/tidyverse/ellmer/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/tidyverse/ellmer/actions/workflows/R-CMD-check.yaml)\n<!-- badges: end -->\n\nellmer makes it easy to use large language models (LLM) from R. It\nsupports a wide variety of LLM providers and implements a rich set of\nfeatures including streaming outputs, tool/function calling, structured\ndata extraction, and more.\n\n(Looking for something similar to ellmer for python? Check out\n[chatlas](https://github.com/posit-dev/chatlas)!)\n\n## Installation\n\nYou can install ellmer from CRAN with:\n\n``` r\ninstall.packages(\"ellmer\")\n```\n\n## Providers\n\nellmer supports a wide variety of model providers:\n\n- Anthropics Claude: `chat_anthropic()`.\n- AWS Bedrock: `chat_aws_bedrock()`.\n- Azure OpenAI: `chat_azure_openai()`.\n- Databricks: `chat_databricks()`.\n- DeepSeek: `chat_deepseek()`.\n- GitHub model marketplace: `chat_github()`.\n- Google Gemini: `chat_google_gemini()`.\n- Groq: `chat_groq()`.\n- Ollama: `chat_ollama()`.\n- OpenAI: `chat_openai()`.\n- OpenRouter: `chat_openrouter()`.\n- perplexity.ai: `chat_perplexity()`.\n- Snowflake Cortex: `chat_snowflake()` and `chat_cortex_analyst()`.\n- VLLM: `chat_vllm()`.\n\n### Provider/model choice\n\nIf youre using ellmer inside an organisation, you may have internal\npolicies that limit you to models from big cloud providers,\ne.g.`chat_azure_openai()`, `chat_aws_bedrock()`, `chat_databricks()`,\nor `chat_snowflake()`.\n\nIf youre using ellmer for your own exploration, youll have a lot more\nfreedom, so we have a few recommendations to help you get started:\n\n- `chat_openai()` or `chat_anthropic()` are good places to start.\n  `chat_openai()` defaults to **GPT-4o**, but you can use\n  `model = \"gpt-4o-mini\"` for a cheaper, lower-quality model, or\n  `model = \"o1-mini\"` for more complex reasoning. `chat_anthropic()` is\n  also good; it defaults to **Claude 3.5 Sonnet**, which we have found\n  to be particularly good at writing code.\n\n- `chat_google_gemini()` is great for large prompts because it has a\n  much larger context window than other models. It allows up to 1\n  million tokens, compared to Claude 3.5 Sonnets 200k and GPT-4os\n  128k. It also comes with a generous free tier (with the downside that\n  [your data is\n  used](https://ai.google.dev/gemini-api/terms#unpaid-services) to\n  improve the model).\n\n- `chat_ollama()`, which uses [Ollama](https://ollama.com), allows you\n  to run models on your own computer. While the biggest models you can\n  run locally arent as good as the state of the art hosted models, they\n  dont share your data and are effectively free.\n\n### Authentication\n\nAuthentication works a little differently depending on the provider. A\nfew popular ones (including OpenAI and Anthropic) require you to obtain\nan API key. We recommend you save it in an environment variable rather\nthan using it directly in your code, and if you deploy an app or report\nthat uses ellmer to another system, youll need to ensure that this\nenvironment variable is available there, too.\n\nellmer also automatically detects many of the OAuth or IAM-based\ncredentials used by the big cloud providers (currently\n`chat_azure_openai()`, `chat_aws_bedrock()`, `chat_databricks()`,\n`chat_snowflake()`). That includes credentials for these platforms\nmanaged by [Posit\nWorkbench](https://docs.posit.co/ide/server-pro/user/posit-workbench/managed-credentials/managed-credentials.html)\nand [Posit\nConnect](https://docs.posit.co/connect/user/oauth-integrations/#adding-oauth-integrations-to-deployed-content).\n\nIf you find cases where ellmer cannot detect credentials from one of\nthese cloud providers, feel free to open an issue; were happy to add\nmore auth mechanisms if needed.\n\n## Using ellmer\n\nYou can work with ellmer in several different ways, depending on whether\nyou are working interactively or programmatically. They all start with\ncreating a new chat object:\n\n``` r\nlibrary(ellmer)\n\nchat <- chat_openai(\n  model = \"gpt-4o-mini\",\n  system_prompt = \"You are a friendly but terse assistant.\",\n)\n```\n\nChat objects are stateful [R6 objects](https://r6.r-lib.org): they\nretain the context of the conversation, so each new query builds on the\nprevious ones. You call their methods with `$`.\n\n### Interactive chat console\n\nThe most interactive and least programmatic way of using ellmer is to\nchat directly in your R console or browser with `live_console(chat)` or\n`live_browser()`:\n\n``` r\nlive_console(chat)\n#> \n#>   Entering chat console. Use \"\"\" for multi-line input.  \n#>   Press Ctrl+C to quit.                                 \n#> \n#> >>> Who were the original creators of R?\n#> R was originally created by Ross Ihaka and Robert Gentleman at the University of\n#> Auckland, New Zealand.\n#>\n#> >>> When was that?\n#> R was initially released in 1995. Development began a few years prior to that,\n#> in the early 1990s.\n```\n\nKeep in mind that the chat object retains state, so when you enter the\nchat console, any previous interactions with that chat object are still\npart of the conversation, and any interactions you have in the chat\nconsole will persist after you exit back to the R prompt. This is true\nregardless of which chat function you use.\n\n### Interactive method call\n\nThe second most interactive way to chat is to call the `chat()` method:\n\n``` r\nchat$chat(\"What preceding languages most influenced R?\")\n#> R was primarily influenced by the S programming language, particularly S-PLUS.\n#> Other languages that had an impact include Scheme and various data analysis\n#> languages.\n```\n\nIf you initialize the chat object in the global environment, the `chat`\nmethod will stream the response to the console. When the entire response\nis received, its also (invisibly) returned as a character vector. This\nis useful when you want to see the response as it arrives, but you dont\nwant to enter the chat console.\n\nIf you want to ask a question about an image, you can pass one or more\nadditional input arguments using `content_image_file()` and/or\n`content_image_url()`:\n\n``` r\nchat$chat(\n  content_image_url(\"https://www.r-project.org/Rlogo.png\"),\n  \"Can you explain this logo?\"\n)\n#> The logo of R features a stylized letter \"R\" in blue, enclosed in an oval\n#> shape that resembles the letter \"O,\" signifying the programming language's\n#> name. The design conveys a modern and professional look, reflecting its use\n#> in statistical computing and data analysis. The blue color often represents\n#> trust and reliability, which aligns with R's role in data science.\n```\n\n### Programmatic chat\n\nThe most programmatic way to chat is to create the chat object inside a\nfunction. By doing so, live streaming is automatically suppressed and\n`$chat()` returns the result as a string:\n\n``` r\nmy_function <- function() {\n  chat <- chat_openai(\n    model = \"gpt-4o-mini\",\n    system_prompt = \"You are a friendly but terse assistant.\",\n  )\n  chat$chat(\"Is R a functional programming language?\")\n}\nmy_function()\n#> [1] \"Yes, R supports functional programming concepts. It allows functions to\n#> be first-class objects, supports higher-order functions, and encourages the\n#> use of functions as core components of code. However, it also supports\n#> procedural and object-oriented programming styles.\"\n```\n\nIf needed, you can manually control this behaviour with the `echo`\nargument. This is useful for programming with ellmer when the result is\neither not intended for human consumption or when you want to process\nthe response before displaying it.\n\n## Learning more\n\nellmer comes with a bunch of vignettes to help you learn more:\n\n- Learn key vocabulary and see example use cases in\n  `vignette(\"ellmer\")`.\n- Learn how to design your prompt in `vignette(\"prompt-design\")`.\n- Learn about tool/function calling in `vignette(\"tool-calling\")`.\n- Learn how to extract structured data in `vignette(\"structured-data\")`.\n- Learn about streaming and async APIs in `vignette(\"streaming-async\")`.\n</file>\n\n</files>\n</DOCUMENTATION>\n`\n\n\n## About brand.yml\n\nbrand.yml is a structured YAML file to hold brand information for key\nbrand elements. The goal of brand.yml is to capture the essence of the\nbrand's color and typographic choices in a simple format.\n\n\"brand.yml\" is the name of the project defining the YAML specification.\nA specific instance of a brand's data is stored in a file named\n\"_brand.yml\" by convention.\n\n## Brand Elements\n\n-   `meta` - Key identity information, name of the company, links to\n    brand guidelines, etc.\n\n-   `logo` - Files or links to the brand's logo at various sizes.\n\n-   `color` Semantic colors, e.g.`primary`, `secondary`, `success`,\n    `warning`, etc. Named colors in the brand's color palette are stored\n    in `color.palette`.\n\n-   `typography` - Font family, weight, style, color, and line height\n    for key elements, e.g.base, headings and monospace text. Available\n    fonts used by the brand are stored in `typography.fonts` and can be\n    sourced from Google Fonts, Bunny Fonts or local or remote font\n    files.\n\n-   `defaults` - Additional context-specific settings beyond the basic\n    brand colors and typography. These could be options, for example,\n    that are used by Bootstrap in Quarto or Shiny. They could also be\n    folded into existing Quarto yaml fields like `format` or `website`,\n    or they could be new fields for other contexts like `shiny`.\n\n## Example file\n\nThe following YAML includes all allowed features of a _brand.yml file.\nNote that all fields are optional.\n\nOnly include fields that directly apply to the brand; it's important for\nthe _brand.yml file to be simple and concise rather than overly\ncomplex. Many fields have simple and complex values variants; generally\nspeaking many fields accept either a simple string or a mapping.\nAlternative syntax is indicated in comments in the example below with\n\"ALT\". If possible, use the simple string.\n\n``` {.yaml filename=\"_brand.yml\"}\nmeta:\n  # name: Acme # ALT: Single string for simple company name\n  name:\n    short: Acme # Short company name\n    full: Acme Corporation International # Full, legal company name\n  \n  # link: https://acmecorp.com # ALT: single url for the company's home page\n  link:\n    home: https://www.acmecorp.com # Company's home apge\n    bluesky: https://bsky.app/profile/acmecorp.bsky.social # Bluesky social media account link\n    github: https://github.com/acmecorp # GitHub account link\n    mastodon: https://mastodon.social/@acmecorp # Mastodon account link\n    linkedin: https://www.linkedin.com/company/acmecorp # LinkedIn account link\n    facebook: https://www.facebook.com/acmecorp # Facebook account link\n    twitter: https://twitter.com/acmecorp # Twitter account link\n\nlogo:\n  images: # Mapping of image names to local files that should be stored next to the _brand.yml file. Users may need to download these files manually.\n    header: logos/header-logo.png # Each entry maps a name to a local file\n    header-white: logos/header-logo-white.png\n    full: # ALT: Images can alternatively be a path with associated alt text for accessibility\n      path: logos/full-logo.svg\n      alt: Acme logo.\n  small: logos/icon.png # A small image, ideally icon-sized. Can be a path to a file or the name of a file in `logo.images`\n  medium: # A medium sized logo, ideally small enough for a sidebar logo\n    # ALT: Logos is small, medium, and large may have `light` and `dark` variants\n    light: header # light variant for use on light backgrounds\n    dark: header-white # dark variant for use on dark backgrounds\n  large: full # A large logo, e.g. for use in a hero or cover page. ALT: Can refer directly to images in `logo.images`.\n\ncolor:\n  palette:\n    # Dictionary of the brand's colors with readable names. \n    # Must be a flat list of names and color values. \n    # Names should be follow Sass variable conventions. Prefer hex color values.\n    # Prefer or create aliases for Bootstrap primary colors: blue, indigo, purple, pink, red, orange, yellow, green, teal, cyan, white, black\n    white: \"#FFFFFF\"\n    black: \"#151515\"\n    blue: \"#447099\"\n    orange: \"#EE6331\"\n    green: \"#72994E\"\n    teal: \"#419599\"\n    burgundy: \"#9A4665\"\n    purple: burgundy # Aliases are allowed by referring to other colors in `color.palette`\n    fire-red: \"#FF0000\"\n    bright-yellow: \"#FFFF00\"\n\n  # All theme colors can take direct color values, and all are optional.\n  # Only include the colors that are obviously required.\n  # Refer to color names from `color.palette` whenever possible.\n  foreground: \"#151515\"  # Main text color, should have high contrast with background\n  background: \"#FFFFFF\"  # Main background color, should have high contrast with foreground\n  primary: \"#447099\"  # Main accent color for links, buttons, etc.\n  secondary: \"#707073\"  # Used for lighter text or disabled states. Only include if necessary.\n  tertiary: \"#C2C2C4\"  # Even lighter color for hover states, accents, wells. Only include if necessary.\n  success: \"#72994E\"  # Color for positive or successful actions/information\n  info: \"#419599\"  # Color for neutral or informational actions/information\n  warning: \"#EE6331\"  # Color for warning or cautionary actions/information,\n  danger: \"#9A4665\"  # Color for errors, dangerous actions, negative information\n  light: \"#FFFFFF\"  # Bright color for high-contrast on dark elements\n  dark: \"#404041\"  # Dark color for high-contrast on light elements\n  # ALT: All properties in `color` can refer by name to values in `color.palette`, including within `color.palette`.\n  # foreground: black\n  # background: white\n  # primary: blue\n  # success: green\n  # info: teal\n  # ALT: All properties in `color` can refer by name to other properties in `color`.\n\ntypography:\n  fonts:\n    - family: Open Sans  # Font family name\n      source: file  # Source of the font (file, google, bunny, or system)\n      files:  # REQUIRED list of font files for `source: file`, which must have at least one font file. Use placeholder names and comment out the source font section if proprietary fonts are used. (And include a Google Font alternative recommendation.)\n        - path: fonts/open-sans/OpenSans-Variable.ttf\n          # Each file corresponds to a weight and style, both default to \"normal\".\n          weight: 400  # Optional: specify weight for this file\n          style: normal  # Optional: specify style for this file\n        - path: fonts/open-sans/OpenSans-Variable-Italic.ttf\n          style: italic\n    - family: Roboto Slab\n      source: google\n      weight: [600, 900]  # Optional font weights to include (for google and bunny), defaults to all weights\n      # weight: 600..900 # ALT: fonts with variable weights can have a weight range\n      # weight: [thin, normal, bold] # ALT: font weights by name are allowed\n      style: [normal, italic]  # Font styles to include (for google and bunny)\n      display: block  # Font display property (for google). Optional and should not be included in most cases.\n    - family: Fira Code\n      source: bunny # Use Bunny Fonts, a GDPR-compliant alternative to Google Fonts\n      weight: [400, 500, 600] # Optional, same as for `source: google`\n      style: [normal, italic] # Optional, same as for `source: google`\n  \n  # base: Open San # ALT: If a string, sets the base font family\n  base:\n    family: Open Sans  # Optional: Font family for body text\n    weight: 400  # Optional: Font weight for body text\n    size: 16px  # Optional: Font size for body text, allows any CSS value, rem or px are preferred\n    line-height: 1.5  # Optional: Line height for body text\n    # DO NOT INCLUDE color HERE. The base font uses `color.foreground` by default.\n  \n  # headings: Roboto Slab # ALT: If a string, sets the headings font family\n  headings:\n    family: Roboto Slab  # Optional: Font family for headings\n    weight: 600  # Optional: Font weight for headings\n    style: normal  # Optional: Font style for headings\n    line-height: 1.2  # Optional: Line height for headings\n    color: \"#333333\"  # Optional: Color for headings\n    # color: primary # ALT: Can use named colors from `color` or `color.palette`\n  \n  # monospace: Fira Code # ALT: If a string, sets the monospace font family\n  monospace:\n    family: Fira Code  # Optional: Font family for monospace text\n    weight: 400  # Optional: Font weight for monospace text\n    size: 0.9em  # Optional: Font size for monospace text, CSS units allowed but `rem` or `px` preferred\n  monospace-inline: # Inline monospace text, inherits from monospace\n    # Properties of monospace can be overwritten here\n    color: \"#7d12ba\"  # Color for inline monospace text, ALT: named colors from `color` or `color.palette`\n    background-color: \"#f8f9fa\"  # Background color for inline monospace text, ALT: named colors from `color` or `color.palette`\n  monospace-block:\n    color: foreground  # Color for block monospace text, ALT: named colors from `color` or `color.palette`\n    background-color: background  # Background color for block monospace text, ALT: named colors from `color` or `color.palette`\n    line-height: 1.4  # Line height for block monospace text\n  link:\n    weight: 600  # Font weight for links\n    color: \"#0066cc\"  # Optional color for link, defaults `color.primary`. ALT: named colors from `color` or `color.palette`\n    background-color: transparent  # Optional background color for links, ALT: named colors from `color` or `color.palette`\n    decoration: underline  # Optional text decoration for links\n\ndefaults: # Additional Bootstrap, Shiny, or Quarto rules, all optional and only to be used as a last resort\n  bootstrap: Additional scss rules for any contexts that use Bootstrap\n    functions: # string with scss function declarations\n    defaults: # Mapping of Bootstrap variables to default values\n    mixins: # string with scss mixins\n    rules: # string with scss rules\n  quarto:\n    format:\n      # Options specific to output Quarto output formats\n  shiny:\n    theme: # Additional scss rules to add to the Shiny branded theme\n      defaults:\n        # Named bootstrap variables and their default values\n        navbar-bg: $brand-orange # Use Sass variables to access brand colors: $brand-{color_name}\n      rules:\n        # A string of additional scss rules\n```\n\n## Brand best practices\n\nBe careful and be certain to follow these rules when creating the\n`_brand.yml` file:\n\n-   When brands define a range of shades and tints for colors, it's best\n    to choose the midpoint color as the primary color used in the\n    `color.palette`.\n\n-   For logo and font files, use placeholders in the `_brand.yml` with\n    instructions to download the files and place them next to\n    `_brand.yml`.\n\n-   Suggest substitutes for proprietary fonts by finding the closest\n    equivalent fonts on Google Fonts.\n\n-   Prefer hex color syntax for raw color values.\n\n## Using `_brand.yml` in Shiny applications\n\n  To use a _brand.yml file in Shiny for R, pass it as the `theme` argument to a `page_*` function.\n\n```R\nui <- page_sidebar(\n  title = \"Acme Sales Dashboard\",\n  theme = bs_theme(brand = \"acme-brand.yml\"),\n  # ... the rest of your app ...\n)\n```\n`\n\n\nConsider multiple possible implementations of the application, then choose the best one. Remember to create a fully functional Shiny for R app that accurately reflects the user's requirements. If you're unsure about any aspect of the app, make a reasonable decision and explain your choice in a comment.\n\nBe very concise in the text."
        }
      ]
    },
    {
      "role": "assistant",
      "content": [
        {
          "type": "text",
          "text": "An error occurred while processing the response from the language model: 429 {\"type\":\"error\",\"error\":{\"type\":\"rate_limit_error\",\"message\":\"This request would exceed the rate limit for your organization (d2f738e7-cd48-4645-af96-31d3a41e97b4) of 50,000 input tokens per minute. For details, refer to: https://docs.claude.com/en/api/rate-limits. You can see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.\"},\"request_id\":\"req_011CVuZeLkX3BHuKooAu8rwh\"}."
        }
      ]
    },
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "It's been many hours, let's see if the rate limit error is gone"
        }
      ]
    },
    {
      "role": "assistant",
      "content": [
        {
          "type": "text",
          "text": "You're right! Let me try again. How can I help you with Shiny for R today? I'm ready to:\n\n- **Explain Shiny concepts** - reactive values, observers, rendering functions, layouts, etc.\n- **Answer how-to questions** - specific techniques for building features\n- **Create a complete Shiny app** - based on your requirements\n\nWhat would you like to work on?"
        }
      ]
    },
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "Implement the changes we discussed"
        }
      ]
    },
    {
      "role": "assistant",
      "content": [
        {
          "type": "text",
          "text": "I don't have any record of previous discussions in our conversation history. This appears to be a fresh start.\n\nCould you please remind me what changes you'd like to implement? You can:\n\n1. **Describe the app** you want to build (what it does, what features it has)\n2. **Share any existing code** you're working with\n3. **Explain the specific changes** you'd like made\n\nOnce you provide those details, I'll be happy to help!"
        }
      ]
    },
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "I'm not happy with the layout. I'd like the dropdown box on the top left, the graph below that, the data summary top right, and the table bottom right"
        }
      ]
    },
    {
      "role": "assistant",
      "content": [
        {
          "type": "text",
          "text": "I'd be happy to help you reorganize the layout! However, I need to see your current app code first.\n\nCould you please share:\n\n1. **Your current app.R file** (or whatever your app file is named)\n2. Or a description of what your app currently does\n\nOnce I see the code, I can restructure it to match your desired layout:\n- Dropdown box - top left\n- Graph - below dropdown\n- Data summary - top right\n- Table - bottom right"
        }
      ]
    },
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "You should be able to see app.R in this folder"
        }
      ]
    },
    {
      "role": "assistant",
      "content": [
        {
          "type": "text",
          "text": "I don't see an app.R file in the workspace yet. Let me check the project structure to see what files are available.\n\nGreat! I found your app.R file. Let me read it so I can help you reorganize the layout.\n\nPerfect! I can see your app. I'll reorganize it to match your desired layout using a grid-based approach:\n- **Top left**: Dropdown box\n- **Below that**: Graph\n- **Top right**: Data summary\n- **Bottom right**: Table\n\nDone! I've reorganized your app layout using bslib's `layout_columns()` function. Here's what changed:\n\n**New Layout:**\n- **Left column (50%)**: Graphs (package and/or component plots based on your filter)\n- **Right column (50%)**: \n  - **Top**: Data summary card\n  - **Bottom**: Data table card\n\nThe filters remain in the sidebar at the top left as before. The layout is responsive and uses bslib cards for clean styling. All your filtering logic works the same wayonly the visual arrangement has changed."
        }
      ]
    },
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "Why am I getting an error?"
        }
      ]
    },
    {
      "role": "assistant",
      "content": [
        {
          "type": "text",
          "text": "I don't see an error message in your message. Could you please share:\n\n1. **The exact error message** you're seeing\n2. **Where it appears** (console, browser, etc.)\n3. **What you were doing** when the error occurred (loading the app, clicking a button, selecting a dropdown, etc.)\n\nOnce you provide those details, I can help you fix it!"
        }
      ]
    },
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "It just says \"An error has occurred!\""
        }
      ]
    },
    {
      "role": "assistant",
      "content": [
        {
          "type": "text",
          "text": "That's a generic Shiny error. Let me help you troubleshoot. Can you:\n\n1. **Check the R console** for detailed error messages (usually appears below the Shiny output)\n2. **Open your browser's developer console** (F12 or right-click  Inspect  Console tab) to see if there are JavaScript errors\n3. **Tell me if the app loads at all** or if it fails immediately on startup\n\nAlternatively, could you share your current app.R code so I can review it for potential issues? That way I can spot the problem directly."
        }
      ]
    },
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "it doesn't load at all"
        }
      ]
    },
    {
      "role": "assistant",
      "content": [
        {
          "type": "text",
          "text": "Let me check your app.R file to see what might be causing it to fail on startup.\n\nI found the issue! There are syntax errors in your `summary_text` output. The escape sequences are malformed. Here's the fix:\n\n"
        }
      ]
    },
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "Are you able to see the app.R shiny app?"
        }
      ]
    }
  ]
}
2025-12-08 22:14:57.508 [trace] [Anthropic] RECV messages.stream [req_011CVvPK1uG6WV43DqehUxJG]: {
  "model": "claude-sonnet-4-5-20250929",
  "id": "msg_014RX4LKHs2rdnPxUjPTYNLP",
  "type": "message",
  "role": "assistant",
  "content": [
    {
      "type": "text",
      "text": "Yes, I can see your app.R file. Let me read it again to check the current state."
    },
    {
      "type": "tool_use",
      "id": "toolu_01GWXajCsVpzK5FQTsB9cmtG",
      "name": "copilot_readFile",
      "input": {
        "filePath": "app.R",
        "startLine": 1,
        "endLine": 200
      }
    }
  ],
  "stop_reason": "tool_use",
  "stop_sequence": null,
  "usage": {
    "input_tokens": 45644,
    "cache_creation_input_tokens": 0,
    "cache_read_input_tokens": 0,
    "cache_creation": {
      "ephemeral_5m_input_tokens": 0,
      "ephemeral_1h_input_tokens": 0
    },
    "output_tokens": 118,
    "service_tier": "standard"
  }
}
2025-12-08 22:15:46.343 [warning] [Anthropic] Tool 'copilot_testFailure' is missing input schema type; defaulting to 'object'
2025-12-08 22:15:49.642 [info] [Anthropic] Start request req_011CVvPNyEdRimMGSEbvNwwW to claude-sonnet-4-5-20250929: 19 messages
2025-12-08 22:15:49.645 [trace] [Anthropic] SEND messages.stream [req_011CVvPNyEdRimMGSEbvNwwW]: {
  "model": "claude-sonnet-4-5-20250929",
  "max_tokens": 4096,
  "tools": [
    {
      "name": "configure_notebook",
      "description": "Tool used to configure a Notebook. ALWAYS use this tool before running/executing any Notebook Cells for the first time or before listing/installing packages in Notebooks for the first time. I.e. there is no need to use this tool more than once for the same notebook.",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePath": {
            "description": "The absolute path of the notebook with the active kernel.",
            "type": "string"
          }
        },
        "required": [
          "filePath"
        ]
      }
    },
    {
      "name": "copilot_applyPatch",
      "description": "Edit text files. Do not use this tool to edit Jupyter notebooks. `apply_patch` allows you to execute a diff/patch against a text file, but the format of the diff specification is unique to this task, so pay careful attention to these instructions. To use the `apply_patch` command, you should pass a message of the following structure as \"input\":\n\n*** Begin Patch\n[YOUR_PATCH]\n*** End Patch\n\nWhere [YOUR_PATCH] is the actual content of your patch, specified in the following V4A diff format.\n\n*** [ACTION] File: [/absolute/path/to/file] -> ACTION can be one of Add, Update, or Delete.\nAn example of a message that you might pass as \"input\" to this function, in order to apply a patch, is shown below.\n\n*** Begin Patch\n*** Update File: /Users/someone/pygorithm/searching/binary_search.py\n@@class BaseClass\n@@    def search():\n-        pass\n+        raise NotImplementedError()\n\n@@class Subclass\n@@    def search():\n-        pass\n+        raise NotImplementedError()\n\n*** End Patch\nDo not use line numbers in this diff format.",
      "input_schema": {
        "type": "object",
        "properties": {
          "input": {
            "type": "string",
            "description": "The edit patch to apply."
          },
          "explanation": {
            "type": "string",
            "description": "A short description of what the tool call is aiming to achieve."
          }
        },
        "required": [
          "input",
          "explanation"
        ]
      }
    },
    {
      "name": "copilot_createDirectory",
      "description": "Create a new directory structure in the workspace. Will recursively create all directories in the path, like mkdir -p. You do not need to use this tool before using create_file, that tool will automatically create the needed directories.",
      "input_schema": {
        "type": "object",
        "properties": {
          "dirPath": {
            "type": "string",
            "description": "The absolute path to the directory to create."
          }
        },
        "required": [
          "dirPath"
        ]
      }
    },
    {
      "name": "copilot_createFile",
      "description": "This is a tool for creating a new file in the workspace. The file will be created with the specified content. The directory will be created if it does not already exist. Never use this tool to edit a file that already exists.",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePath": {
            "type": "string",
            "description": "The absolute path to the file to create."
          },
          "content": {
            "type": "string",
            "description": "The content to write to the file."
          }
        },
        "required": [
          "filePath",
          "content"
        ]
      }
    },
    {
      "name": "copilot_createNewJupyterNotebook",
      "description": "Generates a new Jupyter Notebook (.ipynb) in VS Code. Jupyter Notebooks are interactive documents commonly used for data exploration, analysis, visualization, and combining code with narrative text. Prefer creating plain Python files or similar unless a user explicitly requests creating a new Jupyter Notebook or already has a Jupyter Notebook opened or exists in the workspace.",
      "input_schema": {
        "type": "object",
        "properties": {
          "query": {
            "type": "string",
            "description": "The query to use to generate the jupyter notebook. This should be a clear and concise description of the notebook the user wants to create."
          }
        },
        "required": [
          "query"
        ]
      }
    },
    {
      "name": "copilot_createNewWorkspace",
      "description": "Get comprehensive setup steps to help the user create complete project structures in a VS Code workspace. This tool is designed for full project initialization and scaffolding, not for creating individual files.\n\nWhen to use this tool:\n- User wants to create a new complete project from scratch\n- Setting up entire project frameworks (TypeScript projects, React apps, Node.js servers, etc.)\n- Initializing Model Context Protocol (MCP) servers with full structure\n- Creating VS Code extensions with proper scaffolding\n- Setting up Next.js, Vite, or other framework-based projects\n- User asks for \"new project\", \"create a workspace\", \"set up a [framework] project\"\n- Need to establish complete development environment with dependencies, config files, and folder structure\n\nWhen NOT to use this tool:\n- Creating single files or small code snippets\n- Adding individual files to existing projects\n- Making modifications to existing codebases\n- User asks to \"create a file\" or \"add a component\"\n- Simple code examples or demonstrations\n- Debugging or fixing existing code\n\nThis tool provides complete project setup including:\n- Folder structure creation\n- Package.json and dependency management\n- Configuration files (tsconfig, eslint, etc.)\n- Initial boilerplate code\n- Development environment setup\n- Build and run instructions\n\nUse other file creation tools for individual files within existing projects.",
      "input_schema": {
        "type": "object",
        "properties": {
          "query": {
            "type": "string",
            "description": "The query to use to generate the new workspace. This should be a clear and concise description of the workspace the user wants to create."
          }
        },
        "required": [
          "query"
        ]
      }
    },
    {
      "name": "copilot_editFiles",
      "description": "This is a placeholder tool, do not use",
      "input_schema": {
        "type": "object",
        "properties": {},
        "required": []
      }
    },
    {
      "name": "copilot_editNotebook",
      "description": "This is a tool for editing an existing Notebook file in the workspace. Generate the \"explanation\" property first.\nThe system is very smart and can understand how to apply your edits to the notebooks.\nWhen updating the content of an existing cell, ensure newCode preserves whitespace and indentation exactly and does NOT include any code markers such as (...existing code...).",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePath": {
            "type": "string",
            "description": "An absolute path to the notebook file to edit, or the URI of a untitled, not yet named, file, such as `untitled:Untitled-1."
          },
          "cellId": {
            "type": "string",
            "description": "Id of the cell that needs to be deleted or edited. Use the value `TOP`, `BOTTOM` when inserting a cell at the top or bottom of the notebook, else provide the id of the cell after which a new cell is to be inserted. Remember, if a cellId is provided and editType=insert, then a cell will be inserted after the cell with the provided cellId."
          },
          "newCode": {
            "anyOf": [
              {
                "type": "string",
                "description": "The code for the new or existing cell to be edited. Code should not be wrapped within <VSCode.Cell> tags. Do NOT include code markers such as (...existing code...) to indicate existing code."
              },
              {
                "type": "array",
                "items": {
                  "type": "string",
                  "description": "The code for the new or existing cell to be edited. Code should not be wrapped within <VSCode.Cell> tags"
                }
              }
            ]
          },
          "language": {
            "type": "string",
            "description": "The language of the cell. `markdown`, `python`, `javascript`, `julia`, etc."
          },
          "editType": {
            "type": "string",
            "enum": [
              "insert",
              "delete",
              "edit"
            ],
            "description": "The operation peformed on the cell, whether `insert`, `delete` or `edit`.\nUse the `editType` field to specify the operation: `insert` to add a new cell, `edit` to modify an existing cell's content, and `delete` to remove a cell."
          }
        },
        "required": [
          "filePath",
          "editType",
          "cellId"
        ]
      }
    },
    {
      "name": "copilot_fetchWebPage",
      "description": "Fetches the main content from a web page. This tool is useful for summarizing or analyzing the content of a webpage. You should use this tool when you think the user is looking for information from a specific webpage.",
      "input_schema": {
        "type": "object",
        "properties": {
          "urls": {
            "type": "array",
            "items": {
              "type": "string"
            },
            "description": "An array of URLs to fetch content from."
          },
          "query": {
            "type": "string",
            "description": "The query to search for in the web page's content. This should be a clear and concise description of the content you want to find."
          }
        },
        "required": [
          "urls",
          "query"
        ]
      }
    },
    {
      "name": "copilot_findFiles",
      "description": "Search for files in the workspace by glob pattern. This only returns the paths of matching files. Use this tool when you know the exact filename pattern of the files you're searching for. Glob patterns match from the root of the workspace folder. Examples:\n- **/*.{js,ts} to match all js/ts files in the workspace.\n- src/** to match all files under the top-level src folder.\n- **/foo/**/*.js to match all js files under any foo folder in the workspace.",
      "input_schema": {
        "type": "object",
        "properties": {
          "query": {
            "type": "string",
            "description": "Search for files with names or paths matching this glob pattern."
          },
          "maxResults": {
            "type": "number",
            "description": "The maximum number of results to return. Do not use this unless necessary, it can slow things down. By default, only some matches are returned. If you use this and don't see what you're looking for, you can try again with a more specific query or a larger maxResults."
          }
        },
        "required": [
          "query"
        ]
      }
    },
    {
      "name": "copilot_findTestFiles",
      "description": "For a source code file, find the file that contains the tests. For a test file find the file that contains the code under test.",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePaths": {
            "type": "array",
            "items": {
              "type": "string"
            }
          }
        },
        "required": [
          "filePaths"
        ]
      }
    },
    {
      "name": "copilot_findTextInFiles",
      "description": "Do a fast text search in the workspace. Use this tool when you want to search with an exact string or regex. If you are not sure what words will appear in the workspace, prefer using regex patterns with alternation (|) or character classes to search for multiple potential words at once instead of making separate searches. For example, use 'function|method|procedure' to look for all of those words at once. Use includePattern to search within files matching a specific pattern, or in a specific file, using a relative path. Use this tool when you want to see an overview of a particular file, instead of using read_file many times to look for code within a file.",
      "input_schema": {
        "type": "object",
        "properties": {
          "query": {
            "type": "string",
            "description": "The pattern to search for in files in the workspace. Use regex with alternation (e.g., 'word1|word2|word3') or character classes to find multiple potential words in a single search. Be sure to set the isRegexp property properly to declare whether it's a regex or plain text pattern. Is case-insensitive."
          },
          "isRegexp": {
            "type": "boolean",
            "description": "Whether the pattern is a regex."
          },
          "includePattern": {
            "type": "string",
            "description": "Search files matching this glob pattern. Will be applied to the relative path of files within the workspace. To search recursively inside a folder, use a proper glob pattern like \"src/folder/**\". Do not use | in includePattern."
          },
          "maxResults": {
            "type": "number",
            "description": "The maximum number of results to return. Do not use this unless necessary, it can slow things down. By default, only some matches are returned. If you use this and don't see what you're looking for, you can try again with a more specific query or a larger maxResults."
          }
        },
        "required": [
          "query",
          "isRegexp"
        ]
      }
    },
    {
      "name": "copilot_getChangedFiles",
      "description": "Get git diffs of current file changes in a git repository. Don't forget that you can use run_in_terminal to run git commands in a terminal as well.",
      "input_schema": {
        "type": "object",
        "properties": {
          "repositoryPath": {
            "type": "string",
            "description": "The absolute path to the git repository to look for changes in. If not provided, the active git repository will be used."
          },
          "sourceControlState": {
            "type": "array",
            "items": {
              "type": "string",
              "enum": [
                "staged",
                "unstaged",
                "merge-conflicts"
              ]
            },
            "description": "The kinds of git state to filter by. Allowed values are: 'staged', 'unstaged', and 'merge-conflicts'. If not provided, all states will be included."
          }
        }
      }
    },
    {
      "name": "copilot_getDocInfo",
      "description": "Find information about how to document it a symbol like a class or function. This tool is useful for generating documentation comments for code symbols. You should use this tool when you think the user is looking for information about how to document a specific code symbol.",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePaths": {
            "type": "array",
            "items": {
              "type": "string"
            },
            "description": "The file paths for which documentation information is needed."
          }
        },
        "required": [
          "filePaths"
        ]
      }
    },
    {
      "name": "copilot_getErrors",
      "description": "Get any compile or lint errors in a specific file or across all files. If the user mentions errors or problems in a file, they may be referring to these. Use the tool to see the same errors that the user is seeing. If the user asks you to analyze all errors, or does not specify a file, use this tool to gather errors for all files. Also use this tool after editing a file to validate the change.",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePaths": {
            "description": "The absolute paths to the files or folders to check for errors. Omit 'filePaths' when retrieving all errors.",
            "type": "array",
            "items": {
              "type": "string"
            }
          }
        }
      }
    },
    {
      "name": "copilot_getNotebookSummary",
      "description": "This is a tool returns the list of the Notebook cells along with the id, cell types, line ranges, language, execution information and output mime types for each cell. This is useful to get Cell Ids when executing a notebook or determine what cells have been executed and what order, or what cells have outputs. If required to read contents of a cell use this to determine the line range of a cells, and then use read_file tool to read a specific line range. Requery this tool if the contents of the notebook change.",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePath": {
            "type": "string",
            "description": "An absolute path to the notebook file with the cell to run, or the URI of a untitled, not yet named, file, such as `untitled:Untitled-1.ipynb"
          }
        },
        "required": [
          "filePath"
        ]
      }
    },
    {
      "name": "copilot_getProjectSetupInfo",
      "description": "Do not call this tool without first calling the tool to create a workspace. This tool provides a project setup information for a Visual Studio Code workspace based on a project type and programming language.",
      "input_schema": {
        "type": "object",
        "properties": {
          "projectType": {
            "type": "string",
            "description": "The type of project to create. Supported values are: 'python-script', 'python-project', 'mcp-server', 'model-context-protocol-server', 'vscode-extension', 'next-js', 'vite' and 'other'"
          }
        },
        "required": [
          "projectType"
        ]
      }
    },
    {
      "name": "copilot_getSearchResults",
      "description": "The results from the search view",
      "input_schema": {
        "type": "object",
        "properties": {},
        "required": []
      }
    },
    {
      "name": "copilot_getVSCodeAPI",
      "description": "Get comprehensive VS Code API documentation and references for extension development. This tool provides authoritative documentation for VS Code's extensive API surface, including proposed APIs, contribution points, and best practices. Use this tool for understanding complex VS Code API interactions.\n\nWhen to use this tool:\n- User asks about specific VS Code APIs, interfaces, or extension capabilities\n- Need documentation for VS Code extension contribution points (commands, views, settings, etc.)\n- Questions about proposed APIs and their usage patterns\n- Understanding VS Code extension lifecycle, activation events, and packaging\n- Best practices for VS Code extension development architecture\n- API examples and code patterns for extension features\n- Troubleshooting extension-specific issues or API limitations\n\nWhen NOT to use this tool:\n- Creating simple standalone files or scripts unrelated to VS Code extensions\n- General programming questions not specific to VS Code extension development\n- Questions about using VS Code as an editor (user-facing features)\n- Non-extension related development tasks\n- File creation or editing that doesn't involve VS Code extension APIs\n\nCRITICAL usage guidelines:\n1. Always include specific API names, interfaces, or concepts in your query\n2. Mention the extension feature you're trying to implement\n3. Include context about proposed vs stable APIs when relevant\n4. Reference specific contribution points when asking about extension manifest\n5. Be specific about the VS Code version or API version when known\n\nScope: This tool is for EXTENSION DEVELOPMENT ONLY - building tools that extend VS Code itself, not for general file creation or non-extension programming tasks.",
      "input_schema": {
        "type": "object",
        "properties": {
          "query": {
            "type": "string",
            "description": "The query to search vscode documentation for. Should contain all relevant context."
          }
        },
        "required": [
          "query"
        ]
      }
    },
    {
      "name": "copilot_githubRepo",
      "description": "Searches a GitHub repository for relevant source code snippets. Only use this tool if the user is very clearly asking for code snippets from a specific GitHub repository. Do not use this tool for Github repos that the user has open in their workspace.",
      "input_schema": {
        "type": "object",
        "properties": {
          "repo": {
            "type": "string",
            "description": "The name of the Github repository to search for code in. Should must be formatted as '<owner>/<repo>'."
          },
          "query": {
            "type": "string",
            "description": "The query to search for repo. Should contain all relevant context."
          }
        },
        "required": [
          "repo",
          "query"
        ]
      }
    },
    {
      "name": "copilot_insertEdit",
      "description": "Insert new code into an existing file in the workspace. Use this tool once per file that needs to be modified, even if there are multiple changes for a file. Generate the \"explanation\" property first.\nThe system is very smart and can understand how to apply your edits to the files, you just need to provide minimal hints.\nAvoid repeating existing code, instead use comments to represent regions of unchanged code. Be as concise as possible. For example:\n// ...existing code...\n{ changed code }\n// ...existing code...\n{ changed code }\n// ...existing code...\n\nHere is an example of how you should use format an edit to an existing Person class:\nclass Person {\n\t// ...existing code...\n\tage: number;\n\t// ...existing code...\n\tgetAge() {\n\treturn this.age;\n\t}\n}",
      "input_schema": {
        "type": "object",
        "properties": {
          "explanation": {
            "type": "string",
            "description": "A short explanation of the edit being made."
          },
          "filePath": {
            "type": "string",
            "description": "An absolute path to the file to edit."
          },
          "code": {
            "type": "string",
            "description": "The code change to apply to the file.\nThe system is very smart and can understand how to apply your edits to the files, you just need to provide minimal hints.\nAvoid repeating existing code, instead use comments to represent regions of unchanged code. Be as concise as possible. For example:\n// ...existing code...\n{ changed code }\n// ...existing code...\n{ changed code }\n// ...existing code...\n\nHere is an example of how you should use format an edit to an existing Person class:\nclass Person {\n\t// ...existing code...\n\tage: number;\n\t// ...existing code...\n\tgetAge() {\n\t\treturn this.age;\n\t}\n}"
          }
        },
        "required": [
          "explanation",
          "filePath",
          "code"
        ]
      }
    },
    {
      "name": "copilot_installExtension",
      "description": "Install an extension in VS Code. Use this tool to install an extension in Visual Studio Code as part of a new workspace creation process only.",
      "input_schema": {
        "type": "object",
        "properties": {
          "id": {
            "type": "string",
            "description": "The ID of the extension to install. This should be in the format <publisher>.<extension>."
          },
          "name": {
            "type": "string",
            "description": "The name of the extension to install. This should be a clear and concise description of the extension."
          }
        },
        "required": [
          "id",
          "name"
        ]
      }
    },
    {
      "name": "copilot_listCodeUsages",
      "description": "Request to list all usages (references, definitions, implementations etc) of a function, class, method, variable etc. Use this tool when \n1. Looking for a sample implementation of an interface or class\n2. Checking how a function is used throughout the codebase.\n3. Including and updating all usages when changing a function, method, or constructor",
      "input_schema": {
        "type": "object",
        "properties": {
          "symbolName": {
            "type": "string",
            "description": "The name of the symbol, such as a function name, class name, method name, variable name, etc."
          },
          "filePaths": {
            "type": "array",
            "description": "One or more file paths which likely contain the definition of the symbol. For instance the file which declares a class or function. This is optional but will speed up the invocation of this tool and improve the quality of its output.",
            "items": {
              "type": "string"
            }
          }
        },
        "required": [
          "symbolName"
        ]
      }
    },
    {
      "name": "copilot_listDirectory",
      "description": "List the contents of a directory. Result will have the name of the child. If the name ends in /, it's a folder, otherwise a file",
      "input_schema": {
        "type": "object",
        "properties": {
          "path": {
            "type": "string",
            "description": "The absolute path to the directory to list."
          }
        },
        "required": [
          "path"
        ]
      }
    },
    {
      "name": "copilot_multiReplaceString",
      "description": "This tool allows you to apply multiple replace_string_in_file operations in a single call, which is more efficient than calling replace_string_in_file multiple times. It takes an array of replacement operations and applies them sequentially. Each replacement operation has the same parameters as replace_string_in_file: filePath, oldString, newString, and explanation. This tool is ideal when you need to make multiple edits across different files or multiple edits in the same file. The tool will provide a summary of successful and failed operations.",
      "input_schema": {
        "type": "object",
        "properties": {
          "explanation": {
            "type": "string",
            "description": "A brief explanation of what the multi-replace operation will accomplish."
          },
          "replacements": {
            "type": "array",
            "description": "An array of replacement operations to apply sequentially.",
            "items": {
              "type": "object",
              "properties": {
                "explanation": {
                  "type": "string",
                  "description": "A brief explanation of this specific replacement operation."
                },
                "filePath": {
                  "type": "string",
                  "description": "An absolute path to the file to edit."
                },
                "oldString": {
                  "type": "string",
                  "description": "The exact literal text to replace, preferably unescaped. Include at least 3 lines of context BEFORE and AFTER the target text, matching whitespace and indentation precisely. If this string is not the exact literal text or does not match exactly, this replacement will fail."
                },
                "newString": {
                  "type": "string",
                  "description": "The exact literal text to replace `oldString` with, preferably unescaped. Provide the EXACT text. Ensure the resulting code is correct and idiomatic."
                }
              },
              "required": [
                "explanation",
                "filePath",
                "oldString",
                "newString"
              ]
            },
            "minItems": 1
          }
        },
        "required": [
          "explanation",
          "replacements"
        ]
      }
    },
    {
      "name": "copilot_openSimpleBrowser",
      "description": "Preview a website or open a URL in the editor's Simple Browser. Useful for quickly viewing locally hosted websites, demos, or resources without leaving the coding environment.",
      "input_schema": {
        "type": "object",
        "properties": {
          "url": {
            "type": "string",
            "description": "The website URL to preview or open in the Simple Browser inside the editor. Must be either an http or https URL"
          }
        },
        "required": [
          "url"
        ]
      }
    },
    {
      "name": "copilot_readFile",
      "description": "Read the contents of a file.\n\nYou must specify the line range you're interested in. Line numbers are 1-indexed. If the file contents returned are insufficient for your task, you may call this tool again to retrieve more content. Prefer reading larger ranges over doing many small reads.",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePath": {
            "description": "The absolute path of the file to read.",
            "type": "string"
          },
          "startLine": {
            "type": "number",
            "description": "The line number to start reading from, 1-based."
          },
          "endLine": {
            "type": "number",
            "description": "The inclusive line number to end reading at, 1-based."
          }
        },
        "required": [
          "filePath",
          "startLine",
          "endLine"
        ]
      }
    },
    {
      "name": "copilot_readNotebookCellOutput",
      "description": "This tool will retrieve the output for a notebook cell from its most recent execution or restored from disk. The cell may have output even when it has not been run in the current kernel session. This tool has a higher token limit for output length than the runNotebookCell tool.",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePath": {
            "type": "string",
            "description": "An absolute path to the notebook file with the cell to run, or the URI of a untitled, not yet named, file, such as `untitled:Untitled-1.ipynb"
          },
          "cellId": {
            "type": "string",
            "description": "The ID of the cell for which output should be retrieved."
          }
        },
        "required": [
          "filePath",
          "cellId"
        ]
      }
    },
    {
      "name": "copilot_readProjectStructure",
      "description": "Get a file tree representation of the workspace.",
      "input_schema": {
        "type": "object",
        "properties": {},
        "required": []
      }
    },
    {
      "name": "copilot_replaceString",
      "description": "This is a tool for making edits in an existing file in the workspace. For moving or renaming files, use run in terminal tool with the 'mv' command instead. For larger edits, split them into smaller edits and call the edit tool multiple times to ensure accuracy. Before editing, always ensure you have the context to understand the file's contents and context. To edit a file, provide: 1) filePath (absolute path), 2) oldString (MUST be the exact literal text to replace including all whitespace, indentation, newlines, and surrounding code etc), and 3) newString (MUST be the exact literal text to replace \\`oldString\\` with (also including all whitespace, indentation, newlines, and surrounding code etc.). Ensure the resulting code is correct and idiomatic.). Each use of this tool replaces exactly ONE occurrence of oldString.\n\nCRITICAL for \\`oldString\\`: Must uniquely identify the single instance to change. Include at least 3 lines of context BEFORE and AFTER the target text, matching whitespace and indentation precisely. If this string matches multiple locations, or does not match exactly, the tool will fail. Never use 'Lines 123-456 omitted' from summarized documents or ...existing code... comments in the oldString or newString.",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePath": {
            "type": "string",
            "description": "An absolute path to the file to edit."
          },
          "oldString": {
            "type": "string",
            "description": "The exact literal text to replace, preferably unescaped. For single replacements (default), include at least 3 lines of context BEFORE and AFTER the target text, matching whitespace and indentation precisely. For multiple replacements, specify expected_replacements parameter. If this string is not the exact literal text (i.e. you escaped it) or does not match exactly, the tool will fail."
          },
          "newString": {
            "type": "string",
            "description": "The exact literal text to replace `old_string` with, preferably unescaped. Provide the EXACT text. Ensure the resulting code is correct and idiomatic."
          }
        },
        "required": [
          "filePath",
          "oldString",
          "newString"
        ]
      }
    },
    {
      "name": "copilot_runNotebookCell",
      "description": "This is a tool for running a code cell in a notebook file directly in the notebook editor. The output from the execution will be returned. Code cells should be run as they are added or edited when working through a problem to bring the kernel state up to date and ensure the code executes successfully. Code cells are ready to run and don't require any pre-processing. If asked to run the first cell in a notebook, you should run the first code cell since markdown cells cannot be executed. NOTE: Avoid executing Markdown cells or providing Markdown cell IDs, as Markdown cells cannot be  executed.",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePath": {
            "type": "string",
            "description": "An absolute path to the notebook file with the cell to run, or the URI of a untitled, not yet named, file, such as `untitled:Untitled-1.ipynb"
          },
          "reason": {
            "type": "string",
            "description": "An optional explanation of why the cell is being run. This will be shown to the user before the tool is run and is not necessary if it's self-explanatory."
          },
          "cellId": {
            "type": "string",
            "description": "The ID for the code cell to execute. Avoid providing markdown cell IDs as nothing will be executed."
          },
          "continueOnError": {
            "type": "boolean",
            "description": "Whether or not execution should continue for remaining cells if an error is encountered. Default to false unless instructed otherwise."
          }
        },
        "required": [
          "filePath",
          "cellId"
        ]
      }
    },
    {
      "name": "copilot_runVscodeCommand",
      "description": "Run a command in VS Code. Use this tool to run a command in Visual Studio Code as part of a new workspace creation process only.",
      "input_schema": {
        "type": "object",
        "properties": {
          "commandId": {
            "type": "string",
            "description": "The ID of the command to execute. This should be in the format <command>."
          },
          "name": {
            "type": "string",
            "description": "The name of the command to execute. This should be a clear and concise description of the command."
          },
          "args": {
            "type": "array",
            "description": "The arguments to pass to the command. This should be an array of strings.",
            "items": {
              "type": "string"
            }
          }
        },
        "required": [
          "commandId",
          "name"
        ]
      }
    },
    {
      "name": "copilot_searchCodebase",
      "description": "Run a natural language search for relevant code or documentation comments from the user's current workspace. Returns relevant code snippets from the user's current workspace if it is large, or the full contents of the workspace if it is small.",
      "input_schema": {
        "type": "object",
        "properties": {
          "query": {
            "type": "string",
            "description": "The query to search the codebase for. Should contain all relevant context. Should ideally be text that might appear in the codebase, such as function names, variable names, or comments."
          }
        },
        "required": [
          "query"
        ]
      }
    },
    {
      "name": "copilot_searchWorkspaceSymbols",
      "description": "Search the user's workspace for code symbols using language services. Use this tool when the user is looking for a specific symbol in their workspace.",
      "input_schema": {
        "type": "object",
        "properties": {
          "symbolName": {
            "type": "string",
            "description": "The symbol to search for, such as a function name, class name, or variable name."
          }
        },
        "required": [
          "symbolName"
        ]
      }
    },
    {
      "name": "copilot_testFailure",
      "description": "Includes test failure information in the prompt.",
      "input_schema": {
        "type": "object"
      }
    },
    {
      "name": "create_and_run_task",
      "description": "Creates and runs a build, run, or custom task for the workspace by generating or adding to a tasks.json file based on the project structure (such as package.json or README.md). If the user asks to build, run, launch and they have no tasks.json file, use this tool. If they ask to create or add a task, use this tool.",
      "input_schema": {
        "type": "object",
        "properties": {
          "workspaceFolder": {
            "type": "string",
            "description": "The absolute path of the workspace folder where the tasks.json file will be created."
          },
          "task": {
            "type": "object",
            "description": "The task to add to the new tasks.json file.",
            "properties": {
              "label": {
                "type": "string",
                "description": "The label of the task."
              },
              "type": {
                "type": "string",
                "description": "The type of the task. The only supported value is 'shell'.",
                "enum": [
                  "shell"
                ]
              },
              "command": {
                "type": "string",
                "description": "The shell command to run for the task. Use this to specify commands for building or running the application."
              },
              "args": {
                "type": "array",
                "description": "The arguments to pass to the command.",
                "items": {
                  "type": "string"
                }
              },
              "isBackground": {
                "type": "boolean",
                "description": "Whether the task runs in the background without blocking the UI or other tasks. Set to true for long-running processes like watch tasks or servers that should continue executing without requiring user attention. When false, the task will block the terminal until completion."
              },
              "problemMatcher": {
                "type": "array",
                "description": "The problem matcher to use to parse task output for errors and warnings. Can be a predefined matcher like '$tsc' (TypeScript), '$eslint - stylish', '$gcc', etc., or a custom pattern defined in tasks.json. This helps VS Code display errors in the Problems panel and enables quick navigation to error locations.",
                "items": {
                  "type": "string"
                }
              },
              "group": {
                "type": "string",
                "description": "The group to which the task belongs."
              }
            },
            "required": [
              "label",
              "type",
              "command"
            ]
          }
        },
        "required": [
          "task",
          "workspaceFolder"
        ]
      }
    },
    {
      "name": "documentCreate",
      "description": "Create a new document in the workspace.",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePath": {
            "type": "string",
            "description": "The path to the document to create, including the file name and extension. This path must be relative to the workspace folder."
          },
          "workspaceFolder": {
            "type": "string",
            "description": "The workspace folder to create the document in. If not specified, the document will be created in the first workspace folder."
          },
          "content": {
            "type": "string",
            "description": "The initial content of the document. If not specified, the document will be created empty."
          },
          "errorIfExists": {
            "type": "boolean",
            "description": "Whether to throw an error if the document already exists. If false, the existing document will be opened instead.",
            "default": true
          }
        }
      }
    },
    {
      "name": "documentEdit",
      "description": "Output an edited version of the document.",
      "input_schema": {
        "type": "object",
        "properties": {
          "deltas": {
            "type": "array",
            "description": "The array of changes to apply.",
            "items": {
              "type": "object",
              "properties": {
                "delete": {
                  "type": "string",
                  "description": "Text to delete from the document."
                },
                "replace": {
                  "type": "string",
                  "description": "Text to replace the deleted text with."
                }
              }
            }
          }
        }
      }
    },
    {
      "name": "editNotebookCells",
      "description": "Perform edit operations on notebook cells. Use operation='add' to create new cells (requires cellType, index, and content), operation='update' to modify existing cells (requires cellIndex and content), or operation='delete' to remove cells (requires cellIndex). Use index=-1 to append cells at the end when adding.",
      "input_schema": {
        "type": "object",
        "properties": {
          "operation": {
            "type": "string",
            "enum": [
              "add",
              "update",
              "delete"
            ],
            "description": "Type of edit operation to perform. 'add' creates a new cell, 'update' modifies existing cell content, 'delete' removes a cell."
          },
          "cellType": {
            "type": "string",
            "enum": [
              "code",
              "markdown"
            ],
            "description": "Type of cell to create. Required when operation is 'add'. Use 'code' for executable cells, 'markdown' for documentation."
          },
          "index": {
            "type": "number",
            "description": "Position to insert the cell (0-based). Required when operation is 'add'. Use -1 to append at the end."
          },
          "content": {
            "type": "string",
            "description": "Cell content. Required when operation is 'add' or 'update'."
          },
          "cellIndex": {
            "type": "number",
            "description": "Index of the cell to modify or delete (0-based). Required when operation is 'update' or 'delete'."
          }
        },
        "required": [
          "operation"
        ]
      }
    },
    {
      "name": "executeCode",
      "description": "Execute a piece of code in the specified programming language and return the result. You prefer to show code over running it unless given an imperative. You prefer this tool to the terminal and other ways of running code when there is a session available with the correct language.",
      "input_schema": {
        "type": "object",
        "properties": {
          "sessionIdentifier": {
            "type": "string",
            "description": "The identifier of the session to execute the code in."
          },
          "code": {
            "type": "string",
            "description": "The code to execute."
          },
          "language": {
            "type": "string",
            "description": "The programming language of the code."
          },
          "summary": {
            "type": "string",
            "description": "A very short summary of the task the code is performing, beginning with a verb and not to exceed 7 words. Shown to the user to help them understand what the code will do."
          }
        }
      }
    },
    {
      "name": "get_terminal_output",
      "description": "Get the output of a terminal command previously started with run_in_terminal",
      "input_schema": {
        "type": "object",
        "properties": {
          "id": {
            "type": "string",
            "description": "The ID of the terminal to check."
          }
        },
        "required": [
          "id"
        ]
      }
    },
    {
      "name": "getChangedFiles",
      "description": "Get summaries and git diffs for current changes to files in this workspace.",
      "input_schema": {
        "type": "object",
        "properties": {},
        "required": []
      }
    },
    {
      "name": "getDirectoryStructure",
      "description": "Returns a list of directories without listing files within them. Empty directories are included. Unlike getProjectTree, this tool focuses on directories only and is more efficient for directory queries. Prefer this tool over running code in the terminal for finding directories.",
      "input_schema": {
        "type": "object",
        "properties": {
          "path": {
            "type": "string",
            "description": "Starting path to explore (relative to workspace root). Defaults to workspace root if not specified."
          },
          "maxDepth": {
            "type": "number",
            "description": "Maximum recursion depth. 1 shows only immediate subdirectories. Must be between 1 and 3.",
            "default": 1,
            "minimum": 1,
            "maximum": 3
          },
          "maxDirectories": {
            "type": "number",
            "description": "Maximum number of directories to return.",
            "default": 50,
            "maximum": 100
          },
          "include": {
            "type": "array",
            "items": {
              "type": "string",
              "description": "A glob pattern to include directories."
            },
            "description": "Glob patterns to include directories. Only directories matching these patterns will be returned."
          },
          "exclude": {
            "type": "array",
            "items": {
              "type": "string",
              "description": "A glob pattern to exclude directories."
            },
            "description": "Glob patterns to exclude directories. These patterns will be applied in addition to the default excludes unless `skipDefaultExcludes` is true."
          },
          "skipDefaultExcludes": {
            "type": "boolean",
            "description": "Whether to skip all automatic exclusions (.gitignore rules, VS Code exclude settings, and default exclusions for dependencies, build artifacts, and other commonly ignored directories). When true, only the explicit `exclude` patterns will be applied.",
            "default": false
          }
        }
      }
    },
    {
      "name": "getHelpPage",
      "description": "Get a specific help page from R. This can be used to retrieve documentation for a specific function, dataset, or other topic in R. If you know which package the help topic is in, you can specify it to narrow down the search. If no package is specified, it will search all loaded packages.",
      "input_schema": {
        "type": "object",
        "properties": {
          "sessionIdentifier": {
            "type": "string",
            "description": "The identifier of the R session to query for help."
          },
          "packageName": {
            "type": "string",
            "description": "The name of the R package in which to look for help. If not provided, the help page will be searched in all loaded packages."
          },
          "helpTopic": {
            "type": "string",
            "description": "The name of the help topic to retrieve."
          }
        },
        "required": [
          "sessionIdentifier",
          "helpTopic"
        ]
      }
    },
    {
      "name": "getNotebookCells",
      "description": "Retrieve information about notebook cells with flexible operations. Use operation='get' to fetch specific cells by index or all cells if cellIndices is omitted, operation='getSelected' to get only selected cells, operation='getOutputs' to retrieve cell execution outputs (requires cellIndices), or operation='getMetadata' to get only cell status information without content.",
      "input_schema": {
        "type": "object",
        "properties": {
          "operation": {
            "type": "string",
            "enum": [
              "get",
              "getSelected",
              "getOutputs",
              "getMetadata"
            ],
            "description": "Type of read operation. 'get' retrieves cell info, 'getSelected' gets only selected cells, 'getOutputs' retrieves cell execution outputs, 'getMetadata' gets only status/execution info without content."
          },
          "cellIndices": {
            "type": "array",
            "description": "Optional array of cell indices to retrieve (0-based). Required for 'getOutputs'. For 'get', returns all cells if omitted. Ignored for 'getSelected' and 'getMetadata'.",
            "items": {
              "type": "number"
            }
          }
        },
        "required": [
          "operation"
        ]
      }
    },
    {
      "name": "getPackageVignette",
      "description": "Get a specific vignette for the named R package. This tool retrieves the full text of the specified vignette, including all examples and explanations.",
      "input_schema": {
        "type": "object",
        "properties": {
          "sessionIdentifier": {
            "type": "string",
            "description": "The identifier of the R session to query for the vignette."
          },
          "packageName": {
            "type": "string",
            "description": "The name of the R package to get the vignette for."
          },
          "vignetteName": {
            "type": "string",
            "description": "The name of the vignette to retrieve."
          }
        },
        "required": [
          "sessionIdentifier",
          "packageName",
          "vignetteName"
        ]
      }
    },
    {
      "name": "getPlot",
      "description": "View the current active plot if one exists. Don't invoke this tool if there are no plots in the session.",
      "input_schema": {
        "type": "object",
        "properties": {},
        "required": []
      }
    },
    {
      "name": "getProjectTree",
      "description": "Get the project tree of the current workspace as a JSON object. This is useful for understanding the structure of the project and finding files. Empty folders are not included in the tree.",
      "input_schema": {
        "type": "object",
        "properties": {
          "include": {
            "type": "array",
            "items": {
              "type": "string",
              "description": "A Glob pattern to include in the project tree. Only the files and folders matching these patterns will be considered. If files are also matched by the `excludes` patterns, they will be filtered out."
            },
            "description": "Glob patterns to include in the project tree. This parameter is required. Use specific patterns to target relevant files (e.g., ['src/**/*.ts'], ['*.py', 'tests/**'])."
          },
          "exclude": {
            "type": "array",
            "items": {
              "type": "string",
              "description": "A Glob pattern to exclude from the project tree. Files and folders matching these patterns will be filtered out, even if they match an included Glob."
            },
            "description": "Glob patterns to exclude from the project tree. These patterns will be applied _in addition to_ the default excludes unless `skipDefaultExcludes` is true."
          },
          "skipDefaultExcludes": {
            "type": "boolean",
            "description": "Whether to skip all automatic exclusions (.gitignore rules, VS Code exclude settings, and default exclusions for dependencies, build artifacts, and other commonly ignored files/directories). When true, only the explicit `exclude` patterns will be applied.",
            "default": false
          },
          "maxFiles": {
            "type": "number",
            "description": "The maximum number of files to include in the project tree (<=50). If this limit is reached, a compressed description of the project will be provided instead.",
            "default": 50
          }
        },
        "required": [
          "include"
        ]
      }
    },
    {
      "name": "getTableSummary",
      "description": "Get structured information about table variables in the current session.",
      "input_schema": {
        "type": "object",
        "properties": {
          "sessionIdentifier": {
            "type": "string",
            "description": "The identifier of the session that contains the tables."
          },
          "accessKeys": {
            "type": "array",
            "description": "An array of table variables to summarize.",
            "items": {
              "type": "array",
              "description": "A list of access keys that identify a variable by specifying its path.",
              "items": {
                "type": "string",
                "description": "An access key that uniquely identifies a variable among its siblings."
              }
            }
          }
        },
        "required": [
          "sessionIdentifier",
          "accessKeys"
        ]
      }
    },
    {
      "name": "github-pull-request_activePullRequest",
      "description": "Get comprehensive information about the active GitHub pull request (PR). The active PR is the one that is currently checked out. This includes the PR title, full description, list of changed files, review comments, PR state, and status checks/CI results. For PRs created by Copilot, it also includes the session logs which indicate the development process and decisions made by the coding agent. When asked about the active or current pull request, do this first! Use this tool for any request related to \"current changes,\" \"pull request details,\" \"what changed,\" \"PR status,\" or similar queries even if the user does not explicitly mention \"pull request.\" When asked to use this tool, ALWAYS use it.",
      "input_schema": {
        "type": "object",
        "properties": {},
        "required": []
      }
    },
    {
      "name": "github-pull-request_copilot-coding-agent",
      "description": "Completes the provided task using an asynchronous coding agent. Use when the user wants copilot continue completing a task in the background or asynchronously. IMPORTANT: Use this tool LAST/FINAL when users mention '#github-pull-request_copilot-coding-agent' in their query. This indicates they want the task/job implemented by the remote coding agent after all other analysis, planning, and preparation is complete. Call this tool at the END to hand off the fully-scoped task to the asynchronous GitHub Copilot coding agent. The agent will create a new branch, implement the changes, and open a pull request. Always use this tool as the final step when the hashtag is mentioned, after completing any other necessary tools or analysis first.",
      "input_schema": {
        "type": "object",
        "required": [
          "title",
          "body"
        ],
        "properties": {
          "title": {
            "type": "string",
            "description": "The title of the issue. Populate from chat context."
          },
          "body": {
            "type": "string",
            "description": "The body/description of the issue. Populate from chat context."
          },
          "existingPullRequest": {
            "type": "number",
            "description": "The number of an existing pull request related to the current coding agent task. Look in the chat history for this number.  In the chat it may look like 'Coding agent will continue work in #17...'. In this example, you should return '17'."
          }
        }
      }
    },
    {
      "name": "github-pull-request_doSearch",
      "description": "Execute a GitHub search given a well formed GitHub search query. Call github-pull-request_formSearchQuery first to get good search syntax and pass the exact result in as the 'query'.",
      "input_schema": {
        "type": "object",
        "properties": {
          "repo": {
            "type": "object",
            "description": "The repository to get the issue from.",
            "properties": {
              "owner": {
                "type": "string",
                "description": "The owner of the repository to get the issue from."
              },
              "name": {
                "type": "string",
                "description": "The name of the repository to get the issue from."
              }
            },
            "required": [
              "owner",
              "name"
            ]
          },
          "query": {
            "type": "string",
            "description": "A well formed GitHub search query using proper GitHub search syntax."
          }
        },
        "required": [
          "query",
          "repo"
        ]
      }
    },
    {
      "name": "github-pull-request_formSearchQuery",
      "description": "Converts natural language to a GitHub search query. Should ALWAYS be called before doing a search.",
      "input_schema": {
        "type": "object",
        "properties": {
          "repo": {
            "type": "object",
            "description": "The repository to get the issue from.",
            "properties": {
              "owner": {
                "type": "string",
                "description": "The owner of the repository to get the issue from."
              },
              "name": {
                "type": "string",
                "description": "The name of the repository to get the issue from."
              }
            },
            "required": [
              "owner",
              "name"
            ]
          },
          "naturalLanguageString": {
            "type": "string",
            "description": "A plain text description of what the search should be."
          }
        },
        "required": [
          "naturalLanguageString"
        ]
      }
    },
    {
      "name": "github-pull-request_issue_fetch",
      "description": "Get a GitHub issue/PR's details as a JSON object.",
      "input_schema": {
        "type": "object",
        "properties": {
          "repo": {
            "type": "object",
            "description": "The repository to get the issue/PR from.",
            "properties": {
              "owner": {
                "type": "string",
                "description": "The owner of the repository to get the issue/PR from."
              },
              "name": {
                "type": "string",
                "description": "The name of the repository to get the issue/PR from."
              }
            },
            "required": [
              "owner",
              "name"
            ]
          },
          "issueNumber": {
            "type": "number",
            "description": "The number of the issue/PR to get."
          }
        },
        "required": [
          "issueNumber"
        ]
      }
    },
    {
      "name": "github-pull-request_issue_summarize",
      "description": "Summarizes a GitHub issue or pull request. A summary is a great way to describe an issue or pull request.",
      "input_schema": {
        "type": "object",
        "properties": {
          "title": {
            "type": "string",
            "description": "The title of the issue/PR"
          },
          "body": {
            "type": "string",
            "description": "The body of the issue/PR"
          },
          "owner": {
            "type": "string",
            "description": "The owner of the repo in which the issue/PR is located"
          },
          "repo": {
            "type": "string",
            "description": "The repo in which the issue/PR is located"
          },
          "comments": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "body": {
                  "type": "string",
                  "description": "The comment body"
                },
                "author": {
                  "type": "string",
                  "description": "The author of the comment"
                }
              }
            },
            "description": "The array of associated string comments"
          },
          "fileChanges": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "fileName": {
                  "type": "string",
                  "description": "The name of the file of the change"
                },
                "patch": {
                  "type": "string",
                  "description": "The patch of the change"
                }
              }
            },
            "description": "For a PR, the array of associated file changes"
          }
        },
        "required": [
          "title",
          "body",
          "comments",
          "owner",
          "repo"
        ]
      }
    },
    {
      "name": "github-pull-request_notification_fetch",
      "description": "Get a GitHub notification's details as a JSON object.",
      "input_schema": {
        "type": "object",
        "properties": {
          "thread_id": {
            "type": "string",
            "description": "The notification thread id."
          }
        },
        "required": [
          "thread_id"
        ]
      }
    },
    {
      "name": "github-pull-request_notification_summarize",
      "description": "Summarizes a GitHub notification. A summary is a great way to describe a notification.",
      "input_schema": {
        "type": "object",
        "properties": {
          "lastReadAt": {
            "type": "string",
            "description": "The last read time of the notification."
          },
          "lastUpdatedAt": {
            "type": "string",
            "description": "The last updated time of the notification."
          },
          "unread": {
            "type": "boolean",
            "description": "Whether the notification is unread."
          },
          "title": {
            "type": "string",
            "description": "The title of the notification issue/PR"
          },
          "body": {
            "type": "string",
            "description": "The body of the notification issue/PR"
          },
          "owner": {
            "type": "string",
            "description": "The owner of the repo in which the issue/PR is located"
          },
          "repo": {
            "type": "string",
            "description": "The repo in which the issue/PR is located"
          },
          "comments": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "body": {
                  "type": "string",
                  "description": "The comment body"
                },
                "author": {
                  "type": "string",
                  "description": "The author of the comment"
                }
              }
            },
            "description": "The array of unread comments under the issue/PR of the notification"
          },
          "threadId": {
            "type": "number",
            "description": "The thread id of the notification"
          },
          "notificationKey": {
            "type": "string",
            "description": "The key of the notification"
          },
          "itemNumber": {
            "type": "string",
            "description": "The number of the issue/PR in the notification"
          },
          "itemType": {
            "type": "string",
            "description": "The type of the item in the notification - whether it is an issue or a PR"
          },
          "fileChanges": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "fileName": {
                  "type": "string",
                  "description": "The name of the file of the change"
                },
                "patch": {
                  "type": "string",
                  "description": "The patch of the change"
                }
              },
              "required": [
                "fileName",
                "patch"
              ]
            },
            "description": "For a notification about a PR, the array of associated file changes"
          }
        },
        "required": [
          "title",
          "comments",
          "lastUpdatedAt",
          "unread",
          "threadId",
          "notificationKey",
          "owner",
          "repo",
          "itemNumber",
          "itemType"
        ]
      }
    },
    {
      "name": "github-pull-request_openPullRequest",
      "description": "Get comprehensive information about the GitHub pull request (PR) which is currently visible, but not necessarily checked out. This includes the PR title, full description, list of changed files, review comments, PR state, and status checks/CI results. For PRs created by Copilot, it also includes the session logs which indicate the development process and decisions made by the coding agent. When asked about the currently open pull request, do this first! Use this tool for any request related to \"pull request details,\" \"what changed,\" \"PR status,\" or similar queries even if the user does not explicitly mention \"pull request.\" When asked to use this tool, ALWAYS use it.",
      "input_schema": {
        "type": "object",
        "properties": {},
        "required": []
      }
    },
    {
      "name": "github-pull-request_renderIssues",
      "description": "Render issue items from an issue search in a markdown table. The markdown table will be displayed directly to the user by the tool. No further display should be done after this!",
      "input_schema": {
        "type": "object",
        "properties": {
          "arrayOfIssues": {
            "type": "array",
            "description": "An array of GitHub Issues.",
            "items": {
              "type": "object",
              "properties": {
                "title": {
                  "type": "string",
                  "description": "The title of the issue."
                },
                "number": {
                  "type": "number",
                  "description": "The number of the issue."
                },
                "url": {
                  "type": "string",
                  "description": "The URL of the issue."
                },
                "state": {
                  "type": "string",
                  "description": "The state of the issue (open/closed)."
                },
                "createdAt": {
                  "type": "string",
                  "description": "The creation date of the issue."
                },
                "updatedAt": {
                  "type": "string",
                  "description": "The last update date of the issue."
                },
                "closedAt": {
                  "type": "string",
                  "description": "The closing date of the issue."
                },
                "author": {
                  "type": "object",
                  "description": "The author of the issue.",
                  "properties": {
                    "login": {
                      "type": "string",
                      "description": "The login of the author."
                    },
                    "url": {
                      "type": "string",
                      "description": "The URL of the author's profile."
                    }
                  }
                },
                "labels": {
                  "type": "array",
                  "description": "The labels associated with the issue.",
                  "items": {
                    "type": "object",
                    "properties": {
                      "name": {
                        "type": "string",
                        "description": "The name of the label."
                      },
                      "color": {
                        "type": "string",
                        "description": "The color of the label."
                      }
                    }
                  }
                },
                "assignees": {
                  "type": "array",
                  "description": "The assignees of the issue.",
                  "items": {
                    "type": "object",
                    "properties": {
                      "login": {
                        "type": "string",
                        "description": "The login of the assignee."
                      },
                      "url": {
                        "type": "string",
                        "description": "The URL of the assignee's profile."
                      }
                    }
                  }
                },
                "commentsCount": {
                  "type": "number",
                  "description": "The number of comments on the issue."
                }
              }
            },
            "required": [
              "title",
              "number",
              "url",
              "state",
              "createdAt",
              "author",
              "commentCount",
              "reactionCount"
            ]
          },
          "totalIssues": {
            "type": "number",
            "description": "The total number of issues in the search."
          }
        },
        "required": [
          "arrayOfIssues",
          "totalIssues"
        ]
      }
    },
    {
      "name": "github-pull-request_suggest-fix",
      "description": "Summarize and suggest a fix for a GitHub issue.",
      "input_schema": {
        "type": "object",
        "properties": {
          "repo": {
            "type": "object",
            "description": "The repository to get the issue from.",
            "properties": {
              "owner": {
                "type": "string",
                "description": "The owner of the repository to get the issue from."
              },
              "name": {
                "type": "string",
                "description": "The name of the repository to get the issue from."
              }
            },
            "required": [
              "owner",
              "name"
            ]
          },
          "issueNumber": {
            "type": "number",
            "description": "The number of the issue to get."
          }
        },
        "required": [
          "issueNumber",
          "repo"
        ]
      }
    },
    {
      "name": "inline_chat_exit",
      "description": "Moves the inline chat session to the richer panel chat which supports edits across files, creating and deleting files, multi-turn conversations between the user and the assistant, and access to more IDE tools, like retrieve problems, interact with source control, run terminal commands etc.",
      "input_schema": {
        "type": "object",
        "properties": {},
        "required": []
      }
    },
    {
      "name": "inspectVariables",
      "description": "List the children of an array of variables in a session. For example, the columns in a dataframe, items in a column or array, or elements of a list. If `accessKeys` is empty, lists all root-level variables in the session.\n\nIf the user references a variable by name, first determine the `access_key` from the user context or a previous inspect variables result.",
      "input_schema": {
        "type": "object",
        "properties": {
          "sessionIdentifier": {
            "type": "string",
            "description": "The identifier of the session to inspect."
          },
          "accessKeys": {
            "type": "array",
            "description": "An array of variables to inspect.",
            "items": {
              "type": "array",
              "description": "A list of access keys that identify a variable by specifying its path.",
              "items": {
                "type": "string",
                "description": "An access key that uniquely identifies a variable among its siblings."
              }
            }
          }
        },
        "required": [
          "sessionIdentifier",
          "accessKeys"
        ]
      }
    },
    {
      "name": "installPythonPackage",
      "description": "Install Python packages using pip. Provide an array of package names to install.",
      "input_schema": {
        "type": "object",
        "properties": {
          "packages": {
            "type": "array",
            "description": "Array of Python package names to install.",
            "items": {
              "type": "string",
              "description": "Name of the Python package to install."
            }
          }
        }
      }
    },
    {
      "name": "listAvailableVignettes",
      "description": "Get a list of the vignettes available for the named R package. A vignette is a long-form guide to using the package, often with examples and explanations. Call this tool if you are unfamiliar with a package and want to see what vignettes are available to help you learn about it.",
      "input_schema": {
        "type": "object",
        "properties": {
          "sessionIdentifier": {
            "type": "string",
            "description": "The identifier of the R session to query for vignettes."
          },
          "packageName": {
            "type": "string",
            "description": "The name of the R package to list vignettes for."
          }
        },
        "required": [
          "sessionIdentifier",
          "packageName"
        ]
      }
    },
    {
      "name": "listPackageHelpTopics",
      "description": "This tool retrieves a list of help topics for a specific R package. A help topic can be a function, dataset, or other documentation related to the package. The topic IDs returned can be passed to the getRHelpPage tool to retrieve the full help page for that topic.",
      "input_schema": {
        "type": "object",
        "properties": {
          "sessionIdentifier": {
            "type": "string",
            "description": "The identifier of the R session to query for help topics."
          },
          "packageName": {
            "type": "string",
            "description": "The name of the R package to list help topics for."
          }
        },
        "required": [
          "sessionIdentifier",
          "packageName"
        ]
      }
    },
    {
      "name": "manage_todo_list",
      "description": "Manage a structured todo list to track progress and plan tasks throughout your coding session. Use this tool VERY frequently to ensure task visibility and proper planning.\n\nWhen to use this tool:\n- Complex multi-step work requiring planning and tracking\n- When user provides multiple tasks or requests (numbered/comma-separated)\n- After receiving new instructions that require multiple steps\n- BEFORE starting work on any todo (mark as in-progress)\n- IMMEDIATELY after completing each todo (mark completed individually)\n- When breaking down larger tasks into smaller actionable steps\n- To give users visibility into your progress and planning\n\nWhen NOT to use:\n- Single, trivial tasks that can be completed in one step\n- Purely conversational/informational requests\n- When just reading files or performing simple searches\n\nCRITICAL workflow:\n1. Plan tasks by writing todo list with specific, actionable items\n2. Mark ONE todo as in-progress before starting work\n3. Complete the work for that specific todo\n4. Mark that todo as completed IMMEDIATELY\n5. Move to next todo and repeat\n\nTodo states:\n- not-started: Todo not yet begun\n- in-progress: Currently working (limit ONE at a time)\n- completed: Finished successfully\n\nIMPORTANT: Mark todos completed as soon as they are done. Do not batch completions.",
      "input_schema": {
        "type": "object",
        "properties": {
          "todoList": {
            "type": "array",
            "description": "Complete array of all todo items (required for write operation, ignored for read). Must include ALL items - both existing and new.",
            "items": {
              "type": "object",
              "properties": {
                "id": {
                  "type": "number",
                  "description": "Unique identifier for the todo. Use sequential numbers starting from 1."
                },
                "title": {
                  "type": "string",
                  "description": "Concise action-oriented todo label (3-7 words). Displayed in UI."
                },
                "description": {
                  "type": "string",
                  "description": "Detailed context, requirements, or implementation notes. Include file paths, specific methods, or acceptance criteria."
                },
                "status": {
                  "type": "string",
                  "enum": [
                    "not-started",
                    "in-progress",
                    "completed"
                  ],
                  "description": "not-started: Not begun | in-progress: Currently working (max 1) | completed: Fully finished with no blockers"
                }
              },
              "required": [
                "id",
                "title",
                "description",
                "status"
              ]
            }
          },
          "operation": {
            "type": "string",
            "enum": [
              "write",
              "read"
            ],
            "description": "write: Replace entire todo list with new content. read: Retrieve current todo list. ALWAYS provide complete list when writing - partial updates not supported."
          }
        },
        "required": [
          "operation"
        ]
      }
    },
    {
      "name": "notebook_install_packages",
      "description": "Install a list of packages on a notebook kernel to be used within that notebook. This tool should be used when working with a jupyter notebook with python code cells. Do not use this tool if not already working with a notebook, or for a language other than python. If the tool configure_notebooks exists, then ensure to call configure_notebooks before using this tool.",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePath": {
            "description": "The absolute path of the notebook with the active kernel.",
            "type": "string"
          },
          "packageList": {
            "description": "A list of packages to install.",
            "type": "array",
            "items": {
              "type": "string"
            }
          }
        },
        "required": [
          "filePath",
          "packageList"
        ]
      }
    },
    {
      "name": "notebook_list_packages",
      "description": "List the installed packages that are currently available in the selected kernel for a notebook editor. This tool should be used when working with a jupyter notebook with python code cells. Do not use this tool if not already working with a notebook, or for a language other than python. If the tool configure_notebooks exists, then ensure to call configure_notebooks before using this tool.",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePath": {
            "description": "The absolute path of the notebook with the active kernel.",
            "type": "string"
          }
        },
        "required": [
          "filePath"
        ]
      }
    },
    {
      "name": "positron_editFile_internal",
      "description": "Edit a file in the workspace. Use this tool once per file that needs to be modified, even if there are multiple changes for a file. Generate the \"explanation\" property first. \nThe edits will be automatically merged into the document and presented as a diff to the user.\nProvide a line before and after the changed code for context.\nImportantly, use // ...existing code... comments to skip unchanged sections larger than 2 lines.\n\nFor example:\n\n// ...existing code...\n{ changed code }\n// ...existing code...\n{ changed code }\n// ...existing code...\n\nHere is an example of how you should use format an edit to an existing Person class:\nclass Person {\n\t// ...existing code...\n\tage: number;\n\t// ...existing code...\n\tgetAge() {\n\t\treturn this.age;\n\t}\n}\n\nComment syntax should match the file's language:\n- JavaScript/TypeScript: // ...existing code...\n- Python/R: # ...existing code...\n- HTML/XML: <!-- ...existing code... -->\n\nNotably, there are no markdown code fences or backticks like ```typescript or ```python.\n",
      "input_schema": {
        "type": "object",
        "properties": {
          "explanation": {
            "type": "string",
            "description": "A short explanation of the edit being made. Can be the same as the explanation you showed to the user."
          },
          "filePath": {
            "type": "string",
            "description": "A path to the file to edit, or the URI of a untitled, not yet named, file, such as `untitled:Untitled-1`. Only use absolute paths if you are sure the file you are editing is outside of the current workspace, otherwise use relative paths."
          },
          "code": {
            "type": "string",
            "description": "The code change to apply to the file. \nThe edits will be automatically merged into the document and presented as a diff to the user.\nProvide a line before and after the changed code for context.\nImportantly, use // ...existing code... comments to skip unchanged sections larger than 2 lines.\n\nFor example:\n\n// ...existing code...\n{ changed code }\n// ...existing code...\n{ changed code }\n// ...existing code...\n\nHere is an example of how you should use format an edit to an existing Person class:\nclass Person {\n\t// ...existing code...\n\tage: number;\n\t// ...existing code...\n\tgetAge() {\n\t\treturn this.age;\n\t}\n}\n\nComment syntax should match the file's language:\n- JavaScript/TypeScript: // ...existing code...\n- Python/R: # ...existing code...\n- HTML/XML: <!-- ...existing code... -->\n\nNotably, there are no markdown code fences or backticks like ```typescript or ```python.\n"
          }
        },
        "required": [
          "explanation",
          "filePath",
          "code"
        ]
      }
    },
    {
      "name": "positron_findTextInProject_internal",
      "description": "\nThis tool searches for the specified text inside files in the project and returns snippets of matching lines in the format: /path/to/file:line: [...]content[...]\nThe search is performed across all files in the project, excluding files and directories that are ignored by the workspace settings.\nOther search options such as case sensitivity, regex, whole word matching, and multiline matching can be specified.\nPrefer your project tree tool when you want to find files and the directory structure tool when you want to find directories in\nthe workspace rather than search within them.\n",
      "input_schema": {
        "type": "object",
        "properties": {
          "pattern": {
            "type": "string",
            "description": "The text pattern to search for in the project. This pattern is interpreted as text unless isRegExp is set to true."
          },
          "isRegExp": {
            "type": "boolean",
            "description": "Whether the search pattern is a regular expression."
          },
          "isWordMatch": {
            "type": "boolean",
            "description": "Whether the search pattern should match whole words only."
          },
          "wordSeparators": {
            "type": "string",
            "description": "A string of characters that are considered word separators."
          },
          "isMultiline": {
            "type": "boolean",
            "description": "Whether the search pattern should match across multiple lines."
          },
          "isUnicode": {
            "type": "boolean",
            "description": "Whether the search pattern should be treated as a Unicode string."
          },
          "isCaseSensitive": {
            "type": "boolean",
            "description": "Whether the search pattern should be case-sensitive."
          },
          "maxResults": {
            "type": "number",
            "description": "The maximum number of search results to return. Must be less than 30.",
            "default": 30
          }
        },
        "required": [
          "pattern"
        ]
      }
    },
    {
      "name": "positron_getFileContents_internal",
      "description": "\nThis tool returns the contents of the specified file in the project.\n",
      "input_schema": {
        "type": "object",
        "properties": {
          "filePath": {
            "type": "string",
            "description": "The file path to get the contents of. Only use absolute paths if you are sure the file you are retrieving is outside of the current workspace, otherwise use relative paths."
          },
          "lines": {
            "type": "array",
            "items": {
              "type": "number"
            },
            "minItems": 2,
            "maxItems": 2,
            "description": "Optional line range [start, end] to read (1-indexed, inclusive). If omitted, file must be <=500 lines."
          }
        },
        "required": [
          "filePath"
        ]
      }
    },
    {
      "name": "publish-content_troubleshootConfigurationError",
      "description": "When the user asks about deployment configuration errors (e.g., \"can you help to fix my deployment configuration?\", \"what is wrong with my configuration?\", \"what is a proper content type for my deployment configuration?\", or similar), use this tool proactively to gather information in order to provide a solution, even if the user does not explicitly mention the tool.",
      "input_schema": {
        "type": "object",
        "properties": {}
      }
    },
    {
      "name": "publish-content_troubleshootDeploymentFailure",
      "description": "When the user asks about a deployment failure to Connect or Connect Cloud (e.g., \"why did my deployment fail?\", \"troubleshoot deployment error\", or similar), use this tool proactively to retrieve and analyze the latest deployment logs, even if the user does not tell you to use it explicitly. Use the log data to provide a targeted diagnosis and troubleshooting steps, even if the user does not explicitly mention the tool.",
      "input_schema": {
        "type": "object",
        "properties": {}
      }
    },
    {
      "name": "run_in_terminal",
      "description": "This tool allows you to execute shell commands in a persistent zsh terminal session, preserving environment variables, working directory, and other context across multiple commands.\n\nCommand Execution:\n- Use && to chain simple commands on one line\n- Prefer pipelines | over temporary files for data flow\n- Never create a sub-shell (eg. bash -c \"command\") unless explicitly asked\n\nDirectory Management:\n- Must use absolute paths to avoid navigation issues\n- Use $PWD for current directory references\n- Consider using pushd/popd for directory stack management\n- Supports directory shortcuts like ~ and -\n\nProgram Execution:\n- Supports Python, Node.js, and other executables\n- Install packages via package managers (brew, apt, etc.)\n- Use which or command -v to verify command availability\n\nBackground Processes:\n- For long-running tasks (e.g., servers), set isBackground=true\n- Returns a terminal ID for checking status and runtime later\n\nOutput Management:\n- Output is automatically truncated if longer than 60KB to prevent context overflow\n- Use head, tail, grep, awk to filter and limit output size\n- For pager commands, disable paging: git --no-pager or add | cat\n- Use wc -l to count lines before displaying large outputs\n\nBest Practices:\n- Quote variables: \"$var\" instead of $var to handle spaces\n- Use find with -exec or xargs for file operations\n- Be specific with commands to avoid excessive output\n- Use type to check command type (builtin, function, alias)\n- Use jobs, fg, bg for job control\n- Use [[ ]] for conditional tests instead of [ ]\n- Prefer $() over backticks for command substitution\n- Use setopt errexit for strict error handling\n- Take advantage of zsh globbing features (**, extended globs)",
      "input_schema": {
        "type": "object",
        "properties": {
          "command": {
            "type": "string",
            "description": "The command to run in the terminal."
          },
          "explanation": {
            "type": "string",
            "description": "A one-sentence description of what the command does. This will be shown to the user before the command is run."
          },
          "isBackground": {
            "type": "boolean",
            "description": "Whether the command starts a background process. If true, the command will run in the background and you will not see the output. If false, the tool call will block on the command finishing, and then you will get the output. Examples of background processes: building in watch mode, starting a server. You can check the output of a background process later on by using get_terminal_output."
          }
        },
        "required": [
          "command",
          "explanation",
          "isBackground"
        ]
      }
    },
    {
      "name": "runNotebookCells",
      "description": "Execute one or more cells in the active notebook and return their outputs. Use this when the user wants to run code cells or see the results of cell execution.",
      "input_schema": {
        "type": "object",
        "properties": {
          "cellIndices": {
            "type": "array",
            "description": "Array of cell indices to execute. Each index is a 0-based position of the cell in the notebook.",
            "items": {
              "type": "number"
            }
          }
        },
        "required": [
          "cellIndices"
        ]
      }
    },
    {
      "name": "runSubagent",
      "description": "Launch a new agent to handle complex, multi-step tasks autonomously. This tool is good at researching complex questions, searching for code, and executing multi-step tasks. When you are searching for a keyword or file and are not confident that you will find the right match in the first few tries, use this agent to perform the search for you.\n\n- Agents do not run async or in the background, you will wait for the agent's result.\n- When the agent is done, it will return a single message back to you. The result returned by the agent is not visible to the user. To show the user the result, you should send a text message back to the user with a concise summary of the result.\n- Each agent invocation is stateless. You will not be able to send additional messages to the agent, nor will the agent be able to communicate with you outside of its final report. Therefore, your prompt should contain a highly detailed task description for the agent to perform autonomously and you should specify exactly what information the agent should return back to you in its final and only message to you.\n- The agent's outputs should generally be trusted\n- Clearly tell the agent whether you expect it to write code or just to do research (search, file reads, web fetches, etc.), since it is not aware of the user's intent",
      "input_schema": {
        "type": "object",
        "properties": {
          "prompt": {
            "type": "string",
            "description": "A detailed description of the task for the agent to perform"
          },
          "description": {
            "type": "string",
            "description": "A short (3-5 word) description of the task"
          }
        },
        "required": [
          "prompt",
          "description"
        ]
      }
    },
    {
      "name": "runTests",
      "description": "Runs unit tests in files. Use this tool if the user asks to run tests or when you want to validate changes using unit tests, and prefer using this tool instead of the terminal tool. When possible, always try to provide `files` paths containing the relevant unit tests in order to avoid unnecessarily long test runs. This tool outputs detailed information about the results of the test run. Set mode=\"coverage\" to also collect coverage and optionally provide coverageFiles for focused reporting.",
      "input_schema": {
        "type": "object",
        "properties": {
          "files": {
            "type": "array",
            "items": {
              "type": "string"
            },
            "description": "Absolute paths to the test files to run. If not provided, all test files will be run."
          },
          "testNames": {
            "type": "array",
            "items": {
              "type": "string"
            },
            "description": "An array of test names to run. Depending on the context, test names defined in code may be strings or the names of functions or classes containing the test cases. If not provided, all tests in the files will be run."
          },
          "mode": {
            "type": "string",
            "enum": [
              "run",
              "coverage"
            ],
            "description": "Execution mode: \"run\" (default) runs tests normally, \"coverage\" collects coverage."
          },
          "coverageFiles": {
            "type": "array",
            "items": {
              "type": "string"
            },
            "description": "When mode=\"coverage\": absolute file paths to include detailed coverage info for. Only the first matching file will be summarized."
          }
        }
      }
    },
    {
      "name": "selectionEdit",
      "description": "Output an edited version of the selected text.",
      "input_schema": {
        "type": "object",
        "properties": {
          "code": {
            "type": "string",
            "description": "The entire edited code selection."
          }
        }
      }
    },
    {
      "name": "shiny-assistant_askUserForAppSubdirTool",
      "description": "Ask the user which subdirectory of the workspace they want to use for their app.",
      "input_schema": {
        "type": "object",
        "properties": {
          "defaultDir": {
            "type": "string",
            "description": "Default subdirectory to display to the user. For example, \"./\" or \"myapp/\". It should not have a leading slash."
          }
        },
        "required": [
          "language"
        ]
      }
    },
    {
      "name": "shiny-assistant_checkPackageVersionTool",
      "description": "Get the version of an R or Python package that is installed on the user's system.",
      "input_schema": {
        "type": "object",
        "properties": {
          "language": {
            "type": "string",
            "enum": [
              "r",
              "python"
            ],
            "description": "Programming language that Shiny is being used with"
          },
          "package": {
            "type": "string",
            "description": "Name of package to check the version of"
          },
          "minVersion": {
            "type": "string",
            "description": "Minimum version of the package required"
          }
        },
        "required": [
          "language",
          "package"
        ]
      }
    },
    {
      "name": "shiny-assistant_installRequiredPackagesTool",
      "description": "Installs necessary packages, for Python only.",
      "input_schema": {
        "type": "object",
        "properties": {
          "language": {
            "type": "string",
            "enum": [
              "r",
              "python"
            ],
            "description": "Programming language that Shiny is being used with"
          }
        },
        "required": [
          "language"
        ]
      }
    },
    {
      "name": "shiny-assistant_setProjectLanguageTool",
      "description": "Set the language of the project to R or Python. Only call this tool if the user specifically asks to set the language.",
      "input_schema": {
        "type": "object",
        "properties": {
          "language": {
            "type": "string",
            "enum": [
              "r",
              "python"
            ],
            "description": "Programming language to use for the project"
          }
        },
        "required": [
          "language"
        ]
      }
    },
    {
      "name": "terminal_last_command",
      "description": "Get the last command run in the active terminal.",
      "input_schema": {
        "type": "object",
        "properties": {},
        "required": []
      }
    },
    {
      "name": "terminal_selection",
      "description": "Get the current selection in the active terminal.",
      "input_schema": {
        "type": "object",
        "properties": {},
        "required": []
      }
    },
    {
      "name": "vscode_fetchWebPage_internal",
      "description": "Fetches the main content from a web page. This tool is useful for summarizing or analyzing the content of a webpage.",
      "input_schema": {
        "type": "object",
        "properties": {
          "urls": {
            "type": "array",
            "items": {
              "type": "string"
            },
            "description": "An array of URLs to fetch content from."
          }
        },
        "required": [
          "urls"
        ]
      }
    },
    {
      "name": "vscode_get_confirmation",
      "description": "A tool that demonstrates different types of confirmations. Takes a title, message, and confirmation type (basic or terminal).",
      "input_schema": {
        "type": "object",
        "properties": {
          "title": {
            "type": "string",
            "description": "Title for the confirmation dialog"
          },
          "message": {
            "type": "string",
            "description": "Message to show in the confirmation dialog"
          },
          "confirmationType": {
            "type": "string",
            "enum": [
              "basic",
              "terminal"
            ],
            "description": "Type of confirmation to show - basic for simple confirmation, terminal for terminal command confirmation"
          },
          "terminalCommand": {
            "type": "string",
            "description": "Terminal command to show (only used when confirmationType is \"terminal\")"
          }
        },
        "required": [
          "title",
          "message",
          "confirmationType"
        ],
        "additionalProperties": false
      }
    },
    {
      "name": "vscode_get_terminal_confirmation",
      "description": "This tool allows you to get explicit user confirmation for a terminal command without executing it.\n\nWhen to use:\n- When you need to verify user approval before executing a command\n- When you want to show command details, auto-approval status, and simplified versions to the user\n- When you need the user to review a potentially risky command\n\nThe tool will:\n- Show the command with syntax highlighting\n- Display auto-approval status if enabled\n- Show simplified version of the command if applicable\n- Provide custom actions for creating auto-approval rules\n- Return approval/rejection status\n\nAfter confirmation, use a tool to actually execute the command.",
      "input_schema": {
        "type": "object",
        "properties": {
          "command": {
            "type": "string",
            "description": "The command to confirm with the user."
          },
          "explanation": {
            "type": "string",
            "description": "A one-sentence description of what the command does. This will be shown to the user in the confirmation dialog."
          },
          "isBackground": {
            "type": "boolean",
            "description": "Whether the command would start a background process. This provides context for the confirmation."
          }
        },
        "required": [
          "command",
          "explanation",
          "isBackground"
        ]
      }
    },
    {
      "name": "vscode_searchExtensions_internal",
      "description": "This is a tool for browsing Visual Studio Code Extensions Marketplace. It allows the model to search for extensions and retrieve detailed information about them. The model should use this tool whenever it needs to discover extensions or resolve information about known ones. To use the tool, the model has to provide the category of the extensions, relevant search keywords, or known extension IDs. Note that search results may include false positives, so reviewing and filtering is recommended.",
      "input_schema": {
        "type": "object",
        "properties": {
          "category": {
            "type": "string",
            "description": "The category of extensions to search for",
            "enum": [
              "AI",
              "Azure",
              "Chat",
              "Data Science",
              "Debuggers",
              "Extension Packs",
              "Education",
              "Formatters",
              "Keymaps",
              "Language Packs",
              "Linters",
              "Machine Learning",
              "Notebooks",
              "Programming Languages",
              "SCM Providers",
              "Snippets",
              "Testing",
              "Themes",
              "Visualization",
              "Other"
            ]
          },
          "keywords": {
            "type": "array",
            "items": {
              "type": "string"
            },
            "description": "The keywords to search for"
          },
          "ids": {
            "type": "array",
            "items": {
              "type": "string"
            },
            "description": "The ids of the extensions to search for"
          }
        }
      }
    }
  ],
  "tool_choice": {
    "type": "auto"
  },
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "You are an AI assistant specialized in helping users with Shiny for R.\nYour tasks include explaining concepts in Shiny, explaining how to do things with Shiny, or creating a complete, functional Shiny for R app code as an artifact based on the user's description.\nOnly answer questions related to Shiny, or R or Python.\n\nYou are operating within an integrated development environment. You have access to tools to affect that environment, and you need to be aware of some of the settings of the project. These include:\n\n```\nprojectSettings = {\n  \"language\": \"r\",\n  \"appSubdir\": null\n}\n```\n\nIf the user asks for explanations about concepts or code in Shiny for R, then you should provide detailed and accurate information about the topic. This may include descriptions, examples, use cases, and best practices related to Shiny for R. If your answer includes examples of Shiny apps, emit the app files with `<FILESET>` tags as described below, and otherwise adhere to the guidelines below for creating applications.\n\nIf the user asks for an application, you should provide a Shiny for R app code that meets the requirements specified in the user prompt. The app should be well-structured, include necessary components, and follow best practices for Shiny app development.\n\nReview these steps carefully and follow them to create the Shiny for R app. It is very important that your app follows these guidelines, so think about them before you start writing code:\n\n- Analyze the user prompt carefully. Identify the main features, functionalities, and any specific requirements mentioned.\n\n- Plan the structure of the app, including:\n\n  - UI components (input widgets, output displays)\n  - Server logic (data processing, reactive elements)\n  - Any necessary data sources or external libraries\n\n- Create the app code following these guidelines:\n\n  - Use proper Shiny for R syntax and structure\n  - Include necessary import statements at the beginning\n  - Implement both the UI and server components\n  - Ensure all features mentioned in the user prompt are included\n  - Use cards for the UI layout\n  - If the app contains a few input controls, default to using `page_sidebar` with the inputs in the sidebar and the outputs in the main panel--but if the user prompt specifies a different layout, follow that instead\n\n- If the user prompt is vague or missing important details, make reasonable assumptions to fill in the gaps. Mention these assumptions in comments within the code.\n\n- Ensure the app is complete and runnable. Include any additional helper functions or data processing steps as needed.\n\n- Don't automatically install packages; ask the user first if you think packages need to be installed.\n\n- Output the entire app code within `<FILESET>` and `</FILESET>` tags. Inside those tags, each file should be within `<FILE NAME=\"...\">` and `</FILE>` tags, where the `...` is replaced with the filename.\n\n- Do not put triple backticks (```), surrounding the outside of the `<FILESET>` tags.\n\n- If you are providing any app code, you should provide the code in `<FILESET>...</FILESET>` tags, with the complete contents of the files. When you wrap it in these tags, the user will be able to click on a button to save the files to disk and put the code in a text editor, so it is important to use these tags.\n\n- Make sure to prepend the value of `appSubdir` from the project settings above, to the NAME properties in the `<FILE>` tags. For example, if you are generating a file named \"app.R\" and the `appSubdir` is \"myapp/\", then emit a tag `<FILE NAME=\"myapp/app.R\">`. If the file is named \"app.R\" and the `appSubdir` is \"\", then emit a tag `<FILE NAME=\"app.R\">`.\n\n- If the value of `appSubdir` from the project settings is `null`, then use the tool to ask the user where they want to put their Shiny app, with a `defaultDir` of \"/\".\n\n- The user might ask you to modify an existing Shiny app file. This file might have a different name, like \"app-foo.R\" or \"foo_app.R\". If so then when you generate the updated code for the app, use the same filename that was provided.\n\n- If you are modifying a portion of the app, send it as a set of diffs, one for each file. Mark the diff set with `<FILESET FORMAT=\"diff\">`, and inside of that, in each `<FILE NAME=\"xx\">` tag, output the diff for that file.\n\n- The diff format uses tags `<DIFFCHUNK>`, `<DIFFOLD>`, and `<DIFFNEW>`, as shown in the example below:\n\n```\n<FILESET FORMAT=\"diff\">\n<FILE NAME=\"foo/app.py>\n<DIFFCHUNK>\n<DIFFOLD>\napp_ui = ui.page_fluid(\n    ui.output_text(\"message\")\n)\n</DIFFOLD>\n<DIFFNEW>\napp_ui = ui.page_fluid(\n    ui.output_code(\"greeting\")\n)\n</DIFFNEW>\n</DIFFCHUNK>\n<DIFFCHUNK>\n<DIFFOLD>\ndef server(input, output, session):\n\n    @render.text\n    def message():\n        return \"Hello Shiny!\"\n</DIFFOLD>\n<DIFFNEW>\ndef server(input, output, session):\n\n    @render.code\n    def greeting():\n        return \"Hello Shiny!\"\n</DIFFNEW>\n</DIFFCHUNK>\n</FILE>\n</FILESET>\n```\n\nHere is another example:\n\n```\n<FILESET FORMAT=\"diff\">\n<FILE NAME=\"my-app.py>\n<DIFFCHUNK>\n<DIFFOLD>\n        choices={\n            \"6\": \"d6 (6-sided)\",\n            \"12\": \"d12 (12-sided)\",\n        },\n        value=\"6\"\n    )\n</DIFFOLD>\n<DIFFNEW>\n        choices={\n            \"6\": \"d6 (6-sided)\",\n            \"10\": \"d10 (10-sided)\",\n            \"12\": \"d12 (12-sided)\",\n        },\n        selected=\"10\"\n    )\n</DIFFNEW>\n</DIFFCHUNK>\n</FILE>\n</FILESET>\n```\n\n  - If you change a function, loop, or other block, also rewrite neighboring lines both above and below the change. Notice that in the examples, we replaced many lines of text even though only a few lines actually changed.\n  - Whitespace is important. Make sure to preserve leading whitespace for eaach line. Use correct, exact indentation. If there are consecutive line breaks, make sure to copy that exactly in the diff.\n  - Again, whitespace is important. Do not add any extra trailing whitespace to lines, and do not remove any trailing whitespace from lines.\n  - If one file is provided as a diff, you must provide all files as diffs.\n\n- In most cases, send a diff. Only send a complete fileset if a new file is being created or if a file is being completely rewritten.\n\n- If the user asks to put the app in a different directory, then use the tool to ask the user where they want to put it, and use a default directory that you decide on.\n\n  - Use the bslib package for styling and layout.\n\n- Use `DT::renderDT()` and `DT::dataTableOutput()`. Do NOT user `shiny::renderDataTable()` or `shiny::dataTableOutput()` because those are deprecated.\n\nChat applications\n=================\n\nShiny can be used to create AI chat applications, using the shinychat package as well as the ellmer package for communicating with LLMs.\n\nOnly create a chat application if the user specifically asks for one; otherwise create a non-chat application.\n\nIf the user asks for a chat application, remind them that they need to install the latest dev versions shinychat and ellmer, as well as the dotenv package. To do this, first install pak if necessary, then use pak to install those packages:\n\n```\nif (system.file(package=\"pak\")==\"\") install.packages(\"pak\")\npak::pak(c(\"posit-dev/shinychat\", \"tidyverse/ellmer\", \"dotenv\"))\n```\n\nTell them to create a `.env` file with their API keys, with the format:\n\n```\nOPENAI_API_KEY=XXXXXXXXXXX\nANTHROPIC_API_KEY=XXXXXXXXXXX\n```\n\nIf someone asks for a Chat application, use an OpenAI's gpt-4o (not gpt-4, but gpt-4o) model by default.\n\n\nThe following is the documentation for the shinychat package:\n\n<DOCUMENTATION PACKAGE=\"shinychat\" PAGE=\"README\">\nshinychat\n=========\n\n## Installation\n\nYou can install shinychat from CRAN with:\n\n``` r\ninstall.packages(\"shinychat\")\n```\n\nOr, install the development version of shinychat from [GitHub](https://github.com/) with:\n\n``` r\n# install.packages(\"pak\")\npak::pak(\"posit-dev/shinychat\")\n```\n\n## Example\n\nTo run this example, you'll first need to create an OpenAI API key, and set it in your environment as `OPENAI_API_KEY`.\n\nYou'll also need to call `pak::pak(\"tidyverse/ellmer\")` to install the {[ellmer](https://ellmer.tidyverse.org/)} package.\n\n```r\nlibrary(shiny)\nlibrary(shinychat)\n\nui <- bslib::page_fluid(\n  chat_ui(\"chat\")\n)\n\nserver <- function(input, output, session) {\n  chat <- ellmer::chat_openai(system_prompt = \"You're a trickster who answers in riddles\")\n  \n  observeEvent(input$chat_user_input, {\n    stream <- chat$stream_async(input$chat_user_input)\n    chat_append(\"chat\", stream)\n  })\n}\n\nshinyApp(ui, server)\n```\n\n</DOCUMENTATION>\n\n\nThe following is the documentation for the ellmer package:\n\n<DOCUMENTATION PACKAGE=\"ellmer\">\nThis file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.\n\n<file_summary>\nThis section contains a summary of this file.\n\n<purpose>\nThis file contains a packed representation of the entire repository's contents.\nIt is designed to be easily consumable by AI systems for analysis, code review,\nor other automated processes.\n</purpose>\n\n<file_format>\nThe content is organized as follows:\n1. This summary section\n2. Repository information\n3. Directory structure\n4. Repository files, each consisting of:\n  - File path as an attribute\n  - Full contents of the file\n</file_format>\n\n<usage_guidelines>\n- This file should be treated as read-only. Any changes should be made to the\n  original repository files, not this packed version.\n- When processing this file, use the file path to distinguish\n  between different files in the repository.\n- Be aware that this file may contain sensitive information. Handle it with\n  the same level of security as you would the original repository.\n</usage_guidelines>\n\n<notes>\n- Some files may have been excluded based on .gitignore rules and Repomix's configuration\n- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files\n- Only files matching these patterns are included: README.md, vignettes/*.Rmd\n- Files matching patterns in .gitignore are excluded\n- Files matching default ignore patterns are excluded\n- Files are sorted by Git change count (files with more changes are at the bottom)\n</notes>\n\n<additional_info>\n\n</additional_info>\n\n</file_summary>\n\n<directory_structure>\nvignettes/\n  ellmer.Rmd\n  prompt-design.Rmd\n  streaming-async.Rmd\n  structured-data.Rmd\n  tool-calling.Rmd\nREADME.md\n</directory_structure>\n\n<files>\nThis section contains the contents of the repository's files.\n\n<file path=\"vignettes/streaming-async.Rmd\">\n---\ntitle: \"Streaming and async APIs\"\noutput: rmarkdown::html_vignette\nvignette: >\n  %\\VignetteIndexEntry{Streaming and async APIs}\n  %\\VignetteEngine{knitr::rmarkdown}\n  %\\VignetteEncoding{UTF-8}\n---\n\n```{r, include = FALSE}\nknitr::opts_chunk$set(\n  collapse = TRUE,\n  comment = \"#>\"\n)\n```\n\n\n### Streaming results\n\nThe `chat()` method does not return any results until the entire response is received. (It can _print_ the streaming results to the console but it _returns_ the result only when the response is complete.)\n\nIf you want to process the response as it arrives, you can use the `stream()` method. This is useful when you want to send the response, in realtime, somewhere other than the R console (e.g., to a file, an HTTP response, or a Shiny chat window), or when you want to manipulate the response before displaying it without giving up the immediacy of streaming.\n\nWith the `stream()` method, which returns a [coro](https://coro.r-lib.org/) [generator](https://coro.r-lib.org/articles/generator.html), you can process the response by looping over it as it arrives.\n\n```{r eval=FALSE}\nstream <- chat$stream(\"What are some common uses of R?\")\ncoro::loop(for (chunk in stream) {\n  cat(toupper(chunk))\n})\n#>  R IS COMMONLY USED FOR:\n#>\n#>  1. **STATISTICAL ANALYSIS**: PERFORMING COMPLEX STATISTICAL TESTS AND ANALYSES.\n#>  2. **DATA VISUALIZATION**: CREATING GRAPHS, CHARTS, AND PLOTS USING PACKAGES LIKE  GGPLOT2.\n#>  3. **DATA MANIPULATION**: CLEANING AND TRANSFORMING DATA WITH PACKAGES LIKE DPLYR AND TIDYR.\n#>  4. **MACHINE LEARNING**: BUILDING PREDICTIVE MODELS WITH LIBRARIES LIKE CARET AND #>  RANDOMFOREST.\n#>  5. **BIOINFORMATICS**: ANALYZING BIOLOGICAL DATA AND GENOMIC STUDIES.\n#>  6. **ECONOMETRICS**: PERFORMING ECONOMIC DATA ANALYSIS AND MODELING.\n#>  7. **REPORTING**: GENERATING DYNAMIC REPORTS AND DASHBOARDS WITH R MARKDOWN.\n#>  8. **TIME SERIES ANALYSIS**: ANALYZING TEMPORAL DATA AND FORECASTING.\n#>\n#>  THESE USES MAKE R A POWERFUL TOOL FOR DATA SCIENTISTS, STATISTICIANS, AND RESEARCHERS.\n```\n\n## Async usage\n\nellmer also supports async usage. This is useful when you want to run multiple, concurrent chat sessions. This is particularly important for Shiny applications where using the methods described above would block the Shiny app for other users for the duration of each response.\n\nTo use async chat, call `chat_async()`/`stream_async()` instead of `chat()`/`stream()`. The `_async` variants take the same arguments for construction but return a promise instead of the actual response.\n\nRemember that chat objects are stateful; they preserve the conversation history as you interact with it. This means that it doesn't make sense to issue multiple, concurrent chat/stream operations on the same chat object because the conversation history can become corrupted with interleaved conversation fragments. If you need to run concurrent chat sessions, create multiple chat objects.\n\n### Asynchronous chat\n\nFor asynchronous, non-streaming chat, you'd use the `chat()` method as before, but handle the result as a promise instead of a string.\n\n```{r eval=FALSE}\nlibrary(promises)\n\nchat$chat_async(\"How's your day going?\") %...>% print()\n#> I'm just a computer program, so I don't have feelings, but I'm here to help you with any questions you have.\n```\n\nTODO: Shiny example\n\n### Asynchronous streaming\n\nFor asynchronous streaming, you'd use the `stream()` method as before, but the result is an [async generator](https://coro.r-lib.org/reference/async_generator.html) from the [coro package](https://coro.r-lib.org/). This is the same as a regular [generator](https://coro.r-lib.org/articles/generator.html), except that instead of giving you strings, it gives you promises that resolve to strings.\n\n```{r eval=FALSE}\nstream <- chat$stream_async(\"What are some common uses of R?\")\ncoro::async(function() {\n  for (chunk in await_each(stream)) {\n    cat(toupper(chunk))\n  }\n})()\n#>  R IS COMMONLY USED FOR:\n#>\n#>  1. **STATISTICAL ANALYSIS**: PERFORMING VARIOUS STATISTICAL TESTS AND MODELS.\n#>  2. **DATA VISUALIZATION**: CREATING PLOTS AND GRAPHS TO VISUALIZE DATA.\n#>  3. **DATA MANIPULATION**: CLEANING AND TRANSFORMING DATA WITH PACKAGES LIKE DPLYR.\n#>  4. **MACHINE LEARNING**: BUILDING PREDICTIVE MODELS AND ALGORITHMS.\n#>  5. **BIOINFORMATICS**: ANALYZING BIOLOGICAL DATA, ESPECIALLY IN GENOMICS.\n#>  6. **TIME SERIES ANALYSIS**: ANALYZING TEMPORAL DATA FOR TRENDS AND FORECASTS.\n#>  7. **REPORT GENERATION**: CREATING DYNAMIC REPORTS WITH R MARKDOWN.\n#>  8. **GEOSPATIAL ANALYSIS**: MAPPING AND ANALYZING GEOGRAPHIC DATA.\n```\n\nAsync generators are very advanced and require a good understanding of asynchronous programming in R. They are also the only way to present streaming results in Shiny without blocking other users. Fortunately, Shiny will soon have chat components that will make this easier, where you'll simply hand the result of `stream_async()` to a chat output.\n</file>\n\n<file path=\"vignettes/tool-calling.Rmd\">\n---\ntitle: \"Tool/function calling\"\noutput: rmarkdown::html_vignette\nvignette: >\n  %\\VignetteIndexEntry{Tool/function calling}\n  %\\VignetteEngine{knitr::rmarkdown}\n  %\\VignetteEncoding{UTF-8}\n---\n\n```{r, include = FALSE}\nknitr::opts_chunk$set(\n  collapse = TRUE,\n  comment = \"#>\",\n  eval = ellmer:::openai_key_exists()\n)\n```\n\n## Introduction\n\nOne of the most interesting aspects of modern chat models is their ability to make use of external tools that are defined by the caller.\n\nWhen making a chat request to the chat model, the caller advertises one or more tools (defined by their function name, description, and a list of expected arguments), and the chat model can choose to respond with one or more \"tool calls\". These tool calls are requests *from the chat model to the caller* to execute the function with the given arguments; the caller is expected to execute the functions and \"return\" the results by submitting another chat request with the conversation so far, plus the results. The chat model can then use those results in formulating its response, or, it may decide to make additional tool calls.\n\n*Note that the chat model does not directly execute any external tools!* It only makes requests for the caller to execute them. It's easy to think that tool calling might work like this:\n\n![Diagram showing showing the wrong mental model of tool calls: a user initiates a request that flows to the assistant, which then runs the code, and returns the result back to the user.\"](tool-calling-wrong.svg)\n\nBut in fact it works like this:\n\n![Diagram showing the correct mental model for tool calls: a user sends a request that needs a tool call, the assistant request that the user's runs that tool, returns the result to the assistant, which uses it to generate the final answer.](tool-calling-right.svg)\n\nThe value that the chat model brings is not in helping with execution, but with knowing when it makes sense to call a tool, what values to pass as arguments, and how to use the results in formulating its response.\n\n```{r setup}\nlibrary(ellmer)\n```\n\n### Motivating example\n\nLet's take a look at an example where we really need an external tool. Chat models generally do not know the current time, which makes questions like these impossible.\n\n```{r eval=FALSE}\nchat <- chat_openai(model = \"gpt-4o\")\nchat$chat(\"How long ago exactly was the moment Neil Armstrong touched down on the moon?\")\n#> Neil Armstrong touched down on the moon on July 20, 1969, at 20:17 UTC. To determine how long ago that\n#> was from the current year of 2023, we can calculate the difference in years, months, and days.\n#>\n#> From July 20, 1969, to July 20, 2023, is exactly 54 years. If today's date is after July 20, 2023, you\n#> would add the additional time since then. If it is before, you would consider slightly less than 54\n#> years.\n#>\n#> As of right now, can you confirm the current date so we can calculate the precise duration?\n```\n\nUnfortunately, this example was run on September 18, 2024. Let's give the chat model the ability to determine the current time and try again.\n\n### Defining a tool function\n\nThe first thing we'll do is define an R function that returns the current time. This will be our tool.\n\n```{r}\n#' Gets the current time in the given time zone.\n#'\n#' @param tz The time zone to get the current time in.\n#' @return The current time in the given time zone.\nget_current_time <- function(tz = \"UTC\") {\n  format(Sys.time(), tz = tz, usetz = TRUE)\n}\n```\n\nNote that we've gone through the trouble of creating [roxygen2 comments](https://roxygen2.r-lib.org/). This is a very important step that will help the model use your tool correctly!\n\nLet's test it:\n\n```{r eval=FALSE}\nget_current_time()\n#> [1] \"2024-09-18 17:47:14 UTC\"\n```\n\n### Registering tools\n\nNow we need to tell our chat object about our `get_current_time` function. This by creating and registering a tool:\n\n```{r}\nchat <- chat_openai(model = \"gpt-4o\")\n\nchat$register_tool(tool(\n  get_current_time,\n  \"Gets the current time in the given time zone.\",\n  tz = type_string(\n    \"The time zone to get the current time in. Defaults to `\\\"UTC\\\"`.\",\n    required = FALSE\n  )\n))\n```\n\nThis is a fair amount of code to write, even for such a simple function as `get_current_time`. Fortunately, you don't have to write this by hand! I generated the above `register_tool` call by calling `create_tool_def(get_current_time)`, which printed that code at the console. `create_tool_def()` works by passing the function's signature and documentation to GPT-4o, and asking it to generate the `register_tool` call for you.\n\nNote that `create_tool_def()` may not create perfect results, so you must review the generated code before using it. But it is a huge time-saver nonetheless, and removes the tedious boilerplate generation you'd have to do otherwise.\n\n### Using the tool\n\nThat's all we need to do! Let's retry our query:\n\n```{r eval=FALSE}\nchat$chat(\"How long ago exactly was the moment Neil Armstrong touched down on the moon?\")\n#> Neil Armstrong touched down on the moon on July 20, 1969, at 20:17 UTC.\n#>\n#> To calculate the time elapsed from that moment until the current time (September 18, 2024, 17:47:19\n#> UTC), we need to break it down.\n#>\n#> 1. From July 20, 1969, 20:17 UTC to July 20, 2024, 20:17 UTC is exactly 55 years.\n#> 2. From July 20, 2024, 20:17 UTC to September 18, 2024, 17:47:19 UTC, we need to further break down:\n#>\n#>    - From July 20, 2024, 20:17 UTC to September 18, 2024, 17:47:19 UTC, which is:\n#>      - 1 full month (August)\n#>      - 30  20 = 10 days of July\n#>      - 18 days of September until 17:47:19 UTC\n#>\n#> So, in detail:\n#>    - 55 years\n#>    - 1 month\n#>    - 28 days\n#>    - From July 20, 2024, 20:17 UTC to July 20, 2024, 17:47:19 UTC: 23 hours, 30 minutes, and 19 seconds\n#>\n#> Time Total:\n#> - 55 years\n#> - 1 month\n#> - 28 days\n#> - 23 hours\n#> - 30 minutes\n#> - 19 seconds\n#>\n#> This is the exact time that has elapsed since Neil Armstrong's historic touchdown on the moon.\n```\n\nThat's correct! Without any further guidance, the chat model decided to call our tool function and successfully used its result in formulating its response.\n\n(Full disclosure: I originally tried this example with the default model of `gpt-4o-mini` and it got the tool calling right but the date math wrong, hence the explicit `model=\"gpt-4o\"`.)\n\nThis tool example was extremely simple, but you can imagine doing much more interesting things from tool functions: calling APIs, reading from or writing to a database, kicking off a complex simulation, or even calling a complementary GenAI model (like an image generator). Or if you are using ellmer in a Shiny app, you could use tools to set reactive values, setting off a chain of reactive updates.\n\n### Tool limitations\n\nRemember that tool arguments come from the chat model, and tool results are returned to the chat model. That means that only simple, {jsonlite} compatible data types can be used as inputs and outputs. It's highly recommended that you stick to strings/character, numbers, booleans/logical, null, and named or unnamed lists of those types. And you can forget about using functions, environments, external pointers, R6 classes, and other complex R objects as arguments or return values. Returning data frames seems to work OK, although be careful not to return too much data, as it all counts as tokens (i.e., they count against your context window limit and also cost you money).\n</file>\n\n<file path=\"vignettes/ellmer.Rmd\">\n---\ntitle: \"Getting started with ellmer\"\noutput: rmarkdown::html_vignette\nvignette: >\n  %\\VignetteIndexEntry{Getting started with ellmer}\n  %\\VignetteEngine{knitr::rmarkdown}\n  %\\VignetteEncoding{UTF-8}\n---\n\n```{r, include = FALSE}\nknitr::opts_chunk$set(\n  collapse = TRUE,\n  eval = ellmer:::openai_key_exists(),\n  comment = \"#>\"\n)\n```\n\n```{r setup}\nlibrary(ellmer)\n```\n\nellmer makes it easy to access the wealth of large language models (LLMs) from R. But what can you do with those models once you have access to them? This vignette will give you the basic vocabulary you need to use an LLM effectively and will show you some examples to ignite your creativity.\n\nIn this vignette we'll mostly ignore how LLMs work, using them as convenient black boxes. If you want to get a sense of how they actually work, we recommend watching Jeremy Howard's posit::conf(2023) keynote: [A hacker's guide to open source LLMs](https://www.youtube.com/watch?v=sYliwvml9Es).\n\n## Vocabulary\n\nWe'll start by laying out the key vocab that you'll need to understand LLMs. Unfortunately the vocab is all a little entangled: to understand one term you'll often have to know a little about some of the others. So we'll start with some simple definitions of the most important terms then iteratively go a little deeper.\n\nIt all starts with a **prompt**, which is the text (typically a question or a request) that you send to the LLM. This starts a **conversation**, a sequence of turns that alternate between user prompts and model responses. Inside the model, both the prompt and response are represented by a sequence of **tokens**, which represent either individual words or subcomponents of a word. The tokens are used to compute the cost of using a model and to measure the size of the **context**, the combination of the current prompt and any previous prompts and responses used to generate the next response.\n\nIt's useful to make the distinction between providers and models. A **provider** is a web API that gives access to one or more **models**. The distinction is a bit subtle because providers are often synonymous with a model, like OpenAI and GPT, Anthropic and Claude, and Google and Gemini. But other providers, like Ollama, can host many different models, typically open source models like LLaMa and Mistral. Still other providers support both open and closed models, typically by partnering with a company that provides a popular closed model. For example, Azure OpenAI offers both open source models and OpenAI's GPT, while AWS Bedrock offers both open source models and Anthropic's Claude.\n\n### What is a token?\n\nAn LLM is a _model_, and like all models needs some way to represent its inputs numerically. For LLMs, that means we need some way to convert words to numbers. This is the goal of the **tokenizer**. For example, using the GPT 4o tokenizer, the string \"When was R created?\" is converted to 5 tokens: 5958 (\"When\"), 673 (\" was\"), 460 (\" R\"), 5371 (\" created\"), 30 (\"?\"). As you can see, many simple strings can be represented by a single token. But more complex strings require multiple tokens. For example, the string \"counterrevolutionary\" requires 4 tokens: 32128 (\"counter\"), 264 (\"re\"), 9477 (\"volution\"), 815 (\"ary\"). (You can see how various strings are tokenized at <http://tiktokenizer.vercel.app/>).\n\nIt's important to have a rough sense of how text is converted to tokens because tokens are used to determine the cost of a model and how much context can be used to predict the next response. On average an English word needs ~1.5 tokens so a page might require 375-400 tokens and a complete book might require 75,000 to 150,000 tokens. Other languages will typically require more tokens, because (in brief) LLMs are trained on data from the internet, which is primarily in English.\n\nLLMs are priced per million tokens. State of the art models (like GPT-4o or Claude 3.5 sonnet) cost $2-3 per million input tokens, and $10-15 per million output tokens. Cheaper models can cost much less, e.g. GPT-4o mini costs $0.15 per million input tokens and $0.60 per million output tokens. Even $10 of API credit will give you a lot of room for experimentation, particularly with cheaper models, and prices are likely to decline as model performance improves.\n\nTokens also used to measure the context window, which is how much text the LLM can use to generate the next response. As we'll discuss shortly, the context length includes the full state of your conversation so far (both your prompts and the model's responses), which means that cost grow rapidly with the number of conversational turns.\n\nIn ellmer, you can see how many tokens a conversations has used by printing it, and you can see total usage for a session with `token_usage()`.\n\n```{r}\nchat <- chat_openai(model = \"gpt-4o\")\n. <- chat$chat(\"Who created R?\", echo = FALSE)\nchat\n\ntoken_usage()\n```\n\nIf you want to learn more about tokens and tokenizers, I'd recommend watching the first 20-30 minutes of [Let's build the GPT Tokenizer](https://www.youtube.com/watch?v=zduSFxRajkE) by Andrej Karpathy. You certainly don't need to learn how to build your own tokenizer, but the intro will give you a bunch of useful background knowledge that will help improve your undersstanding of how LLM's work.\n\n### What is a conversation?\n\nA conversation with an LLM takes place through a series of HTTP requests and responses: you send your question to the LLM as an HTTP request, and it sends back its reply as an HTTP response. In other words, a conversation consists of a sequence of a paired turns: a sent prompt and a returned response.\n\nIt's important to note that a request includes not only the current user prompt, but every previous user prompt and model response. This means that:\n\n* The cost of a conversation grows quadratically with the number of turns: if you want to save money, keep your conversations short.\n\n* Each response is affected by all previous prompts and responses. This can make a converstion get stuck in a local optimum, so it's generally better to iterate by starting a new conversation with a better prompt rather than having a long back-and-forth.\n\n* ellmer has full control over the conversational history. Because it's ellmer's responsibility to send the previous turns of the conversation, it's possible to start a conversation with one model and finish it with another.\n\n### What is a prompt?\n\nThe user prompt is the question that you send to the model. There are two other important prompts that underlie the user prompt:\n\n* The **platform prompt**, which is unchangeable, set by the model provider, and affects every conversation. You can see what these look like from Anthropic, who [publishes their core system prompts](https://docs.anthropic.com/en/release-notes/system-prompts).\n\n* The **system prompt** (aka developer prompt), which is set when you create a new conversation, and affects every response. It's used to provide additional instructions to the model, shaping its responses to your needs. For example, you might use the system prompt to ask the model to always respond in Spanish or to write dependency-free base R code. You can also use the system prompt to provide the model with information it wouldn't otherwise know, like the details of your database schema, or your preferred ggplot2 theme and color palette.\n\nOpenAI calls this the [chain of command](https://cdn.openai.com/spec/model-spec-2024-05-08.html#follow-the-chain-of-command): if there are conflicts or inconsistencies the prompts, the platform prompt overrides the system prompt, which in turn overrides the user prompt.\n\nWhen you use a chat app like ChatGPT or claude.ai you can only iterate on the user prompt. But when you're programming with LLMs, you'll primarily iterate on the system prompt. For example, if you're developing an app that helps a user write tidyverse code, you'd work with the system prompt to ensure that user gets the style of code they want.\n\nWriting a good prompt, which is called __prompt design__, is key to effective use of LLMs. It is discussed in more detail in `vignette(\"prompt-design\")`.\n\n## Example uses\n\nNow that you've got the basic vocab under your belt, I'm going to fire a bunch of interesting potential use cases at you. While there are special purpose tools that might solve these cases faster and/or cheaper, an LLM allows you to rapidly prototype a solution. This can be extremely valuable even if you end up using those more specialised tools in your final product.\n\nIn general, we recommend avoiding LLMs where accuracy is critical. That said, there are still many cases for their use. For example, even though they always require some manual fiddling, you might save a bunch of time ever with an 80% correct solution. In fact, even a not-so-good solution can still be useful because it makes it easier to get started: it's easier to react to something rather than to have to start from scratch with a blank page.\n\n### Chatbots\n\nA great place to start with ellmer and LLMs is to build a chatbot with a custom prompt. Chatbots are a familiar interface to LLMs and are easy to create in R with [shinychat](https://github.com/jcheng5/shinychat). And there's a surprising amount of value to creating a custom chatbot that has a prompt stuffed with useful knowledge. For example:\n\n* Help people use your new package. To do so, you need a custom prompt because LLMs were trained on data prior to your package's existence. You can create a surprisingly useful tool just by preloading the prompt with your README and vignettes. This is how the [ellmer assistant](https://github.com/jcheng5/elmer-assistant) works.\n\n* Build language specific prompts for R and/or python. [Shiny assistant](https://shiny.posit.co/blog/posts/shiny-assistant/) helps you build shiny apps (either in R or python) by combining a [prompt](https://github.com/posit-dev/shiny-assistant/blob/main/shinyapp/app_prompt.md) that gives general advice on building apps with a prompt for [R](https://github.com/posit-dev/shiny-assistant/blob/main/shinyapp/app_prompt_r.md) or [python](https://github.com/posit-dev/shiny-assistant/blob/main/shinyapp/app_prompt_python.md). The python prompt is very detailed because there's much less information about Shiny for Python in the existing LLM knowledgebases.\n\n* Help people find the answers to their questions. Even if you've written a bunch of documentation for something, you might find that you still get questions because folks can't easily find exactly what they're looking for. You can reduce the need to answer these questions by creating a chatbot with a prompt that contains your documentation. For example, if you're a teacher, you could create a chatbot that includes your syllabus in the prompt. This eliminates a common class of question where the data necessary to answer the question is available, but hard to find.\n\nAnother direction is to give the chatbot additional context about your current environment. For example, [aidea](https://github.com/cpsievert/aidea) allows the user to interactively explore a dataset with the help of the LLM. It adds summary statistics about the dataset to the [prompt](https://github.com/cpsievert/aidea/blob/main/inst/app/prompt.md) so that the LLM knows something about your data. Along these lines, imagine writing a chatbot to help with data import that has a prompt which include all the files in the current directory along with their first few lines.\n\n### Structured data extraction\n\nLLMs are often very good at extracting structured data from unstructured text. This can give you traction to analyse data that was previously unaccessible. For example:\n\n* Customer tickets and GitHub issues: you can use LLMs for quick and dirty sentiment analysis by extracting any specifically mentioned products and summarising the discussion as a few bullet points.\n\n* Geocoding: LLMs do a surprisingly good job at geocoding, especially extracting addresses or finding the latitute/longitude of cities. There are specialised tools that do this better, but using an LLM makes it easy to get started.\n\n* Recipes: I've extracted structured data from baking and cocktail recipes. Once you have the data in a structured form you can use your R skills to better understand how recipes vary within a cookbook or to look for recipes that use the ingredients currently in your kitchen. You could even use shiny assistant to help make those techniques available to anyone, not just R users.\n\nStructured data extraction also works well with images. It's not the fastest or cheapest way to extract data but it makes it really easy to prototype ideas. For example, maybe you have a bunch of scanned documents that you want to index. You can convert PDFs to images (e.g. using {imagemagick}) then use structured data extraction to pull out key details.\n\nLearn more about structured data extraction in `vignette(\"structure-data\")`.\n\n### Programming\n\nLLMs can also be useful to solve general programming problems. For example:\n\n* Write a detailed prompt that explains how to update code to use a new version of a package. You could combine this with the rstudioapi package to allow the user to select code, transform it, and replace it in the existing text. A comprehensive example of this sort of app is [chores](https://simonpcouch.github.io/chores/), which includes prompts for automatically generating roxygen documentation blocks, updating testthat code to the 3rd edition, and converting `stop()` and `abort()` to use `cli::cli_abort()`.\n\n* You could automatically look up the documentation for an R function, and include it in the prompt to make it easier to figure out how to use a specific function.\n\n* You can use LLMs to explain code, or even ask them to [generate a diagram](https://bsky.app/profile/daviddiviny.com/post/3lb6kjaen4c2u).\n\n* You can ask an LLM to analyse your code for potential code smells or security issues. You can do this a function at a time, or explore the entire source code of your package or script in the prompt.\n\n* You could use [gh](https://gh.r-lib.org) to find unlabelled issues, extract the text, and ask the LLM to figure out what labels might be most appropriate. Or maybe an LLM might be able to help people create better reprexes, or simplify reprexes that are too complicated?\n\n* I find it useful to have an LLM document a function for me, even knowing that it's likely to be mostly incorrect. Having something to react to make it much easier for me to get started.\n\n* If you're working with code or data from another programming language, you can ask an LLM to convert it to R code for you. Even if it's not perfect, it's still typically much faster than doing everything yourself.\n\n## Miscellaneous\n\nTo finish up here are a few other ideas that seem cool but didn't seem to fit the above categories:\n\n* Automatically generate alt text for plots, using `content_image_plot()`.\n\n* Analyse the text of your statistical report to look for flaws in your statistical reasoning (e.g. misinterpreting p-values or assuming causation where only correlation exists).\n\n* Use your existing company style guide to generate a [brand.yaml](https://posit-dev.github.io/brand-yml/articles/llm-brand-yml-prompt/) specification to automatically style your reports, apps, dashboards and plots to match your corporate style guide.\n</file>\n\n<file path=\"vignettes/prompt-design.Rmd\">\n---\ntitle: \"Prompt design\"\noutput: rmarkdown::html_vignette\nvignette: >\n  %\\VignetteIndexEntry{Prompt design}\n  %\\VignetteEngine{knitr::rmarkdown}\n  %\\VignetteEncoding{UTF-8}\n---\n\n```{r, include = FALSE}\nknitr::opts_chunk$set(\n  collapse = TRUE,\n  comment = \"#>\",\n  eval = ellmer:::openai_key_exists() && ellmer:::anthropic_key_exists(),\n  cache = TRUE\n)\noptions(ellmer_seed = 1337)\n```\n\nThis vignette gives you some advice about how to use ellmer to write prompts. We'll work through two hopefully relevant examples: a prompt that generates code and another that extracts structured data. If you've never written a prompt, I'd highly recommend reading Ethan Mollick's [Getting started with AI: Good enough prompting](https://www.oneusefulthing.org/p/getting-started-with-ai-good-enough). I think understanding his analogy about how AI works will really help you get started:\n\n> Treat AI like an infinitely patient new coworker who forgets everything you tell them each new conversation, one that comes highly recommended but whose actual abilities are not that clear. ... Two parts of this are analogous to working with humans (being new on the job and being a coworker) and two of them are very alien (forgetting everything and being infinitely patient). We should start with where AIs are closest to humans, because that is the key to good-enough prompting\n\nAs well as learning general prompt design skills, it's also a good idea to read any specific advice for the model that you're using. Here are some pointers to the prompt design guides of some of the most popular models:\n\n* [Claude](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview)\n* [OpenAI](https://platform.openai.com/docs/guides/prompt-engineering)\n* [Gemini](https://ai.google.dev/gemini-api/docs/prompting-intro)\n\nIf you have a claude account, you can use its [prompt-generator](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-generator). It's specifically tailored for Claude, but I suspect it will help you with many other LLMs, or at least give you some ideas as to what else to include in your prompt.\n\n```{r setup}\n#| cache: false\nlibrary(ellmer)\n```\n\n```{r}\n#| include: false\n# Manually ratchet claude variability way down to hopefully make generated\n# code better match my prose.\nchat_anthropic <- function(...) {\n  ellmer::chat_anthropic(..., params = params(temperature = 0))\n}\n```\n\n## Best practices\n\nIt's highly likely that you'll end up writing long, possibly multi-page prompts. To ensure your success with this task, we have two recommendations. First, put each prompt its own, separate file. Second, write the prompts using markdown. The reason to use markdown is that it's quite readable to LLMs (and humans), and it allows you to do things like use headers to divide up a prompt into sections and itemised lists to enumerate multiple options. You can see some examples of this style of prompt here:\n\n* <https://github.com/posit-dev/shiny-assistant/blob/main/shinyapp/app_prompt_python.md>\n* <https://github.com/jcheng5/py-sidebot/blob/main/prompt.md>\n* <https://github.com/simonpcouch/pal/tree/main/inst/prompts>\n* <https://github.com/cpsievert/aidea/blob/main/inst/app/prompt.md>\n\nIn terms of file names, if you only have one prompt in your project, call it `prompt.md`. If you have multiple prompts, give them informative names like `prompt-extract-metadata.md` or `prompt-summarize-text.md`. If you're writing a package, put your prompt(s) in `inst/prompts`, otherwise it's fine to put them in the project's root directory.\n\nYour prompts are going to change over time, so we'd highly recommend commiting them to a git repo. That will ensure that you can easily see what has changed, and that if you accidentally make a mistake you can easily roll back to a known good verison.\n\nIf your prompt includes dynamic data, use `ellmer::interpolate_file()` to intergrate it into your prompt. `interpolate_file()` works like [glue](https://glue.tidyverse.org) but uses `{{ }}` instead of `{ }` to make it easier to work with JSON.\n\nAs you iterate the prompt, it's a good idea to build up a small set of challenging examples that you can regularly re-check with your latest version of the prompt. Currently you'll need to do this by hand, but we hope to eventually provide tools that'll help you do this a little more formally.\n\nUnfortunately, you won't see these best practices in action in this vignette since we're keeping the prompts short and inline to make it easier for you to grok what's going on.\n\n## Code generation\n\nLet's explore prompt design for a simple code generation task:\n\n```{r}\n#| cache: false\nquestion <- \"\n  How can I compute the mean and median of variables a, b, c, and so on,\n  all the way up to z, grouped by age and sex.\n\"\n```\n\nI'll use `chat_anthropic()` for this problem because in our experience it does the best job of generating code.\n\n### Basic flavour\n\nWhen I don't provide a system prompt, I sometimes get answers in different languages or different styles of R code:\n\n```{r}\n#| label: code-basic\nchat <- chat_anthropic()\nchat$chat(question)\n```\n\nI can ensure that I always get R code in a specific style by providing a system prompt:\n\n```{r}\n#| label: code-r\nchat <- chat_anthropic(\n  system_prompt = \"\n  You are an expert R programmer who prefers the tidyverse.\n\"\n)\nchat$chat(question)\n```\n\nNote that I'm using both a system prompt (which defines the general behaviour) and a user prompt (which asks the specific question). You could put all this content in the user prompt and get similar results, but I think it's helpful to use both to cleanly divide the general framing of the response from the specific questions you ask.\n\nSince I'm mostly interested in the code, I ask it to drop the explanation and sample data:\n\n```{r}\n#| label: code-r-minimal\nchat <- chat_anthropic(\n  system_prompt = \"\n  You are an expert R programmer who prefers the tidyverse.\n  Just give me the code. I don't want any explanation or sample data.\n\"\n)\nchat$chat(question)\n```\n\nAnd of course, if you want a different style of R code, just ask for it:\n\n```{r}\n#| label: code-styles\nchat <- chat_anthropic(\n  system_prompt = \"\n  You are an expert R programmer who prefers data.table.\n  Just give me the code. I don't want any explanation or sample data.\n\"\n)\nchat$chat(question)\n\nchat <- chat_anthropic(\n  system_prompt = \"\n  You are an expert R programmer who prefers base R.\n  Just give me the code. I don't want any explanation or sample data.\n\"\n)\nchat$chat(question)\n```\n\n### Be explicit\n\nIf there's something about the output that you don't like, try being more explicit. For example, the code isn't styled quite how I'd like it, so I provide more details about what I do want:\n\n```{r}\n#| label: code-explicit\nchat <- chat_anthropic(\n  system_prompt = \"\n  You are an expert R programmer who prefers the tidyverse.\n  Just give me the code. I don't want any explanation or sample data.\n\n  Follow the tidyverse style guide:\n  * Spread long function calls across multiple lines.\n  * Where needed, always indent function calls with two spaces.\n  * Only name arguments that are less commonly used.\n  * Always use double quotes for strings.\n  * Use the base pipe, `|>`, not the magrittr pipe `%>%`.\n\"\n)\nchat$chat(question)\n```\n\nThis still doesn't yield exactly the code that I'd write, but it's pretty close.\n\nYou could provide a different prompt if you were looking for more explanation of the code:\n\n```{r}\n#| label: code-teacher\nchat <- chat_anthropic(\n  system_prompt = \"\n  You are an expert R teacher.\n  I am a new R user who wants to improve my programming skills.\n  Help me understand the code you produce by explaining each function call with\n  a brief comment. For more complicated calls, add documentation to each\n  argument. Just give me the code. I don't want any explanation or sample data.\n\"\n)\nchat$chat(question)\n```\n\n### Teach it about new features\n\nYou can imagine LLMs as being a sort of an average of the internet at a given point in time. That means they will provide popular answers, which will tend to reflect older coding styles (either because the new features aren't in their index, or the older features are so much more popular). So if you want your code to use specific newer language features, you might need to provide the examples yourself:\n\n```{r}\n#| label: code-new-feature\nchat <- chat_anthropic(\n  system_prompt = \"\n  You are an expert R programmer.\n  Just give me the code; no explanation in text.\n  Use the `.by` argument rather than `group_by()`.\n  dplyr 1.1.0 introduced per-operation grouping with the `.by` argument.\n  e.g., instead of:\n\n  transactions |>\n    group_by(company, year) |>\n    mutate(total = sum(revenue))\n\n  write this:\n  transactions |>\n    mutate(\n      total = sum(revenue),\n      .by = c(company, year)\n    )\n\"\n)\nchat$chat(question)\n```\n\n## Structured data\n\nProviding a rich set of examples is a great way to encourage the output to produce exactly what you want. This is known as **multi-shot prompting**. Below we'll work through a prompt that I designed to extract structured data from recipes, but the same ideas apply in many other situations.\n\n### Getting started\n\nMy overall goal is to turn a list of ingredients, like the following, into a nicely structured JSON that I can then analyse in R (e.g. compute the total weight, scale the recipe up or down, or convert the units from volumes to weights).\n\n```{r}\n#| cache: false\ningredients <- \"\n   cup (150g) dark brown sugar\n  2 large eggs\n   cup (165g) sour cream\n   cup (113g) unsalted butter, melted\n  1 teaspoon vanilla extract\n   teaspoon kosher salt\n   cup (80ml) neutral oil\n  1 cups (190g) all-purpose flour\n  150g plus 1 teaspoons sugar\n\"\n```\n\n(This isn't the ingredient list for a real recipe but it includes a sampling of styles that I encountered in my project.)\n\nIf you don't have strong feelings about what the data structure should look like, you can start with a very loose prompt and see what you get back. I find this a useful pattern for underspecified problems where the heavy lifting lies with precisely defining the problem you want to solve. Seeing the LLM's attempt to create a data structure gives me something to react to, rather than having to start from a blank page.\n\n```{r}\n#| label: data-loose\ninstruct_json <- \"\n  You're an expert baker who also loves JSON. I am going to give you a list of\n  ingredients and your job is to return nicely structured JSON. Just return the\n  JSON and no other commentary.\n\"\n\nchat <- chat_openai(instruct_json)\nchat$chat(ingredients)\n```\n\n(I don't know if the additional colour, \"You're an expert baker who also loves JSON\", does anything, but I like to think this helps the LLM get into the right mindset of a very nerdy baker.)\n\n### Provide examples\n\nThis isn't a bad start, but I prefer to cook with weight and I only want to see volumes if weight isn't available so I provide a couple of examples of what I'm looking for. I was pleasantly suprised that I can provide the input and output examples in such a loose format.\n\n```{r}\n#| label: data-examples\ninstruct_weight <- r\"(\n  Here are some examples of the sort of output I'm looking for:\n\n   cup (150g) dark brown sugar\n  {\"name\": \"dark brown sugar\", \"quantity\": 150, \"unit\": \"g\"}\n\n   cup (80ml) neutral oil\n  {\"name\": \"neutral oil\", \"quantity\": 80, \"unit\": \"ml\"}\n\n  2 t ground cinnamon\n  {\"name\": \"ground cinnamon\", \"quantity\": 2, \"unit\": \"teaspoon\"}\n)\"\n\nchat <- chat_openai(paste(instruct_json, instruct_weight))\nchat$chat(ingredients)\n```\n\nJust providing the examples seems to work remarkably well. But I found it useful to also include a description of what the examples are trying to accomplish. I'm not sure if this helps the LLM or not, but it certainly makes it easier for me to understand the organisation of the whole prompt and check that I've covered the key pieces I'm interested in.\n\n```{r}\n#| cache: false\ninstruct_weight <- r\"(\n  * If an ingredient has both weight and volume, extract only the weight:\n\n   cup (150g) dark brown sugar\n  [\n    {\"name\": \"dark brown sugar\", \"quantity\": 150, \"unit\": \"g\"}\n  ]\n\n* If an ingredient only lists a volume, extract that.\n\n  2 t ground cinnamon\n   cup (80ml) neutral oil\n  [\n    {\"name\": \"ground cinnamon\", \"quantity\": 2, \"unit\": \"teaspoon\"},\n    {\"name\": \"neutral oil\", \"quantity\": 80, \"unit\": \"ml\"}\n  ]\n)\"\n```\n\nThis structure also allows me to give the LLMs a hint about how I want multiple ingredients to be stored, i.e. as an JSON array.\n\nI then iterated on the prompt, looking at the results from different recipes to get a sense of what the LLM was getting wrong. Much of this felt like I waws iterating on my own understanding of the problem as I didn't start by knowing exactly how I wanted the data. For example, when I started out I didn't really think about all the various ways that ingredients are specified. For later analysis, I always want quantities to be number, even if they were originally fractions, or the if the units aren't precise (like a pinch). It made me realise that some ingredients are unitless.\n\n```{r}\n#| cache: false\ninstruct_unit <- r\"(\n* If the unit uses a fraction, convert it to a decimal.\n\n   cup sugar\n   teaspoon salt\n  [\n    {\"name\": \"dark brown sugar\", \"quantity\": 0.33, \"unit\": \"cup\"},\n    {\"name\": \"salt\", \"quantity\": 0.5, \"unit\": \"teaspoon\"}\n  ]\n\n* Quantities are always numbers\n\n  pinch of kosher salt\n  [\n    {\"name\": \"kosher salt\", \"quantity\": 1, \"unit\": \"pinch\"}\n  ]\n\n* Some ingredients don't have a unit.\n  2 eggs\n  1 lime\n  1 apple\n  [\n    {\"name\": \"egg\", \"quantity\": 2},\n    {\"name\": \"lime\", \"quantity\": 1},\n    {\"name\", \"apple\", \"quantity\": 1}\n  ]\n)\"\n```\n\nYou might want to take a look at the [full prompt](https://gist.github.com/hadley/7688b4dd1e5e97b800c6d7d79e437b48) to see what I ended up with.\n\n### Structured data\n\nNow that I've iterated to get a data structure I like, it seems useful to formalise it and tell the LLM exactly what I'm looking for when dealing with structured data. This guarantees that the LLM will only return JSON, that the JSON will have the fields that you expect, and that ellmer will convert it into an R data structure.\n\n```{r}\n#| label: data-structured\ntype_ingredient <- type_object(\n  name = type_string(\"Ingredient name\"),\n  quantity = type_number(),\n  unit = type_string(\"Unit of measurement\")\n)\n\ntype_ingredients <- type_array(items = type_ingredient)\n\nchat <- chat_openai(c(instruct_json, instruct_weight))\nchat$extract_data(ingredients, type = type_ingredients)\n```\n\n### Capturing raw input\n\nOne thing that I'd do next time would also be to include the raw ingredient names in the output. This doesn't make much difference in this simple example but it makes it much easier to align the input with the output and to start developing automated measures of how well my prompt is doing.\n\n```{r}\n#| cache: false\ninstruct_weight_input <- r\"(\n  * If an ingredient has both weight and volume, extract only the weight:\n\n     cup (150g) dark brown sugar\n    [\n      {\"name\": \"dark brown sugar\", \"quantity\": 150, \"unit\": \"g\", \"input\": \" cup (150g) dark brown sugar\"}\n    ]\n\n  * If an ingredient only lists a volume, extract that.\n\n    2 t ground cinnamon\n     cup (80ml) neutral oil\n    [\n      {\"name\": \"ground cinnamon\", \"quantity\": 2, \"unit\": \"teaspoon\", \"input\": \"2 t ground cinnamon\"},\n      {\"name\": \"neutral oil\", \"quantity\": 80, \"unit\": \"ml\", \"input\": \" cup (80ml) neutral oil\"}\n    ]\n)\"\n```\n\nI think this is particularly important if you're working with even less structured text. For example, imagine you had this text:\n\n```{r}\n#| cache: false\nrecipe <- r\"(\n  In a large bowl, cream together one cup of softened unsalted butter and a\n  quarter cup of white sugar until smooth. Beat in an egg and 1 teaspoon of\n  vanilla extract. Gradually stir in 2 cups of all-purpose flour until the\n  dough forms. Finally, fold in 1 cup of semisweet chocolate chips. Drop\n  spoonfuls of dough onto an ungreased baking sheet and bake at 350F (175C)\n  for 10-12 minutes, or until the edges are lightly browned. Let the cookies\n  cool on the baking sheet for a few minutes before transferring to a wire\n  rack to cool completely. Enjoy!\n)\"\n```\n\nIncluding the input text in the output makes it easier to see if it's doing a good job:\n\n```{r}\n#| label: data-unstructured-input\nchat <- chat_openai(c(instruct_json, instruct_weight_input))\nchat$chat(recipe)\n```\n\nWhen I ran it while writing this vignette, it seemed to be working out the weight of the ingredients specified in volume, even though the prompt specifically asks it not to. This may suggest I need to broaden my examples.\n\n## Token usage\n\n```{r}\n#| label: usage\n#| type: asis\n#| echo: false\nknitr::kable(token_usage())\n```\n</file>\n\n<file path=\"vignettes/structured-data.Rmd\">\n---\ntitle: \"Structured data\"\noutput: rmarkdown::html_vignette\nvignette: >\n  %\\VignetteIndexEntry{Structured data}\n  %\\VignetteEngine{knitr::rmarkdown}\n  %\\VignetteEncoding{UTF-8}\n---\n\n```{r, include = FALSE}\nknitr::opts_chunk$set(\n  collapse = TRUE,\n  comment = \"#>\",\n  eval = ellmer:::openai_key_exists(),\n  cache = TRUE\n)\n```\n\nWhen using an LLM to extract data from text or images, you can ask the chatbot to format it in JSON or any other format that you like. This works well most of the time, but there's no guarantee that you'll get the exact format you want. In particular, if you're trying to get JSON, you'll find that it's typically surrounded in ```` ```json ````, and you'll occasionally get text that isn't valid JSON. To avoid these problems, you can use a recent LLM feature: **structured data** (aka structured output). With structured data, you supply the type specification that defines the object structure you want and the LLM ensures that's what you'll get back.\n\n```{r setup}\n#| cache: false\nlibrary(ellmer)\n```\n\n## Structured data basics\n\nTo extract structured data you call the `$extract_data()` method instead of the `$chat()` method. You'll also need to define a type specification that describes the structure of the data that you want (more on that shortly). Here's a simple example that extracts two specific values from a string:\n\n```{r}\n#| label: basics-text\nchat <- chat_openai()\nchat$extract_data(\n  \"My name is Susan and I'm 13 years old\",\n  type = type_object(\n    age = type_number(),\n    name = type_string()\n  )\n)\n```\n\nThe same basic idea works with images too:\n\n```{r}\n#| label: basics-image\nchat$extract_data(\n  content_image_url(\"https://www.r-project.org/Rlogo.png\"),\n  type = type_object(\n    primary_shape = type_string(),\n    primary_colour = type_string()\n  )\n)\n```\n\n## Data types basics\n\nTo define your desired type specification (also known as a **schema**), you use the `type_()` functions. (You might already be familiar with these if you've done any function calling, as discussed in `vignette(\"function-calling\")`). The type functions can be divided into three main groups:\n\n* **Scalars** represent five types of single values, `type_boolean()`, `type_integer()`, `type_number()`, `type_string()`, and `type_enum()`, which represent a single logical, integer, double, string, and factor value respectively.\n\n* **Arrays** represent any number of values of the same type. They are created with `type_array()`. You must always supply the `item` argument which specifies the type for each individual element. Arrays of scalars are very similar to R's atomic vectors:\n\n  ```{r}\n  #| cache: false\n  type_logical_vector <- type_array(items = type_boolean())\n  type_integer_vector <- type_array(items = type_integer())\n  type_double_vector <- type_array(items = type_number())\n  type_character_vector <- type_array(items = type_string())\n  ```\n\n  You can also have arrays of arrays and arrays of objects, which more closely resemble lists with well defined structures:\n\n  ```{r}\n  #| cache: false\n  list_of_integers <- type_array(items = type_integer_vector)\n  ```\n\n* **Objects** represent a collection of named values. They are created with `type_object()`. Objects can contain any number of scalars, arrays, and other objects. They are similar to named lists in R.\n\n  ```{r}\n  #| cache: false\n  type_person <- type_object(\n    name = type_string(),\n    age = type_integer(),\n    hobbies = type_array(items = type_string())\n  )\n  ```\n\nUsing these type specifications ensures that the LLM will return JSON. But ellmer goes one step further to convert the results to the closest R analog. Currently, this converts arrays of boolean, integers, numbers, and strings into logical, integer, numeric, and character vectors. Arrays of objects are converted into data frames. You can opt-out of this and get plain lists by setting `convert = FALSE` in `$extract_data()`.\n\nIn addition to defining types, you need to provide the LLM with some information about what you actually want. This is the purpose of the first argument, `description`, which is a string that describes the data that you want. This is a good place to ask nicely for other attributes you'll like the value to have (e.g. minimum or maximum values, date formats, ...). There's no guarantee that these requests will be honoured, but the LLM will usually make a best effort to do so.\n\n```{r}\n#| cache: false\ntype_type_person <- type_object(\n  \"A person\",\n  name = type_string(\"Name\"),\n  age = type_integer(\"Age, in years.\"),\n  hobbies = type_array(\n    \"List of hobbies. Should be exclusive and brief.\",\n    items = type_string()\n  )\n)\n```\n\nNow we'll dive into some examples before coming back to talk more about the details of data types.\n\n## Examples\n\nThe following examples, which are [closely inspired by the Claude documentation](https://github.com/anthropics/anthropic-cookbook/blob/main/tool_use/extracting_structured_json.ipynb), hint at some of the ways you can use structured data extraction.\n\n### Example 1: Article summarisation\n\n```{r}\n#| label: examples-summarisation\ntext <- readLines(system.file(\"examples/third-party-testing.txt\", package = \"ellmer\"))\n# url <- \"https://www.anthropic.com/news/third-party-testing\"\n# html <- rvest::read_html(url)\n# text <- rvest::html_text2(rvest::html_element(html, \"article\"))\n\ntype_summary <- type_object(\n  \"Summary of the article.\",\n  author = type_string(\"Name of the article author\"),\n  topics = type_array(\n    'Array of topics, e.g. [\"tech\", \"politics\"]. Should be as specific as possible, and can overlap.',\n    type_string(),\n  ),\n  summary = type_string(\"Summary of the article. One or two paragraphs max\"),\n  coherence = type_integer(\"Coherence of the article's key points, 0-100 (inclusive)\"),\n  persuasion = type_number(\"Article's persuasion score, 0.0-1.0 (inclusive)\")\n)\n\nchat <- chat_openai()\ndata <- chat$extract_data(text, type = type_summary)\ncat(data$summary)\n\nstr(data)\n```\n\n### Example 2: Named entity recognition\n\n```{r}\n#| label: examples-named-entity\ntext <- \"\n  John works at Google in New York. He met with Sarah, the CEO of\n  Acme Inc., last week in San Francisco.\n\"\n\ntype_named_entity <- type_object(\n  name = type_string(\"The extracted entity name.\"),\n  type = type_enum(\"The entity type\", c(\"person\", \"location\", \"organization\")),\n  context = type_string(\"The context in which the entity appears in the text.\")\n)\ntype_named_entities <- type_array(items = type_named_entity)\n\nchat <- chat_openai()\nchat$extract_data(text, type = type_named_entities)\n```\n\n### Example 3: Sentiment analysis\n\n```{r}\n#| label: examples-sentiment\ntext <- \"\n  The product was okay, but the customer service was terrible. I probably\n  won't buy from them again.\n\"\n\ntype_sentiment <- type_object(\n  \"Extract the sentiment scores of a given text. Sentiment scores should sum to 1.\",\n  positive_score = type_number(\"Positive sentiment score, ranging from 0.0 to 1.0.\"),\n  negative_score = type_number(\"Negative sentiment score, ranging from 0.0 to 1.0.\"),\n  neutral_score = type_number(\"Neutral sentiment score, ranging from 0.0 to 1.0.\")\n)\n\nchat <- chat_openai()\nstr(chat$extract_data(text, type = type_sentiment))\n```\n\nNote that while we've asked nicely for the scores to sum 1, which they do in this example (at least when I ran the code), this is not guaranteed.\n\n### Example 4: Text classification\n\n```{r}\n#| label: examples-classification\ntext <- \"The new quantum computing breakthrough could revolutionize the tech industry.\"\n\ntype_classification <- type_array(\n  \"Array of classification results. The scores should sum to 1.\",\n  type_object(\n    name = type_enum(\n      \"The category name\",\n      values = c(\n        \"Politics\",\n        \"Sports\",\n        \"Technology\",\n        \"Entertainment\",\n        \"Business\",\n        \"Other\"\n      )\n    ),\n    score = type_number(\n      \"The classification score for the category, ranging from 0.0 to 1.0.\"\n    )\n  )\n)\n\nchat <- chat_openai()\ndata <- chat$extract_data(text, type = type_classification)\ndata\n```\n\n### Example 5: Working with unknown keys\n\n```{r, eval = ellmer:::anthropic_key_exists()}\n#| label: examples-unknown-keys\ntype_characteristics <- type_object(\n  \"All characteristics\",\n  .additional_properties = TRUE\n)\n\nprompt <- \"\n  Given a description of a character, your task is to extract all the characteristics of that character.\n\n  <description>\n  The man is tall, with a beard and a scar on his left cheek. He has a deep voice and wears a black leather jacket.\n  </description>\n\"\n\nchat <- chat_anthropic()\nstr(chat$extract_data(prompt, type = type_characteristics))\n```\n\nThis example only works with Claude, not GPT or Gemini, because only Claude supports adding additional, arbitrary properties.\n\n### Example 6: Extracting data from an image\n\nThe final example comes from [Dan Nguyen](https://gist.github.com/dannguyen/faaa56cebf30ad51108a9fe4f8db36d8) (you can see other interesting applications at that link). The goal is to extract structured data from this screenshot:\n\n![Screenshot of schedule A: a table showing assets and \"unearned\" income](congressional-assets.png)\n\nEven without any descriptions, ChatGPT does pretty well:\n\n```{r}\n#| label: examples-image\ntype_asset <- type_object(\n  assert_name = type_string(),\n  owner = type_string(),\n  location = type_string(),\n  asset_value_low = type_integer(),\n  asset_value_high = type_integer(),\n  income_type = type_string(),\n  income_low = type_integer(),\n  income_high = type_integer(),\n  tx_gt_1000 = type_boolean()\n)\ntype_assets <- type_array(items = type_asset)\n\nchat <- chat_openai()\nimage <- content_image_file(\"congressional-assets.png\")\ndata <- chat$extract_data(image, type = type_assets)\ndata\n```\n\n## Advanced data types\n\nNow that you've seen a few examples, it's time to get into more specifics about data type declarations.\n\n### Required vs optional\n\nBy default, all components of an object are required. If you want to make some optional, set `required = FALSE`. This is a good idea if you don't think your text will always contain the required fields as LLMs may hallucinate data in order to fulfill your spec.\n\nFor example, here the LLM hallucinates a date even though there isn't one in the text:\n\n```{r}\n#| label: type-required\ntype_article <- type_object(\n  \"Information about an article written in markdown\",\n  title = type_string(\"Article title\"),\n  author = type_string(\"Name of the author\"),\n  date = type_string(\"Date written in YYYY-MM-DD format.\")\n)\n\nprompt <- \"\n  Extract data from the following text:\n\n  <text>\n  # Structured Data\n  By Hadley Wickham\n\n  When using an LLM to extract data from text or images, you can ask the chatbot to nicely format it, in JSON or any other format that you like.\n  </text>\n\"\n\nchat <- chat_openai()\nchat$extract_data(prompt, type = type_article)\nstr(data)\n```\n\nNote that I've used more of an explict prompt here. For this example, I found that this generated better results and that it's a useful place to put additional instructions.\n\nIf I let the LLM know that the fields are all optional, it'll return `NULL` for the missing fields:\n\n```{r}\n#| label: type-optional\ntype_article <- type_object(\n  \"Information about an article written in markdown\",\n  title = type_string(\"Article title\", required = FALSE),\n  author = type_string(\"Name of the author\", required = FALSE),\n  date = type_string(\"Date written in YYYY-MM-DD format.\", required = FALSE)\n)\nchat$extract_data(prompt, type = type_article)\n```\n\n### Data frames\n\nIf you want to define a data frame like object, you might be tempted to create a definition similar to what R uses: an object (i.e., a named list) containing multiple vectors (i.e., an array):\n\n```{r}\n#| cache: false\ntype_my_df <- type_object(\n  name = type_array(items = type_string()),\n  age = type_array(items = type_integer()),\n  height = type_array(items = type_number()),\n  weight = type_array(items = type_number())\n)\n```\n\nThis, however, is not quite right becuase there's no way to specify that each array should have the same length. Instead, you'll need to turn the data structure \"inside out\" and create an array of objects:\n\n```{r}\n#| cache: false\ntype_my_df <- type_array(\n  items = type_object(\n    name = type_string(),\n    age = type_integer(),\n    height = type_number(),\n    weight = type_number()\n  )\n)\n```\n\nIf you're familiar with the terms row-oriented and column-oriented data frames, this is the same idea. Since most languages don't possess vectorisation like R, row-oriented structures tend to be much more common in the wild.\n\n## Token usage\n\n```{r}\n#| label: usage\n#| type: asis\n#| echo: false\nknitr::kable(token_usage())\n```\n</file>\n\n<file path=\"README.md\">\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# ellmer <a href=\"https://ellmer.tidyverse.org\"><img src=\"man/figures/logo.png\" align=\"right\" height=\"138\" alt=\"ellmer website\" /></a>\n\n<!-- badges: start -->\n\n[![Lifecycle:\nexperimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://lifecycle.r-lib.org/articles/stages.html#experimental)\n[![R-CMD-check](https://github.com/tidyverse/ellmer/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/tidyverse/ellmer/actions/workflows/R-CMD-check.yaml)\n<!-- badges: end -->\n\nellmer makes it easy to use large language models (LLM) from R. It\nsupports a wide variety of LLM providers and implements a rich set of\nfeatures including streaming outputs, tool/function calling, structured\ndata extraction, and more.\n\n(Looking for something similar to ellmer for python? Check out\n[chatlas](https://github.com/posit-dev/chatlas)!)\n\n## Installation\n\nYou can install ellmer from CRAN with:\n\n``` r\ninstall.packages(\"ellmer\")\n```\n\n## Providers\n\nellmer supports a wide variety of model providers:\n\n- Anthropics Claude: `chat_anthropic()`.\n- AWS Bedrock: `chat_aws_bedrock()`.\n- Azure OpenAI: `chat_azure_openai()`.\n- Databricks: `chat_databricks()`.\n- DeepSeek: `chat_deepseek()`.\n- GitHub model marketplace: `chat_github()`.\n- Google Gemini: `chat_google_gemini()`.\n- Groq: `chat_groq()`.\n- Ollama: `chat_ollama()`.\n- OpenAI: `chat_openai()`.\n- OpenRouter: `chat_openrouter()`.\n- perplexity.ai: `chat_perplexity()`.\n- Snowflake Cortex: `chat_snowflake()` and `chat_cortex_analyst()`.\n- VLLM: `chat_vllm()`.\n\n### Provider/model choice\n\nIf youre using ellmer inside an organisation, you may have internal\npolicies that limit you to models from big cloud providers,\ne.g.`chat_azure_openai()`, `chat_aws_bedrock()`, `chat_databricks()`,\nor `chat_snowflake()`.\n\nIf youre using ellmer for your own exploration, youll have a lot more\nfreedom, so we have a few recommendations to help you get started:\n\n- `chat_openai()` or `chat_anthropic()` are good places to start.\n  `chat_openai()` defaults to **GPT-4o**, but you can use\n  `model = \"gpt-4o-mini\"` for a cheaper, lower-quality model, or\n  `model = \"o1-mini\"` for more complex reasoning. `chat_anthropic()` is\n  also good; it defaults to **Claude 3.5 Sonnet**, which we have found\n  to be particularly good at writing code.\n\n- `chat_google_gemini()` is great for large prompts because it has a\n  much larger context window than other models. It allows up to 1\n  million tokens, compared to Claude 3.5 Sonnets 200k and GPT-4os\n  128k. It also comes with a generous free tier (with the downside that\n  [your data is\n  used](https://ai.google.dev/gemini-api/terms#unpaid-services) to\n  improve the model).\n\n- `chat_ollama()`, which uses [Ollama](https://ollama.com), allows you\n  to run models on your own computer. While the biggest models you can\n  run locally arent as good as the state of the art hosted models, they\n  dont share your data and are effectively free.\n\n### Authentication\n\nAuthentication works a little differently depending on the provider. A\nfew popular ones (including OpenAI and Anthropic) require you to obtain\nan API key. We recommend you save it in an environment variable rather\nthan using it directly in your code, and if you deploy an app or report\nthat uses ellmer to another system, youll need to ensure that this\nenvironment variable is available there, too.\n\nellmer also automatically detects many of the OAuth or IAM-based\ncredentials used by the big cloud providers (currently\n`chat_azure_openai()`, `chat_aws_bedrock()`, `chat_databricks()`,\n`chat_snowflake()`). That includes credentials for these platforms\nmanaged by [Posit\nWorkbench](https://docs.posit.co/ide/server-pro/user/posit-workbench/managed-credentials/managed-credentials.html)\nand [Posit\nConnect](https://docs.posit.co/connect/user/oauth-integrations/#adding-oauth-integrations-to-deployed-content).\n\nIf you find cases where ellmer cannot detect credentials from one of\nthese cloud providers, feel free to open an issue; were happy to add\nmore auth mechanisms if needed.\n\n## Using ellmer\n\nYou can work with ellmer in several different ways, depending on whether\nyou are working interactively or programmatically. They all start with\ncreating a new chat object:\n\n``` r\nlibrary(ellmer)\n\nchat <- chat_openai(\n  model = \"gpt-4o-mini\",\n  system_prompt = \"You are a friendly but terse assistant.\",\n)\n```\n\nChat objects are stateful [R6 objects](https://r6.r-lib.org): they\nretain the context of the conversation, so each new query builds on the\nprevious ones. You call their methods with `$`.\n\n### Interactive chat console\n\nThe most interactive and least programmatic way of using ellmer is to\nchat directly in your R console or browser with `live_console(chat)` or\n`live_browser()`:\n\n``` r\nlive_console(chat)\n#> \n#>   Entering chat console. Use \"\"\" for multi-line input.  \n#>   Press Ctrl+C to quit.                                 \n#> \n#> >>> Who were the original creators of R?\n#> R was originally created by Ross Ihaka and Robert Gentleman at the University of\n#> Auckland, New Zealand.\n#>\n#> >>> When was that?\n#> R was initially released in 1995. Development began a few years prior to that,\n#> in the early 1990s.\n```\n\nKeep in mind that the chat object retains state, so when you enter the\nchat console, any previous interactions with that chat object are still\npart of the conversation, and any interactions you have in the chat\nconsole will persist after you exit back to the R prompt. This is true\nregardless of which chat function you use.\n\n### Interactive method call\n\nThe second most interactive way to chat is to call the `chat()` method:\n\n``` r\nchat$chat(\"What preceding languages most influenced R?\")\n#> R was primarily influenced by the S programming language, particularly S-PLUS.\n#> Other languages that had an impact include Scheme and various data analysis\n#> languages.\n```\n\nIf you initialize the chat object in the global environment, the `chat`\nmethod will stream the response to the console. When the entire response\nis received, its also (invisibly) returned as a character vector. This\nis useful when you want to see the response as it arrives, but you dont\nwant to enter the chat console.\n\nIf you want to ask a question about an image, you can pass one or more\nadditional input arguments using `content_image_file()` and/or\n`content_image_url()`:\n\n``` r\nchat$chat(\n  content_image_url(\"https://www.r-project.org/Rlogo.png\"),\n  \"Can you explain this logo?\"\n)\n#> The logo of R features a stylized letter \"R\" in blue, enclosed in an oval\n#> shape that resembles the letter \"O,\" signifying the programming language's\n#> name. The design conveys a modern and professional look, reflecting its use\n#> in statistical computing and data analysis. The blue color often represents\n#> trust and reliability, which aligns with R's role in data science.\n```\n\n### Programmatic chat\n\nThe most programmatic way to chat is to create the chat object inside a\nfunction. By doing so, live streaming is automatically suppressed and\n`$chat()` returns the result as a string:\n\n``` r\nmy_function <- function() {\n  chat <- chat_openai(\n    model = \"gpt-4o-mini\",\n    system_prompt = \"You are a friendly but terse assistant.\",\n  )\n  chat$chat(\"Is R a functional programming language?\")\n}\nmy_function()\n#> [1] \"Yes, R supports functional programming concepts. It allows functions to\n#> be first-class objects, supports higher-order functions, and encourages the\n#> use of functions as core components of code. However, it also supports\n#> procedural and object-oriented programming styles.\"\n```\n\nIf needed, you can manually control this behaviour with the `echo`\nargument. This is useful for programming with ellmer when the result is\neither not intended for human consumption or when you want to process\nthe response before displaying it.\n\n## Learning more\n\nellmer comes with a bunch of vignettes to help you learn more:\n\n- Learn key vocabulary and see example use cases in\n  `vignette(\"ellmer\")`.\n- Learn how to design your prompt in `vignette(\"prompt-design\")`.\n- Learn about tool/function calling in `vignette(\"tool-calling\")`.\n- Learn how to extract structured data in `vignette(\"structured-data\")`.\n- Learn about streaming and async APIs in `vignette(\"streaming-async\")`.\n</file>\n\n</files>\n</DOCUMENTATION>\n`\n\n\n## About brand.yml\n\nbrand.yml is a structured YAML file to hold brand information for key\nbrand elements. The goal of brand.yml is to capture the essence of the\nbrand's color and typographic choices in a simple format.\n\n\"brand.yml\" is the name of the project defining the YAML specification.\nA specific instance of a brand's data is stored in a file named\n\"_brand.yml\" by convention.\n\n## Brand Elements\n\n-   `meta` - Key identity information, name of the company, links to\n    brand guidelines, etc.\n\n-   `logo` - Files or links to the brand's logo at various sizes.\n\n-   `color` Semantic colors, e.g.`primary`, `secondary`, `success`,\n    `warning`, etc. Named colors in the brand's color palette are stored\n    in `color.palette`.\n\n-   `typography` - Font family, weight, style, color, and line height\n    for key elements, e.g.base, headings and monospace text. Available\n    fonts used by the brand are stored in `typography.fonts` and can be\n    sourced from Google Fonts, Bunny Fonts or local or remote font\n    files.\n\n-   `defaults` - Additional context-specific settings beyond the basic\n    brand colors and typography. These could be options, for example,\n    that are used by Bootstrap in Quarto or Shiny. They could also be\n    folded into existing Quarto yaml fields like `format` or `website`,\n    or they could be new fields for other contexts like `shiny`.\n\n## Example file\n\nThe following YAML includes all allowed features of a _brand.yml file.\nNote that all fields are optional.\n\nOnly include fields that directly apply to the brand; it's important for\nthe _brand.yml file to be simple and concise rather than overly\ncomplex. Many fields have simple and complex values variants; generally\nspeaking many fields accept either a simple string or a mapping.\nAlternative syntax is indicated in comments in the example below with\n\"ALT\". If possible, use the simple string.\n\n``` {.yaml filename=\"_brand.yml\"}\nmeta:\n  # name: Acme # ALT: Single string for simple company name\n  name:\n    short: Acme # Short company name\n    full: Acme Corporation International # Full, legal company name\n  \n  # link: https://acmecorp.com # ALT: single url for the company's home page\n  link:\n    home: https://www.acmecorp.com # Company's home apge\n    bluesky: https://bsky.app/profile/acmecorp.bsky.social # Bluesky social media account link\n    github: https://github.com/acmecorp # GitHub account link\n    mastodon: https://mastodon.social/@acmecorp # Mastodon account link\n    linkedin: https://www.linkedin.com/company/acmecorp # LinkedIn account link\n    facebook: https://www.facebook.com/acmecorp # Facebook account link\n    twitter: https://twitter.com/acmecorp # Twitter account link\n\nlogo:\n  images: # Mapping of image names to local files that should be stored next to the _brand.yml file. Users may need to download these files manually.\n    header: logos/header-logo.png # Each entry maps a name to a local file\n    header-white: logos/header-logo-white.png\n    full: # ALT: Images can alternatively be a path with associated alt text for accessibility\n      path: logos/full-logo.svg\n      alt: Acme logo.\n  small: logos/icon.png # A small image, ideally icon-sized. Can be a path to a file or the name of a file in `logo.images`\n  medium: # A medium sized logo, ideally small enough for a sidebar logo\n    # ALT: Logos is small, medium, and large may have `light` and `dark` variants\n    light: header # light variant for use on light backgrounds\n    dark: header-white # dark variant for use on dark backgrounds\n  large: full # A large logo, e.g. for use in a hero or cover page. ALT: Can refer directly to images in `logo.images`.\n\ncolor:\n  palette:\n    # Dictionary of the brand's colors with readable names. \n    # Must be a flat list of names and color values. \n    # Names should be follow Sass variable conventions. Prefer hex color values.\n    # Prefer or create aliases for Bootstrap primary colors: blue, indigo, purple, pink, red, orange, yellow, green, teal, cyan, white, black\n    white: \"#FFFFFF\"\n    black: \"#151515\"\n    blue: \"#447099\"\n    orange: \"#EE6331\"\n    green: \"#72994E\"\n    teal: \"#419599\"\n    burgundy: \"#9A4665\"\n    purple: burgundy # Aliases are allowed by referring to other colors in `color.palette`\n    fire-red: \"#FF0000\"\n    bright-yellow: \"#FFFF00\"\n\n  # All theme colors can take direct color values, and all are optional.\n  # Only include the colors that are obviously required.\n  # Refer to color names from `color.palette` whenever possible.\n  foreground: \"#151515\"  # Main text color, should have high contrast with background\n  background: \"#FFFFFF\"  # Main background color, should have high contrast with foreground\n  primary: \"#447099\"  # Main accent color for links, buttons, etc.\n  secondary: \"#707073\"  # Used for lighter text or disabled states. Only include if necessary.\n  tertiary: \"#C2C2C4\"  # Even lighter color for hover states, accents, wells. Only include if necessary.\n  success: \"#72994E\"  # Color for positive or successful actions/information\n  info: \"#419599\"  # Color for neutral or informational actions/information\n  warning: \"#EE6331\"  # Color for warning or cautionary actions/information,\n  danger: \"#9A4665\"  # Color for errors, dangerous actions, negative information\n  light: \"#FFFFFF\"  # Bright color for high-contrast on dark elements\n  dark: \"#404041\"  # Dark color for high-contrast on light elements\n  # ALT: All properties in `color` can refer by name to values in `color.palette`, including within `color.palette`.\n  # foreground: black\n  # background: white\n  # primary: blue\n  # success: green\n  # info: teal\n  # ALT: All properties in `color` can refer by name to other properties in `color`.\n\ntypography:\n  fonts:\n    - family: Open Sans  # Font family name\n      source: file  # Source of the font (file, google, bunny, or system)\n      files:  # REQUIRED list of font files for `source: file`, which must have at least one font file. Use placeholder names and comment out the source font section if proprietary fonts are used. (And include a Google Font alternative recommendation.)\n        - path: fonts/open-sans/OpenSans-Variable.ttf\n          # Each file corresponds to a weight and style, both default to \"normal\".\n          weight: 400  # Optional: specify weight for this file\n          style: normal  # Optional: specify style for this file\n        - path: fonts/open-sans/OpenSans-Variable-Italic.ttf\n          style: italic\n    - family: Roboto Slab\n      source: google\n      weight: [600, 900]  # Optional font weights to include (for google and bunny), defaults to all weights\n      # weight: 600..900 # ALT: fonts with variable weights can have a weight range\n      # weight: [thin, normal, bold] # ALT: font weights by name are allowed\n      style: [normal, italic]  # Font styles to include (for google and bunny)\n      display: block  # Font display property (for google). Optional and should not be included in most cases.\n    - family: Fira Code\n      source: bunny # Use Bunny Fonts, a GDPR-compliant alternative to Google Fonts\n      weight: [400, 500, 600] # Optional, same as for `source: google`\n      style: [normal, italic] # Optional, same as for `source: google`\n  \n  # base: Open San # ALT: If a string, sets the base font family\n  base:\n    family: Open Sans  # Optional: Font family for body text\n    weight: 400  # Optional: Font weight for body text\n    size: 16px  # Optional: Font size for body text, allows any CSS value, rem or px are preferred\n    line-height: 1.5  # Optional: Line height for body text\n    # DO NOT INCLUDE color HERE. The base font uses `color.foreground` by default.\n  \n  # headings: Roboto Slab # ALT: If a string, sets the headings font family\n  headings:\n    family: Roboto Slab  # Optional: Font family for headings\n    weight: 600  # Optional: Font weight for headings\n    style: normal  # Optional: Font style for headings\n    line-height: 1.2  # Optional: Line height for headings\n    color: \"#333333\"  # Optional: Color for headings\n    # color: primary # ALT: Can use named colors from `color` or `color.palette`\n  \n  # monospace: Fira Code # ALT: If a string, sets the monospace font family\n  monospace:\n    family: Fira Code  # Optional: Font family for monospace text\n    weight: 400  # Optional: Font weight for monospace text\n    size: 0.9em  # Optional: Font size for monospace text, CSS units allowed but `rem` or `px` preferred\n  monospace-inline: # Inline monospace text, inherits from monospace\n    # Properties of monospace can be overwritten here\n    color: \"#7d12ba\"  # Color for inline monospace text, ALT: named colors from `color` or `color.palette`\n    background-color: \"#f8f9fa\"  # Background color for inline monospace text, ALT: named colors from `color` or `color.palette`\n  monospace-block:\n    color: foreground  # Color for block monospace text, ALT: named colors from `color` or `color.palette`\n    background-color: background  # Background color for block monospace text, ALT: named colors from `color` or `color.palette`\n    line-height: 1.4  # Line height for block monospace text\n  link:\n    weight: 600  # Font weight for links\n    color: \"#0066cc\"  # Optional color for link, defaults `color.primary`. ALT: named colors from `color` or `color.palette`\n    background-color: transparent  # Optional background color for links, ALT: named colors from `color` or `color.palette`\n    decoration: underline  # Optional text decoration for links\n\ndefaults: # Additional Bootstrap, Shiny, or Quarto rules, all optional and only to be used as a last resort\n  bootstrap: Additional scss rules for any contexts that use Bootstrap\n    functions: # string with scss function declarations\n    defaults: # Mapping of Bootstrap variables to default values\n    mixins: # string with scss mixins\n    rules: # string with scss rules\n  quarto:\n    format:\n      # Options specific to output Quarto output formats\n  shiny:\n    theme: # Additional scss rules to add to the Shiny branded theme\n      defaults:\n        # Named bootstrap variables and their default values\n        navbar-bg: $brand-orange # Use Sass variables to access brand colors: $brand-{color_name}\n      rules:\n        # A string of additional scss rules\n```\n\n## Brand best practices\n\nBe careful and be certain to follow these rules when creating the\n`_brand.yml` file:\n\n-   When brands define a range of shades and tints for colors, it's best\n    to choose the midpoint color as the primary color used in the\n    `color.palette`.\n\n-   For logo and font files, use placeholders in the `_brand.yml` with\n    instructions to download the files and place them next to\n    `_brand.yml`.\n\n-   Suggest substitutes for proprietary fonts by finding the closest\n    equivalent fonts on Google Fonts.\n\n-   Prefer hex color syntax for raw color values.\n\n## Using `_brand.yml` in Shiny applications\n\n  To use a _brand.yml file in Shiny for R, pass it as the `theme` argument to a `page_*` function.\n\n```R\nui <- page_sidebar(\n  title = \"Acme Sales Dashboard\",\n  theme = bs_theme(brand = \"acme-brand.yml\"),\n  # ... the rest of your app ...\n)\n```\n`\n\n\nConsider multiple possible implementations of the application, then choose the best one. Remember to create a fully functional Shiny for R app that accurately reflects the user's requirements. If you're unsure about any aspect of the app, make a reasonable decision and explain your choice in a comment.\n\nBe very concise in the text."
        }
      ]
    },
    {
      "role": "assistant",
      "content": [
        {
          "type": "text",
          "text": "An error occurred while processing the response from the language model: 429 {\"type\":\"error\",\"error\":{\"type\":\"rate_limit_error\",\"message\":\"This request would exceed the rate limit for your organization (d2f738e7-cd48-4645-af96-31d3a41e97b4) of 50,000 input tokens per minute. For details, refer to: https://docs.claude.com/en/api/rate-limits. You can see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.\"},\"request_id\":\"req_011CVuZeLkX3BHuKooAu8rwh\"}."
        }
      ]
    },
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "It's been many hours, let's see if the rate limit error is gone"
        }
      ]
    },
    {
      "role": "assistant",
      "content": [
        {
          "type": "text",
          "text": "You're right! Let me try again. How can I help you with Shiny for R today? I'm ready to:\n\n- **Explain Shiny concepts** - reactive values, observers, rendering functions, layouts, etc.\n- **Answer how-to questions** - specific techniques for building features\n- **Create a complete Shiny app** - based on your requirements\n\nWhat would you like to work on?"
        }
      ]
    },
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "Implement the changes we discussed"
        }
      ]
    },
    {
      "role": "assistant",
      "content": [
        {
          "type": "text",
          "text": "I don't have any record of previous discussions in our conversation history. This appears to be a fresh start.\n\nCould you please remind me what changes you'd like to implement? You can:\n\n1. **Describe the app** you want to build (what it does, what features it has)\n2. **Share any existing code** you're working with\n3. **Explain the specific changes** you'd like made\n\nOnce you provide those details, I'll be happy to help!"
        }
      ]
    },
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "I'm not happy with the layout. I'd like the dropdown box on the top left, the graph below that, the data summary top right, and the table bottom right"
        }
      ]
    },
    {
      "role": "assistant",
      "content": [
        {
          "type": "text",
          "text": "I'd be happy to help you reorganize the layout! However, I need to see your current app code first.\n\nCould you please share:\n\n1. **Your current app.R file** (or whatever your app file is named)\n2. Or a description of what your app currently does\n\nOnce I see the code, I can restructure it to match your desired layout:\n- Dropdown box - top left\n- Graph - below dropdown\n- Data summary - top right\n- Table - bottom right"
        }
      ]
    },
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "You should be able to see app.R in this folder"
        }
      ]
    },
    {
      "role": "assistant",
      "content": [
        {
          "type": "text",
          "text": "I don't see an app.R file in the workspace yet. Let me check the project structure to see what files are available.\n\nGreat! I found your app.R file. Let me read it so I can help you reorganize the layout.\n\nPerfect! I can see your app. I'll reorganize it to match your desired layout using a grid-based approach:\n- **Top left**: Dropdown box\n- **Below that**: Graph\n- **Top right**: Data summary\n- **Bottom right**: Table\n\nDone! I've reorganized your app layout using bslib's `layout_columns()` function. Here's what changed:\n\n**New Layout:**\n- **Left column (50%)**: Graphs (package and/or component plots based on your filter)\n- **Right column (50%)**: \n  - **Top**: Data summary card\n  - **Bottom**: Data table card\n\nThe filters remain in the sidebar at the top left as before. The layout is responsive and uses bslib cards for clean styling. All your filtering logic works the same wayonly the visual arrangement has changed."
        }
      ]
    },
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "Why am I getting an error?"
        }
      ]
    },
    {
      "role": "assistant",
      "content": [
        {
          "type": "text",
          "text": "I don't see an error message in your message. Could you please share:\n\n1. **The exact error message** you're seeing\n2. **Where it appears** (console, browser, etc.)\n3. **What you were doing** when the error occurred (loading the app, clicking a button, selecting a dropdown, etc.)\n\nOnce you provide those details, I can help you fix it!"
        }
      ]
    },
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "It just says \"An error has occurred!\""
        }
      ]
    },
    {
      "role": "assistant",
      "content": [
        {
          "type": "text",
          "text": "That's a generic Shiny error. Let me help you troubleshoot. Can you:\n\n1. **Check the R console** for detailed error messages (usually appears below the Shiny output)\n2. **Open your browser's developer console** (F12 or right-click  Inspect  Console tab) to see if there are JavaScript errors\n3. **Tell me if the app loads at all** or if it fails immediately on startup\n\nAlternatively, could you share your current app.R code so I can review it for potential issues? That way I can spot the problem directly."
        }
      ]
    },
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "it doesn't load at all"
        }
      ]
    },
    {
      "role": "assistant",
      "content": [
        {
          "type": "text",
          "text": "Let me check your app.R file to see what might be causing it to fail on startup.\n\nI found the issue! There are syntax errors in your `summary_text` output. The escape sequences are malformed. Here's the fix:\n\n"
        }
      ]
    },
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "Are you able to see the app.R shiny app?"
        }
      ]
    },
    {
      "role": "assistant",
      "content": [
        {
          "type": "text",
          "text": "Yes, I can see your app.R file. Let me read it again to check the current state."
        }
      ]
    },
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "What does that mean?"
        }
      ]
    }
  ]
}
2025-12-08 22:15:53.790 [trace] [Anthropic] RECV messages.stream [req_011CVvPNyEdRimMGSEbvNwwW]: {
  "model": "claude-sonnet-4-5-20250929",
  "id": "msg_01V9jyxVKia4Y5rSM8HNkjb5",
  "type": "message",
  "role": "assistant",
  "content": [
    {
      "type": "text",
      "text": "When I said \"I can see your app.R file,\" I meant that I have access to read the file in your workspace and can view its contents.\n\nI just read through your app.R file (lines 1-109). It's a Shiny app that:\n- Loads the starwars dataset from dplyr\n- Has filters for species and homeworld in a sidebar\n- Shows plots (by package and by component)\n- Displays a summary and data table\n\nThe app looks correct to me now. Are you still getting the \"An error has occurred!\" message when you try to run it? \n\nIf yes, please:\n1. **Copy and paste the error from your R console** - there should be more detail below the Shiny app window\n2. **Try running the app again** and let me know exactly what happens"
    }
  ],
  "stop_reason": "end_turn",
  "stop_sequence": null,
  "usage": {
    "input_tokens": 45677,
    "cache_creation_input_tokens": 0,
    "cache_read_input_tokens": 0,
    "cache_creation": {
      "ephemeral_5m_input_tokens": 0,
      "ephemeral_1h_input_tokens": 0
    },
    "output_tokens": 185,
    "service_tier": "standard"
  }
}
2025-12-08 22:16:28.865 [warning] [Anthropic] Tool 'copilot_testFailure' is missing input schema type; defaulting to 'object'
2025-12-08 22:16:31.119 [warning] [Anthropic] Error in messages.stream [undefined]: 429 {"type":"error","error":{"type":"rate_limit_error","message":"This request would exceed the rate limit for your organization (d2f738e7-cd48-4645-af96-31d3a41e97b4) of 30,000 input tokens per minute. For details, refer to: https://docs.claude.com/en/api/rate-limits. You can see the response headers for current usage. Please reduce the prompt length or the maximum tokens requested, or try again later. You may also contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase."},"request_id":"req_011CVvPSFXFhbMGweD41xngd"}
